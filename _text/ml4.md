---
section: ml
title: "Диагностика систем машинного обучения"
---

### Что такое метрики эффективности?

Для того, чтобы эффективно проводить обучение моделей необходимо иметь способ оценки, насколько хорошо та или иная модель выполняет свою работу - предсказывает значение целевой переменной. Кажется, мы уже что-то подобное изучали. У каждой модели есть функция ошибки, которая показывает, на сколько модель соответствует эмпирическим значениям. Однако, использование функции ошибки не очень удобно для оценки именно "качества" уже построенных моделей. Ведь эта функция специально создается для единственной цели - организации процесса обучения. Поэтому для оценки уже построенных моделей используется не функция ошибки, а так называемые метрики эффективности - специальные функции, которые показывают, насколько эффективна уже готовая, обученная модель. 

Метрики эффективности на первый взгляд очень похожи на функции ошибки, ведь у них одна цель - отличать хорошие модели от плохих. Но делают они это по-разному, по-разному и применяются. К метрикам эффективности предъявляются совершенно другие требования, нежели к функциям ошибки. Поэтому давайте рассмотрим, для чего нужны и те и другие.

Функция ошибки нужна в первую очередь для формализации процесса обучения модели. То есть для того, чтобы подбирать параметры модели именно такими, чтобы модель как можно больше соответствовала реальным данным в обучающей выборке. Да, значение этой функции можно использовать как некоторую оценку качества модели уже после того, как она обучена, но это не удобно. 

Функция ошибки нужна, чтобы формализовать отклонения предсказанных моделью значений от реальных. Например, в методе линейной регрессии функция ошибки (среднеквадратическое отклонение) используется для метода градиентного спуска. Поэтому функция ошибки обязательно должна быть везде дифференцируемой, мы это отдельно отмечали, когда говорили про метод градиентного спуска. Это требование - дифференцируемость - нужно исключительно для метода оптимизации, то есть для обучения модели.

Зато функция, которая используется для оценки качества модели совершенно не должна быть аналитической и гладкой. Ведь мы не будем вычислять ее производную, мы только вычислим ее один раз для того, чтобы понять, насколько хорошая модель получилась. Так что не любую метрику эффективности вообще физически возможно использовать как функцию ошибки - метод обучения может просто не сработать.

Кроме того, функция ошибки должна быть вычислительно простой, ведь ее придется считать много раз в процессе обучения - тысячи или миллионы раз. Это еще одно требование, которое совершенно необязательно для метрики эффективности. Она как раз может считаться довольно сложно, ведь вычислять ее приходится всего несколько раз.

Зато метрика эффективности должна быть понятной и интерпретируемой, в отличие от функции ошибки. Раньше мы подчеркивали, что само абсолютное значение функции ошибки ничего не показывает. Важно лишь, снижается ли оно в процессе обучения. И разные значения функции ошибки имеет смысл сравнивать только на одних и тех же данных. Что значит, если значение функции ошибки модели равно 35 000? Да ничего, только то, что эта модель хуже, чем та, у которой ошибка 32 000. 

Для того, чтобы значение было более понятно, метрики эффективности зачастую выражаются в каких-то определенных единицах измерения - чеще всего в натуральных или в процентах. Натуральные единицы - это единицы измерения целевой переменной. Допустим, целевая переменная выражается в рублях. То есть, мы предсказываем некоторую стоимость. В таком случае будет вполне понятно, если качество этой модели мы тоже выразим в рублях. Например, так: модель в среднем ошибается на 500 рублей. И сразу становится ясно, насколько эта модель применима на практике.

Еще одно важное отличие. Как мы сказали, требования к функции ошибки определяются алгоритмом оптимизации. Который, в свою очередь зависит от типа модели. У линейной регрессии будет один алгоритм (и одна функция ошибки), а у, например, решающего дерева - другой алгоритм и совершенно другая функция ошибки. Это в частности значит, что функцию ошибки невозможно применять для сравнения нескольких разных моделей, обученных на одной и той же задаче.

И вот для этого как раз и нужны метрики эффективности. Они не зависят от типа модели, а выбираются исходя из задачи и тех вопросов, ответы на которые мы хотим получить. Например, в одной задаче качество модели лучше измерять через среднеквадратическую логарифмическую ошибку, а в другой - через медианную ошибку. Как раз в этом разделе мы посмотрим на примеры разных метрик эффективности, на их особенности и сферы применения.

Кстати, это еще означает, что в каждой конкретной задаче вы можете применять сразу несколько метрик эффективности, для более глубокого понимания работы модели. Зачастую так и поступают, ведь одна метрика не может дать полной информации о сильных и слабых сторонах модели. Тут исследователи ничем не ограничены. А вот функция ошибки обязательно должна быть только одна, ведь нельзя одновременно находить минимум сразу нескольких разных функций (на самом деле можно, но многокритериальная оптимизация - это гораздо сложнее и не используется для обучения моделей).

| Функция ошибки | Метрика эффективности|
|---|---|
| Используется для организации процесса обучения | Используется для оценки качества полученной модели |
| Используется для нахождения оптимума | Используется для сравнения моделей между собой |
| Должна быть быстро вычислимой | Должна быть понятной |
| Должна конструироваться исходя их типа модели | Должна выбираться исходя из задачи |
| Может быть только одна | Может быть несколько |

Еще раз определим, эффективность - это свойство модели машинного обучения давать предсказания значения целевой переменной, как можно ближе к реальным данным. Это самая главная характеристика модели. Но надо помнить, что исходя из задачи и ее условий, к моделям могут предъявляться и другие требования, как сказали бы в программной инженерии - нефункциональные. Типичный пример - скорость работы. Иногда маленький выигрыш в эффективности не стоит того, что модель стала работать в десять раз меньше. Другой пример - интерпретируемость модели. В некоторых областях важно не только сделать точное предсказание, но и иметь возможность обосновать его, провести анализ, выработать рекомендации по улучшению ситуации и так далее. Все эти нефункциональные требования - скорость обучения, скорость предсказания, надежность, робастность, федеративность, интерпретируемость - выходят за рамки данного пособия. Здесь мы сконцентрируемся на измерении именно эффективности модели.

{% capture notice %}
Обратите внимание, что мы старательно избегаем употребления слова "точность" при описании качества работы модели. Хотя казалось бы, оно подходит как нельзя лучше. Дело в том, что "точностью" называют одну из метрик эффективности моделей классификации. Поэтому мы не хотим внести путаницу в термины.
{% endcapture %}
<div class="notice--warning">{{ notice | markdownify }}</div>

Как мы говорили, метрики эффективности не зависят от самого типа модели. Для их вычисления обычно используется два вектора - вектор эмпирических значений целевой переменной (то есть тех, которые даны в датасете) и вектор теоретических значений (то есть тех, которые выдала модель). Естественно, эти вектора должны быть сопоставимы - на соответствующих местах должны быть значения целевой переменной, соответствующие одном у и тому же объекту. И, конечно, у них должна быть одинаковая длина. То есть метрика зависит от самих предсказаний, но не от модели, которая их выдала. Причем, большинство метрик устроены симметрично - если поменять местами эти два вектора, результат не изменится. 

При рассмотрении метрик надо помнить следующее - чем выше эффективность модели, тем лучше. Но некоторые метрики устроены как измерение ошибки модели. В таком случае, конечно, тем ниже, тем лучше. Так что эффективность и ошибка модели - это по сути противоположные понятия. Так сложилось, что метрики регрессии чаще устроены именно как ошибки, а метрики классификации - как метрики именно эффективности. При использовании конкретной метрики на это надо обращать внимание.

{% capture notice %}
Выводы:
1. Метрики эффективности - это способ показать, насколько точно модель отражает реальный мир.
1. Метрики эффективность должны выбираться исходя из задачи, которую решает модель.
1. Функция ошибки и метрика эффективности - это разные вещи, к ним предъявляются разные требования.
1. В задаче можно (и, зачастую, нужно) применять несколько метрик эффективности.
1. Наряду с метриками эффективности есть и другие характеристики моделей - скорость обучения, скорость работы, надежность, робастность, интерпретируемость.
1. Метрики эффективности вычисляются как правило из двух векторов - предсказанных (теоретических) значений целевой переменной и эмпирических (реальных) значений.
1. Обычно метрики устроены таким образом, что чем выше значение, тем модель лучше.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Метрики эффективности для регрессии

Как мы говорили в предыдущем пункте, метрики зависят от конкретной задачи. А все задачи обучения с учителем разделяются на регрессию и классификацию. Совершенно естественно, что метрики для регрессии и для классификации будут разными. 

Метрики эффективности для регрессии оценивают отклонение (расстояние) между предсказанными значениями и реальными. Кажется, что это очевидно, но метрики эффективности классификации устроены по-другому. Предполагается, что чем меньше каждое конкретное отклонение, тем лучше. Разница между разными метриками в том, как учитывать индивидуальные отклонения в общей метрике и в том, как агрегировать ряд значений в один интегральный показатель.

Все метрики эффективности моделей регрессии покажутся вам знакомыми, если вы изучали математическую статистику, ведь именно статистические методы легли в основу измерения эффективности моделей машинного обучения. Причем, метрики эффективности - это лишь самые простые статистические показатели, которые можно использовать для анализа качества модели. При желании можно и нужно задействовать более мощные статистические методы исследования данных. Например, можно проанализировать вид распределения отклонений, и сделать из этого вывод о необходимость корректировки моделей. Но в 99% случаев можно обойтись простым вычислением одной или двух рассматриваемых ниже метрик.

Так как метрики эффективности позволяют интерпретировать оценку качества модели, они зачастую неявно сравнивают данную модель с некоторой тривиальной. Тривиальна модель - это очень простая, даже примитивная модель, которая выдает предсказания оценки целевой переменной абсолютно без оглядки на эффективность и вообще соответствие реальным данным. Тривиальной моделью может выступать, например, предсказание для любого объекта среднего значения целевой переменной из обучающей выборки. Такие тривиальные модели нужны, чтобы оценить, насколько данная модель лучше или хуже них.

Естественно, мы хотим получить модель, которая лучше тривиальной. Причем, у нас есть некоторый идеал - модель, которая никогда не ошибается, то есть чьи предсказания всегда совпадают с реальными значениями. Поэтому реальная модель может быть лучше тривиальной только до этого предела. У такой идеальной модели, говорят, 100% эффективность или нулевая ошибка.

Но надо помнить, что в задачах регрессии модель предсказывает непрерывное значение. Это значит, что величина отклонения может быть неограниченно большой. Так что не бывает нижнего предела качества модели. Модель регрессии может быть бесконечно далекой от идеала, бесконечно хуже даже тривиальной модели. Поэтому ошибки моделей регрессии не ограничиваются сверху (или, что то же самое, эффективность моделей регрессии не ограничивается снизу).

Поэтому в задачах регрессии

{% capture notice %}
Выводы:
1. Метрики эффективности для регрессий обычно анализируют отклонения предсказанных значений от реальных.
1. Большинство метрик пришло в машинное обучение из математической статистики.
1. Результаты работы модели можно исследовать более продвинутыми статистическими методами.
1. Обычно метрики сравнивают данную модель с тривиальной - моделью, которая всегда предсказывает среднее реальное значение целевой переменной.
1. Модель могут быть точны на 100%, но плохи они могут быть без ограничений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Коэффициент детерминации (r-квадрат)

Те, кто раньше хотя бы немного изучал математическую статистику, без труда узнают первую метрику эффективности моделей регрессии. Это так называемый коэффициент детерминации. Это доля дисперсии (вариации) целевой переменной, объясненная данной моделью. Данная метрика вычисляется по такой формуле:

{% capture block %}
$$
R^2(y, \hat{y}) = 1 - \frac
{\sum_{i=1}^n (y_i - \hat{y_i})^2}
{\sum_{i=1}^n (y_i - \bar{y_i})^2}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

где 
$y$ - вектор эмпирических (истинных) значений целевой переменной, 
$\hat{y}$ - вектор теоретических (предсказанных) значений целевой переменной,
$y_i$ - эмпирическое значение целевой переменной для $i$-го объекта,
$\hat{y_i}$ - теоретическое значение целевой переменной для $i$-го объекта,
$\bar{y_i}$ - среднее из эмпирических значений целевой переменной для $i$-го объекта.

Если модель всегда предсказывает идеально (то есть ее предсказания всегда совпадают с реальностью, другими словами, теоретические значения - с эмпирическими), то числитель дроби в формуле будет равен 0, а значит, вся метрика будет равна 1. Если же мы рассмотрим тривиальную модель, которая всегда предсказывает среднее значение, то числитель будет равен знаменателю, дробь будет равна 1, а метрика - 0. Если модель хуже идеальной, но лучше тривиальной, то метрика будет в диапазоне от 0 до 1, причем чем ближе к 1 - тем лучше.

Если же модель предсказывает такие значения, что отклонения их от теоретических получаются больше, чем от среднего значения, то числитель будет больше знаменателя, а значит, что метрика будет принимать отрицательные значения. Запомните, что отрицательные значения коэффициента детерминации означают, что модель хуже, чем тривиальная.

В целом эта метрика показывает силу линейной связи между двумя случайными величинами. В нашем случае этими величинами выступают теоретические и эмпирические значения целевой переменной (то есть предсказанные и реальные). Если модель дает точные предсказания, то будет наблюдаться сильная связь (зависимость) между теоретическим значением и реальным, то есть высокая детерминация, близкая к 1. Если эе модель дает случайные предсказания, никак не связанные с реальными значениями, то связь будет отсутствовать.

Причем так как нас интересует, насколько значения совпадают, нам достаточно использовать именно линейную связь. Ведь когда мы оцениваем связь, например, одного из факторов в целевой переменной, то связь может быть нелинейной, и линейный коэффициент детерминации ее не покажет, то есть пропустит. Но в данному случае это не важно, так как наличие нелинейной связи означает, что предсказанные значения все-таки отклоняются от реальных. Такую линейную связь можно увидеть на графике, если построить диаграмму рассеяния между теоретическими и эмпирическими значениями, вот так:

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression().fit(X, Y)
Y_ = reg.predict(X)

plt.scatter(Y, Y_)
plt.plot(Y, Y)
```

Здесь мы еще строим прямую $y = y$. Она нужна только для удобства. Вот как может выглядеть этот график:

![](/assets/images/ml_text/ml4-15.png "Зависимость в целевой переменной"){: .align-center style="width: 50%;"}

Здесь мы видим, что точки немного отклоняются от центральной линии, но в целом ей следуют. Такая картина характерна для высокого коэффициента детерминации. А вот как может выглядеть менее точная модель:

![](/assets/images/ml_text/ml4-16.png "Зависимость в целевой переменной"){: .align-center style="width: 50%;"}

И в целом, чем точки ближе к центральной линии, тем лучше модель и тем ближе коэффициент детерминации к 1.

В англоязычной литература эта метрика называется $R^2$, так как в определенных случаях она равна квадрату коэффициента корреляции. Пусть это название не вводит вас в заблуждение. Некоторые думаю, что раз метрика в квадрате, то она не может быть отрицательной. Это лишь условное название.

Пару слов об использовании метрик эффективности в библиотеке _sklearn_. Именно коэффициент детерминации чаще всего используется как метрика по умолчанию, которую можно посмотреть при помощи метода _score()_ у модели регрессии. Обратите внимание, что этот метод принимает на вход саму обучающую выборку. Это сделано для единообразия с методами наподобие _fit()_. 

Но более универсально будет использовать эту метрику независимо от модели. Все метрики эффективности собраны в отдельный пакет _metrics_. Данная метрика называется _r2_score_. Обратите внимание, что при использовании этой функции ей надо передавать два вектора целевой переменной - сначала эмпирический, а вторым аргументом - теоретический.

```py
from sklearn.metrics import r2_score

def r2(y, y_):
  return 1 - ((y - y_)**2).sum() / ((y - y.mean())**2).sum()

print(reg.score(X, Y))
print(r2_score(Y, Y_))
print(r2(Y, Y_))
```

В данном коде мы еще реализовали самостоятельный расчет данной метрики, чтобы пояснить применение формулы выше. Можете самостоятельно убедиться, что три этих вызова напечатают одинаковые значения.

Коэффициент детерминации, или $R^2$ - это одна из немногих метрик эффективности для моделей регрессии, значение которой чем больше, тем лучше. Почти все остальные измеряют именно ошибку, что мы и увидим ниже. Еще это одна из немногих несимметричных метрик. Ведь если в формуле поменять теоретические и эмпирические значения, ее смысл и значение могут поменяться. Поэтому при использовании этой метрики нужно обязательно следить за порядком передачи аргументов.

При использовании этой метрики есть один небольшой подводный камень. Так как в знаменатели у этой формулы стоит вариация реального значения целевой переменной, важно следить, чтобы эта вариация присутствовала. Ведь если реальное значение целевой переменной будет одинаковым для всех объектов выборки, то вариация этой переменной будет равна 0. А значит, метрика будет не определена. Причем это единственная причина, почему эта метрика может быть неопределена. Надо понимать, что отсутствие вариации целевой переменной ставит под сомнение вообще целесообразность машинного обучения и моделирования в целом. Ведь что нам предсказывать если $y$ всегда один и тот же? С другой стороны, такая ситуация может случиться, например, при случайном разбиении выборки на обучающую и тестовую. Но об этом мы поговорим дальше.

{% capture notice %}
Выводы:
1. Коэффициент детерминации показывает силу связи между двумя случайными величинами.
1. Если модель всегда предсказывает точно, метрика равна 1. Для тривиальной модели - 0.
1. Значение метрики может быть отрицательно, если модель предсказывает хуже, чем тривиальная.
1. Это одна из немногих несимметричных метрик эффективности.
1. Эта метрика не определена, если $y=const$. Надо следить, чтобы в выборке присутствовали разные значения целевой переменной.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Средняя абсолютная ошибка (MAE)

Коэффициент детерминации - не единственная возможная характеристика эффективности моделей регрессии. Иногда полезно оценить отклонения предсказаний от истинных значений более явно. Как раз для этого служат сразу несколько метрик ошибок моделей регрессии. Самая простая из них - средняя абсолютная ошибка (mean absolute error, MAE). Она вычисляется по формуле:

{% capture block %}
$$
MAE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1} |y_i - \hat{y_i}|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Данная метрика действительно очень проста: это средняя величина разницы между предсказанными и реальными значениями целевой переменной. Причем эта разница берется по модулю, чтобы компенсировать возможные отрицательные отклонения. Мы уже рассматривали похожую функцию, когда говорили о конструировании функции ошибки для градиентного спуска. Но тогда мы отмели использование абсолютного значения, так как эта функция не везде дифференцируема. Но вот для метрики эффективности такого требования нет и MAE вполне можно использовать.

Если модель предсказывает идеально, то, естественно, все отклонения равны 0 и MAE в целом равна нулю. Но эта метрика не учитывает явно сравнение с тривиальной моделью - она просто тем хуже, чем больше. Ниже нуля она быть, конечно, не может.

Данная метрика выражается в натуральных единицах и имеет очень простой и понятный смысл - средняя ошибка модели. Степень применимости модели в таком случае можно очень просто понять исходя из предметной области. Например, наша модель ошибается в среднем на 500 рублей. Хорошо это или плохо? Зависит от размерности исходных данных. Если мы предсказываем цены на недвижимость - то модель прекрасно справляется с задачей. Если же мы моделируем цены на спички - то такая модель скорее всего очень неэффективна.

Использование данной метрики в пакете _sklearn_ очень похоже на любую другую метрику, меняется только название:

```py
>>> from sklearn.metrics import mean_absolute_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_absolute_error(y_true, y_pred)
0.5
```

{% capture notice %}
Выводы:
1. MAE показывает среднее абсолютное отклонение предсказанных значений от реальных.
1. Чем выше значение MAE, тем модель хуже. У идеальной модели $MAE=0$
1. MAE очень легко интерпретировать - на сколько в среднем ошибается модель.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Средний квадрат ошибки (MSE)

Средний квадрат ошибки (mean squared error, MSE) очень похож на предыдущую метрику, но вместо абсолютного значения (модуля) используется квадрат:

{% capture block %}
$$
MSE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1} (y_i - \hat{y_i})^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Граничные случаи у этой метрики такие же, как у предыдущей - 0 у идеальной модели, а в остальном - чем больше, тем хуже. MSE у тривиальной модели будет равна дисперсии целевой переменной. Но это не то, чтобы очень полезно на практике.

Эта метрика используется во многих моделях регрессии как функция ошибки. Но вот как метрику эффективности ее применяют довольно редко. Дело в ее интерпретируемости. Ведь она измеряется в квадратах натуральной величины. А какой физический смысл имеют, например, рубли в квадрате? На самом деле никакого. Поэтому несмотря на то, что математически MAE и MSE в общем-то эквивалентны, первая более проста и понятна, и используется гораздо чаще.

Единственное существенное отличие данной метрики от предыдущей состоит в том, что она чуть больший "вес" в общей ошибке придает большим значениям отклонений. То есть чем больше значение отклонения, тем сильнее оно будет вкладываться в значение MSE. Это иногда бывает полезно, когда исходя из задачи стоит штрафовать сильные отклонения предсказанных значений от реальных. Но с другой стороны это свойство делает эту метрику чувствительной к аномалиям.

Пример расчета метрики MSE:

```py
>>> from sklearn.metrics import mean_squared_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_squared_error(y_true, y_pred, squared=False)
0.612...
```

{% capture notice %}
Выводы:
1. MAE показывает средний квадрат отклонений предсказанных значений от реальных.
1. Чем выше значение MSE, тем модель хуже. У идеальной модели $MSE=0$
1. MSE больше учитывает сильные отклонения, но хуже интерпретируется, чем MAE.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Среднеквадратичная ошибка (RMSE)

Если главная проблема метрики MSE в том, что она измеряется в квадратах натуральных величин, что что будет, если мы возьмем от нее квадратный корень? Тогда мы получим среднеквадратичную ошибку (root mean squared error, RMSE):

{% capture block %}
$$
RMSE(y, _\hat{y}) = \sqrt{\frac{1}{n} \sum_{i=0}^{n-1} (y_i - \hat{y_i})^2}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Использование данной метрики достаточно привычно при статистическом анализе данных. Однако, для интерпретации результатов машинного обучения она имеет те же недостатки, что и MSE. Главный из них - чувствительность к аномалиям. Поэтому при интерпретации эффективности моделей регрессии чаще рекомендуется применять метрику MAE.

Пример использования:

```py
>>> from sklearn.metrics import mean_squared_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_squared_error(y_true, y_pred)
0.375
```

{% capture notice %}
Выводы:
1. RMSE - это по сути корень из MSE. Выражается в тех же единицах, что и целевая переменная.
1. Чаще применяется при статистическом анализа данных.
1. Данная метрика очень чувствительна к аномалиям и выбросам.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Среднеквадратичная логарифмическая ошибка (MSLE)

Еще одна довольно редкая метрика - среднеквадратическая логарифмическая ошибка (mean squared logarithmic error, MSLE). Она очень похожа на MSE, но квадрат вычисляется не от самих отклонений, а от разницы логарифмов (про то, зачем там +1 поговорим позднее):

{% capture block %}
$$
MSLE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1} (
ln(1 + y_i) - ln(1 + \hat{y_i})
)^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Данная материка имеет специфическую, но довольно полезную сферу применения. Она применяется в тех случаях, когда значения целевой переменной простираются на несколько порядков величины. Например, если мы анализируем доходы физических лиц, они могут измеряться от тысяч до сотен миллионов. Понятно, что при использовании более привычных метрик, таких как MSE, RMSE и даже MAE, отклонения в больших значениях, даже небольшие относительно, будут полностью доминировать над отклонениями в малых значениях. 

Это приведет к тому, что оценка моделей в подобных задачах классическими метриками будет давать преимущество моделям, которые более точны в одной части выборки, но почти не будут учитывать ошибки в других частях выборки. Это может привести к несправедливой оценке моделей. А вот использование логарифма поможет сгладить это противоречие.

Чаще всего, величины с таким больших размахом, что имеет смысл использовать логарифмическую ошибку, возникают в тех задачах, которые моделируют некоторые естественные процессы, характеризующиеся экспоненциальным ростом. Например, моделирование популяций, эпидемий, финансов. Такие процессы часто порождают величины, распределенные по экспоненциальному закону. А они чаще всего имеют область значений от нуля до плюс бесконечности, то есть иногда могут обращаться в ноль.

Проблема в том, что логарифм от нуля не определен. Именно поэтому в формуле данной метрики присутствует +1. Это искусственный способ избежать неопределенности. Конечно, если вы имеете дело с величиной, которая может принимать значение -1, то у вас опять будут проблемы. Но на практике такие особые распределения не встречаются почти никогда. 

Использование данной метрике в коде полностью аналогично другим:

```py
>>> from sklearn.metrics import mean_squared_log_error
>>> y_true = [3, 5, 2.5, 7]
>>> y_pred = [2.5, 5, 4, 8]
>>> mean_squared_log_error(y_true, y_pred)
0.039...
```

{% capture notice %}
Выводы:
1. MSLE это среднее отклонение логарифмов реальных и предсказанных данных.
1. Так же, идеальная модель имеет $MSLE = 0$.
1. Данная метрика используется, когда целевая переменная простирается на несколько порядков величины.
1. Еще эта метрика может быть полезна, если моделируется процесс в экспоненциальным ростом.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Среднее процентное отклонение (MAPE)

Все метрики, которые мы рассматривали до этого рассчитывали абсолютную величину отклонения. Но ведь отклонение в 5 единиц при истинном значении 5 и при значении в 100 - разные вещи. В первом случае мы имеем ошибку в 100%, а во втором - только в 5%. Очевидно, что первый и второй случай должны по-разному учитываться в ошибке. Для этого придумана средняя абсолютная процентная ошибка (mean absolute percentage error, MAPE). В ней каждое отклонение оценивается в процентах от истинного значения целевой переменной:

{% capture block %}
$$
MAPE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1}
\frac{|y_i - \hat{y_i}|}{max(\epsilon, |y_i|)}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Эта метрика имеет одно критическое преимущество над остальными - с ее помощью можно сравнивать эффективность моделей на разных обучающих выборках. Ведь если мы возьмем классические метрики (например, MAE), то размер отклонений будет очевидно зависеть от самих данных. А в двух разных выборках и средняя величина скорее всего будет разная. Поэтому метрики MAE, MSE, RMSE, MSLE не сопоставимы при сравнении предсказаний, сделанных на разных выборках.

А вот по метрике MAPE можно сравнивать разные модели, которые были обучены на разных данных. Это очень полезно, например, в научных публикациях, где метрика MAPE (и ее вариации) практически обязательны для описания эффективности моделей регрессии.Ведь если одна модель ошибается в среднем на 3,9%, а другая - на 3,5%, очевидно, что вторая более точна. А вот если оперировать той же MAE, так сказать нельзя. Ведь если одна модель ошибается в среднем на 500 рублей, а вторая - на 490, очевидно ли, что вторая лучше? Может, она даже хуже, просто в исходных данных величина целевой переменной во втором случае была чуть меньше.

При этом у метрики MAPE есть пара недостатков. Во-первых, она не определена, если истинное значение целевой переменной равно 0. Именно для преодоления этого в знаменателе формулы этой метрики присутствует $max(\epsilon, \|y_i\|)$. $\epsilon$ - это некоторое очень маленькое значение. Оно нужно только для того, чтобы избежать деления на ноль. Это, конечно, настоящий математический костыль, но позволяет без опаски применять эту метрику на практике.

Во-вторых, данная метрика дает преимущество более низким предсказаниям. Ведь если предсказание ниже, чем реальное значение, процентное отклонение может быть от 0% до 100%. В это же время если предсказание выше реального, то верхней границы нет, предсказание может быть больше и на 200%, и на 1000%.

В-третьих, эта метрика несимметрична. Ведь в этой формуле $y$ и $\hat{y}$ не взаимозаменяемы. Это не большая проблема и может быть исправлена использованием симметричного варианта этой метрики, который называется SMAPE (symmetric mean absolute percentage error):

{% capture block %}
$$
MAPE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1}
\frac{|y_i - \hat{y_i}|}{max(\epsilon, (|\hat{y_i}|, |y_i|) / 2)}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В русскоязычной литературе данная метрика часто называется относительной ошибкой, так как она учитывает отклонение относительно целевого значения. В английском названии метрики она называется абсолютной. Тут нет никакого противоречия, так как "абсолютный" здесь значит просто взятие по модулю.

С точки зрения использования в коде, все полностью аналогично:

```py
>>> from sklearn.metrics import mean_absolute_percentage_error
>>> y_true = [1, 10, 1e6]
>>> y_pred = [0.9, 15, 1.2e6]
>>> mean_absolute_percentage_error(y_true, y_pred)
0.2666...
```

{% capture notice %}
Выводы:
1. Идея этой метрики - это чувствительность к относительным отклонениям.
1. Данная модель выражается в процентах и имеет хорошую интерпретируемость.
1. Идеальная модель имеет $MAPE = 0$. Верхний предел - не ограничен.
1. Данная метрика отдает предпочтение предсказанию меньших значений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Абсолютная медианная ошибка

Практически во всех ранее рассмотренных метриках используется среднее арифметическое для агрегации частных отклонений в общую величину ошибки. Иногда это может быть не очень уместно, если в выборке присутствует очень неравномерное распределение по целевой переменной. В таких случаях может быть целесообразно использование медианной ошибки:

{% capture block %}
$$
MedAE(y, _\hat{y}) = \frac{1}{n} median_{i=0}^{n-1}
|y_i - \hat{y_i}|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Эта метрика полностью аналогична MAE за одним исключением: вместо среднего арифметического подсчитывается медианное значение. Медиана - это такое значение в выборке, больше которого и меньше которого примерно половина объектов выборки (с точностью до одного объекта).

Эта метрика чаще всего применяется при анализе демографических и экономических данных. Ее особенность в том, что она не так чувствительна к выбросам и аномальным значениям, ведь они практически не влияют на медианное значение выборки, что делает эту метрику более надежной и робастной, чем абсолютная ошибка.

Пример использования:

```py
>>> from sklearn.metrics import median_absolute_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> median_absolute_error(y_true, y_pred)
0.5
```

{% capture notice %}
Выводы:
1. Медианная абсолютная ошибка похожа на среднюю абсолютную, но более устойчива к аномалиям.
1. Применяется в задачах, когда известно, что в данных присутствуют выбросы, аномальные , непоказательные значения.
1. Эта метрика более робастная, нежели MAE. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Максимальная ошибка

Еще одна достаточно экзотическая, но очень простая метрика эффективности регрессии - максимальная ошибка:

{% capture block %}
$$
ME(y, _\hat{y}) = max_{i=0}^{n-1}
|y_i - \hat{y_i}|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Как следует из названия, это просто величина максимального абсолютного отклонения предсказанных значений от теоретических. Особенность этой метрики в том, что она вообще не характеризует распределение отклонений в целом. Поэтому она практически никогда не применяется самостоятельно, в качестве единственной метрики.

Эта метрика именно вспомогательная. В сочетании с другими метриками, она может дополнительно охарактеризовать, насколько сильно модель может ошибаться в самом худшем случае. Опять же, в зависимости от задачи, это может быть важно. В некоторых задачах модель, которая в среднем ошибается пусть чуть больше, но при этом не допускает очень больших "промахов", может быть предпочтительнее, чем более точная модель в среднем, но у которой встречаются сильные отклонения.

Применение этой метрики та же просто, как и других:

```py
>>> from sklearn.metrics import max_error
>>> y_true = [3, 2, 7, 1]
>>> y_pred = [9, 2, 7, 1]
>>> max_error(y_true, y_pred)
6
```

{% capture notice %}
Выводы:
1. Максимальная ошибка показывает наихудший случай предсказания модели.
1. В некоторых задачах важно, чтобы модель не ошибалась сильно, а небольшие отклонения не критичны.
1. Зачастую эта метрика используется как вспомогательная совместно с другими.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Метрики эффективности для классификации

Приступим к рассмотрению метрик эффективности, которые применяются для оценки моделей классификации. Для начала ответим на вопрос, почему для них нельзя использовать те метрики, которые мы уже рассмотрели в предыдущей части? Дело в том, что метрики эффективности регрессии так или иначе оценивают расстояние от предсказанного значения до реального. Это подразумевает, что в значениях целевой переменной существует определенный порядок. Формально говоря, предполагается, что целевая переменная измеряется по относительной шкале. Это значит, что разница между значениями имеет какой-то смысл. Например, если мы ошиблись в предполагаемой цене товара на 10 рублей, это лучше, чем ошибка на 20 рублей. Причем, можно сказать, что это в два раза лучше. 

Но вот целевые переменные, которые существуют в задачах классификации обычно не обладают таким свойством. Да, метки классов часто обозначают числами (класс 0, класс 1, класс 5 и так далее). И мы используем эти числа в качестве значения переменных в программе. Но это ничего не значит. Представим объект, принадлежащий 0 классу, что бы этот класс не значил. Допустим, мы предсказали 1 класс. Было бы хуже, если бы мы предсказали 2 класс. Можно ли сказать, что во втором случае модель ошиблась в два раза сильнее? В общем случае, нельзя. Что в первом, что во втором случае модель просто ошиблась. Имеет значение только разница между правильным предсказанием и неправильным. Отклонение в задачах классификации не играет роли.

Поэтому метрики эффективности для классификации оценивают количество правильно и неправильно классифицированных (иногда еще говорят, распознанных) объектов. При этом разные метрики, как мы увидим, концентрируются на разных соотношениях этих количеств, особенно в случае, когда классов больше двух, то есть имеет место задача множественной классификации.

Причем метрики эффективности классификации тоже нельзя применять для оценки регрессионных моделей. Дело в том, что в задачах регрессии почти никогда не встречается полное совпадение предсказанного и реального значения. Так как мы работам с непрерывным континуумом значений, вероятность такого совпадения равна, буквально, нулю. Поэтому по метрикам для классификации практически любая регрессионная модель будет иметь нулевую эффективность, даже очень хорошая и точная модель. Именно потому, что для метрик классификации даже самая небольшая ошибка уже считается как промах.

Как мы говорили ранее,для оценки конкретной модели можно использовать несколько метрик одновременно. Это хорошая практика для задач регрессии, но для классификации - это практически необходимость. Дело в том, что метрики классификации гораздо легче "обмануть" с помощью тривиальных моделей, особенно в случае несбалансированных классов (об этом мы поговорим чуть позже). Тривиальной моделью в задачах классификации может выступать модель, которая предсказывает случайный класс (такая используется чаще всего), либо которая предсказывает всегда какой-то определенный класс.

Надо обратить внимание, что по многим метрикам, ожидаемая эффективность моделей классификации сильно зависит от количества классов в задаче. Чем больше классов, тем на меньшую эффективность в среднем можно рассчитывать.Поэтому метрики эффективности классификации не позволяют сопоставить задачи, состоящие из разного количества классов. Это следует помнить при анализе моделей. Если точность бинарной классификации составляет 50%, это значит, что модель работает не лучше случайного угадывания. Но в модели множественной классификации из, допустим, 10 000 классов, точность 50% - это существенно лучше случайного гадания.

Еще обратим внимание, что некоторые метрики учитывают только само предсказание, в то время, как другие - степень уверенности модели в предсказании. Вообще, все модели классификации разделяются на логические и метрические. Логические методы классификации выдают конкретное значение класса, без дополнительной информации. Типичные примеры - дерево решений, метод ближайших соседей. Метрические же методы выдают степень уверенности (принадлежности) объекта к одному или, чаще, ко всем классам. Так, например, работает метод логистической регрессии в сочетании с алгоритмом "один против всех". Так вот, в зависимости, от того, какую модель классификации вы используете, вам могут быть доступны разные метрики. Те метрики, которые оценивают эффективность классификации в зависимости от выбранной величины порога не могут работать с логическими методами. Поэтому, например, нет смысла строить PR-кривую для метода ближайших соседей. Остальные метрики, которые не используют порог, могут работать с любыми методами классификации.

{% capture notice %}
Выводы:
1. Метрики эффективности классификации подсчитывают количество правильно распознанных объектов.
1. В задачах классификации почти всегда надо применять несколько метрик одновременно.
1. Тривиальной моделью в задачах классификации считается та, которая предсказывает случайный класс, либо самый популярный класс.
1. Качество бинарной классификации при прочих равных почти всегда будет сильно выше, чем для множественной.
1. Вообще, чем больше в задаче классов, тем ниже ожидаемые значения эффективности.
1. Некоторые метрики работают с метрическими методами, другие - со всеми.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Доля правильных ответов (accuracy)

Если попробовать самостоятельно придумать способ оценить качество модели классификации, ничего не зная о существующих метриках, скорее всего получится именно метрика точности (accuracy). Это самая простая и естественная метрика эффективности классификации. Она подсчитывается как количество объектов в выборке, которые были классифицированы правильно (то есть, для которых теоретическое и эмпирическое значение метки класса - целевой переменной - совпадает), разделенное на общее количество объектов выборки. Вот формула для вычисления точности классификации:

{% capture block %}
$$ 
acc(y, \hat{y}) = \frac{1}{n} \sum_{i=0}^{n} 1(\hat{y_i} = y_i) 
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В этой формуле используется так называемая индикаторная функция $1()$. Эта функция равна 1 тогда, когда ее аргумент - истинное выражение, и 0 - если ложное. В данном случае она равна единице для всех объектов, у которых предсказанное значение равно реальному ($\hat{y_i} = y_i$). Суммируя по всем объектам мы получим количество объектов, классифицированных верно. Перед суммой стоит множитель $\frac{1}{n}$, где $n$ - количество объектов в выборке. То есть в итоге мы получаем долю правильных ответов исследуемой модели.

Значение данной метрики может быть выражено в долях единицы, либо в процентах, домножив значение на 100%. Чем выше значение accuracy, тем лучше модель классифицирует выборку, то есть тем лучше ответы модели соответствуют значениям целевой переменной, присутствующим в выборке. Если модель всегда дает правильные предсказания, то ее accuracy будет равн 1 (или 100%). Худшая модель, которая всегда предсказывает неверно будет иметь accuracy, равную нулю, причем это нижняя граница, хуже быть не может.

{% capture notice %}
В дальнейшем, для обозначения названий метрик эффективности я буду использовать именно английские названия - accuracy, precision, recall. У каждого из этих слов есть перевод на русский, но так случилось, что в русскоязычных терминах существует путаница. Дело в том, что и accuracy и precision чаще всего переводятся словом "точность". А это разные метрики, имеющие разный смысл и разные формулы. Accuracy еще называют "правильность", precision - "прецизионность". Причем у последнего термина есть несколько другое значение в метрологии. Поэтому, пока будем обозначать эти метрики изначальными названиями.
{% endcapture %}
<div class="notice--warning">{{ notice | markdownify }}</div>

А вот accuracy тривиальной модели будет как раз зависеть от количества классов. Если мы имеем дело с бинарной классификацией, то модель будет ошибаться примерно в половине случаев. То есть ее accuracy будет 0,5. В общем же случае, если есть $m$ классов, то тривиальная модель, которая предсказывает случайный класс будет иметь accuracy в среднем около $\frac{1}{m}$.

Но это в случае, если в выборке объекты разных классов встречаются примерно поровну. В реальности же часто встречаются несбалансированные выборки, в которых распределение объектов по классам очень неравномерно. Например, может быть такое, что объектов одного класса в десять раз больше, чем другого. В таком случае, accuracy тривиальной модели может быть как выше, так и ниже $1/m$. Вообще, метрика accuracy очень чувствительна к соотношению классов в выборке. И именно поэтому мы рассматриваем другие способы оценки качества моделей классификации.

Использование метрики accuracy в библиотеке _sklearn_ ничем принципиальным не отличается от использования других численных метрик эффективности:

```py
>>> import numpy as np
>>> from sklearn.metrics import accuracy_score
>>> y_pred = [0, 2, 1, 3]
>>> y_true = [0, 1, 2, 3]
>>> accuracy_score(y_true, y_pred)
0.5
```

В данном примере в задаче 4 класса (0, 1, 2, 3) и столько же объектов, по одному на каждый класс. Модель правильно классифицировала первый и третий объект, то есть половину. Поэтому ее accuracy составляет 0,5 или 50%.

{% capture notice %}
Выводы:
1. Точность (accuracy) - самая простая метрика качества классификации, доля правильных ответов.
1. Может быть выражена в процентах и в долях единицы.
1. Идеальная модель дает точность 1.0, тривиальная - 0.5, самая худшая - 0.0.
1. Тривиальная модель в множественной сбалансированной задаче классификации дает точность 1/m.
1. Метрика точности очень чувствительная к несбалансированности классов.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Матрица классификации

```py
>>> from sklearn.metrics import confusion_matrix
>>> y_true = [2, 0, 2, 2, 0, 1]
>>> y_pred = [0, 0, 2, 2, 0, 2]
>>> confusion_matrix(y_true, y_pred)
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])
```

![Classification matrix](https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png "Classification matrix"){: .align-center style="width: 800px;"}
Источник: [sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. Матрица классификации, или матрица ошибок представляет собой количество объектов по двум осям - истинный класс и предсказанный класс.
1. Обычно, истинный класс располагается по строкам, а предсказанный - по столбцам.
1. Для идеальной модели матрица должна содержать ненулевые элементы только на главной диагонали.
1. Матрица позволяет наглядно представить результаты классификации и увидеть, в каких случаях модель делает ошибки.
1. Матрица незаменима при анализе ошибок, когда исследуется, какие объекты были неправильно классифицированы.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Метрики классификации для неравных классов (precision, recall, F1)

Как мы говорили ранее, метрика accuracy может быть чувствительна к несбалансированности классов. Рассмотрим типичный пример - диагностика заболевания. Допустим, в случайной выборке людей заболевание встречается один раз на 100 человек. То есть в выборке у нас может быть всего 1% объектов, принадлежащих положительному классу и 99% - отрицательному, то есть почти в 100 раз больше. Какая accuracy будет у абсолютно тривиальной модели, которая всегда предсказывает отрицательный класс? Такая модель будет права в 99% случаев и ошибаться только в 1%. То есть иметь accuracy 0,99. Естественно, ценность такой модели минимальна, несмотря на высокий показатель метрики. Поэтому в случае с сильно несбалансированными классами метрика accuracy не то, чтобы неверна, она непоказательна, то есть не дает хорошего представления о качественных характеристиках модели. 

Для более полного описания модели используется ряд других метрик. Для того, чтобы понять, как они устроены и что показывают нужно разобраться с понятием ошибок первого и второго рода. Пока будем рассматривать случай бинарной классификации, а о том, как эти метрики обобщаются на множественные задачи, поговорим позднее. Итак, у нас есть задача бинарной классификации, объекты положительного и отрицательного класса. Идеальным примером для этого будет все та же медицинская диагностика.

По отношению к модели бинарной классификации все объекты выборки можно разделить на четыре непересекающихся множества. Истинноположительные (true positive, TP) - это те объекты, которые отнесены моделью к положительному классу и действительно ему принадлежат. Истинноотрицательные (true negative, TN) - соответственно те, которые правильно распознаны моделью как принадлежащие отрицательному классу. Ложноположительные объекты (FP, false positive) - это те, которые модель распознала как положительные, хотя на самом деле они отрицательные. В математической статистике такая ситуация называется ошибкой первого рода. И, наконец, ложноотрицательные значения (false negative, FN) - это те, которые ошибочно отнесены моделью к отрицательному классу, хотя на самом деле они принадлежат положительному.

В примере с медицинско диагностикой, ложноположительные объекты или ошибки первого рода - это здоровые пациенты, которых при диагностике ошибочно назвали больными. Ложноотрицательные, или ошибки второго рода, - это больные пациенты, которых диагностическая модель "пропустила", ошибочно приняв за здоровых. Очевидно, что в этой задаче, как и во многих других, ошибки первого и второго рода не равнозначны. В медицинской диагностике, например, гораздо важнее распознать всех здоровых пациентов, то есть не допустить ложноотрицательных объектов или ошибок второго рода. Ошибки же первого рода, или ложноположительные предсказания, тоже нежелательны, но значительно меньше, чем ложноотрицательные.

Так вот, метрика accuracy учитывает и те и другие ошибки одинаково, абсолютно симметрично. В терминах наших четырех классов она может выражаться такой формулой:

$$
A = \frac{TP + TN}{TP + TN + FP + FN}
$$

Обратите внимание, что если в модели переименовать положительный класс в отрицательный и наоборот, то это никак не повлияет на accuracy. Так вот, в зависимости от решаемой задачи, нам может быть необходимо воспользоваться другими метриками. Вообще, их существует большое количество, но на практике чаще других применяются метрики precision и recall.

Precision (чаще переводится как "точность", "прецизионность") - это доля объектов, плавильно распознанных как положительные из всех, распознанных как положительные. Считается этот показатель по следующей формуле: $P = \frac{TP}{TP + FP}$. Как можно видеть, precision будет равен 1, если модель не делает ошибок первого рода, то есть не дает ложноположительных предсказаний. Причем ошибки второго рода (ложноотрицательные) вообще не влияют на величину precision, так как эта метрика рассматривает только объекты, отнесенные моделью к положительным.

Precision характеризует способность модели отличать положительный класс от отрицательного, не делать ложноположительных предсказаний. Ведь если мы будем всегда предсказывать отрицательный класс, precision будет не определен. А вот если модель будет всегда предсказывать положительный класс, то precision будет равен доли объектов этого класса в выборке. В нашем примере с медицинской диагностикой, модель, всех пациентов записывающая в больные даст precision всего 0,01.

Метрика recall (обычно переводится как "полнота" или "правильность") - это доля положительных объектов выборки, распознанных моделью. То есть это отношение все тех же истинноположительных объектов к числу всех положительных объектов выборки: $R = \frac{TP}{TP + FN}$. Recall будет равен 1 только в том случае, если модель не делает ошибок второго рода, то есть не дает ложноотрицательных предсказаний. А вот ошибки первого рода (ложноположительные) не влияют на эту метрику, так как она рассматривает только объекты, которые на самом деле принадлежат положительному классу. 

Recall характеризует способность модели обнаруживать все объекты положительного класса. Если мы будем всегда предсказывать отрицательный класс, то данная метрика будет равна 0, а если всегда положительный - то 1. Метрика Recall еще называется полнотой, так как она характеризует полноту распознавания положительного класса моделью.

В примере с медицинской диагностикой нам гораздо важнее, как мы говорили, не делать ложноотрицательных предсказаний. Поэтому метрика recall будет для нас важнее, чем precision и даже accuracy. Однако, как видно из примеров, каждый из этих метрик легко можно максимизировать довольно тривиальной моделью. Если мы будет ориентироваться на recall, то наилучшей моделью будет считаться та, которая всегда предсказывает положительный класс. Если только на precision - то "выиграет" модель, которая всегда предсказывает наоборот, положительный. А если брать в расчет только accuracy, то при сильно несбалансированных классах модель, предсказывающая самый популярный класс. Поэтому эти метрики нелья использовать по отдельности, только сразу как минимум две из них. 

![PR_F1](/assets/images/ml_text/ml4-1.png "PR_F1"){: .align-center style="width: 800px;"}

Так как метрики precision и recall почти всегда используются совместно, часто возникает ситуация, когда есть две модели, у одной из которых выше precision, а у второй - recall. Возникает вопрос, как выбрать лучшую? Для такого случая можно посчитать среднее значение. Но для этих метрик больше подойдет среднее не арифметическое, а гармоническое, ведь оно равно 0, если хотя бы одно число равно 0. Эта метрика называется $F_1$:

{% capture block %}
$$ F_1 = \frac{2 P R}{P + R} = \frac{2 TP}{2 TP + FP + FN} $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Эта метрика полезна, если нужно одно число, которое в себе объединяет и precision и recall. Но эта формула подразумевает, что нам одинаково важны и то и другое. А как мы заметили раньше, часто одна из этих метрик важнее. Поэтому иногда используют обобщение метрики $F_1$, так называемое семейство F-метрик:

{% capture block %}
$$ F_{\beta}  = (1 + \beta^2) \frac{P R}{\beta^2 P + R} $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Эта метрика имеет параметр $\beta > 0$, который определяет, во сколько раз recall важнее precision. Если этот параметр больше единицы, то метрика будет полагать recall более важным. А если меньше - то важнее будет precision. Если же $\beta = 1$, то мы получим уже известную нам метрику $F_1$. Все метрики из F-семейства измеряются от 0 до 1, причем чем значение больше, тем модель лучше.

```py
>>> from sklearn import metrics
>>> y_pred = [0, 1, 0, 0]
>>> y_true = [0, 1, 0, 1]
>>> metrics.precision_score(y_true, y_pred)
1.0
>>> metrics.recall_score(y_true, y_pred)
0.5
>>> metrics.f1_score(y_true, y_pred)
0.66...
```

{% capture notice %}
Выводы:
1. Если классы в задаче не сбалансированы, то метрика точности не дает полного представления о качестве работы моделей.
1. Для бинарной классификации подсчитывается количество истинно положительных, истинно отрицательных, ложно положительных и ложно отрицательных объектов.
1. Precision - доля истинно положительных объектов во всех, распознанных как положительные.
1. Precision характеризует способность модели не помечать положительные объекты как отрицательные (не делать ложно положительных прогнозов).
1. Recall - для истинно положительных объектов во всех положительных.
1. Recall характеризует способность модели выявлять все положительные объекты (не делать ложно отрицательных прогнозов).
1. F1 - среднее гармоническое между этими двумя метриками. F1 - это частный случай. Вообще, семейство F-метрик - это взвешенное среднее гармоническое.
1. Часто используют все вместе для более полной характеристики модели.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>


#### Метрики множественной классификации

Все метрики, о которых мы говорили выше рассчитываются в случае бинарной классификации, так как определяются через понятия ложноположительных, ложноотрицательных прогнозов. Но на практике чаще встречаются задачи множественной классификации. В них не определяется один положительный и один отрицательный класс, поэтому все рассуждения о precision и recall, казалось бы, не имеют смысла. 

На самом деле, все рассмотренные метрики прекрасно обобщаются на случай множественных классов. Рассмотрим простой пример. У нас есть три класса - 0, 1 и 2. Есть пять объектов, каждый их которых принадлежит одному их этих трех классов. Истинные значения целевой переменной такие: $y = \lbrace 0, 1, 2, 2, 0 \rbrace$. Имеется модель, которая предсказывает классы этих объектов, соответственно так: $\hat{y} = \lbrace 0, 0, 2, 1, 0 \rbrace$. Давайте рассчитаем известные нам метрики качества классификации.

С метрикой accuracy все просто. Модель правильно предсказала класс в трех случаях из пяти - первом, третьем и пятом. А в двух случаях - ошиблась. Поэтому метрика рассчитывается так: $A = 3 / 5 = 0.6$. То есть точность модели - 60%.

А вот precision и recall рассчитываются более сложно. В моделях множественной классификации эти метрики могут быть рассчитаны отдельно по каждому классу. Подход в этом случае очень похож на алгоритм "один против всех" - для каждого класса он предполагается положительным, а все остальные классы - отрицательными. Давайте рассчитаем эти метрики на нашем примере.

Возьмем нулевой класс. Его обозначим за 1, а все остальные - за 0. Тогда вектора эмпирических и теоретических значений целевой пременной станут выглядеть так: 
$y = \lbrace 1, 0, 0, 0, 1 \rbrace$,
$\hat{y} = \lbrace 1, 1, 0, 0, 1 \rbrace$.
Тогда $P = \frac{TP}{TP + FP} = \frac{2}{3} \approx 0.67$, ведь у нас получается 2 истинноположительных предсказания (первый и пятый объекты) и одно ложноположительное (второй). $R = \frac{TP}{TP + FN} = \frac{2}{2} = 1$, ведь в модели нет ложноотрицательных прогнозов. 
$F_1 = \frac{2 P R}{P + R} = \frac{2 TP}{2 TP + FP + FN} = \frac{2 \cdot 2}{2 \cdot 2 + 1 + 0} = \frac{4}{5} = 0.8$. 

Аналогично рассчитываются метрики и по остальным классам. Например, для первого класса вектора целевой переменной будут такими:
$y = \lbrace 0, 1, 0, 0, 0 \rbrace$,
$\hat{y} = \lbrace 0, 0, 0, 1, 0 \rbrace$. Обратите внимание, что в данном случае получается, что модель ни разу не угадала. Такое тоже бывает, и в таком случае, метрики будут нулевые. Для третьего класса попробуйте рассчитать метрики самостоятельно, а чуть ниже можно увидеть правильный ответ.

Конечно, при использовании библиотечный функций не придется рассчитывать все эти метрики вручную. В библиотеке _sklearn_ для этого есть очень удобная функция - _classification_report_, отчет о классификации, которая как раз вычисляет все необходимые метрики и представляет результат в виде наглядной таблицы. Вот как будет выглядеть рассмотренный нами пример:

```py
>>> from sklearn.metrics import classification_report
>>> y_true = [0, 1, 2, 2, 0]
>>> y_pred = [0, 0, 2, 1, 0]
>>> target_names = ['class 0', 'class 1', 'class 2']
>>> print(classification_report(y_true, y_pred, target_names=target_names))

              precision    recall  f1-score   support

     class 0       0.67      1.00      0.80         2
     class 1       0.00      0.00      0.00         1
     class 2       1.00      0.50      0.67         2

    accuracy                           0.60         5
   macro avg       0.56      0.50      0.49         5
weighted avg       0.67      0.60      0.59         5
```

Здесь мы видим несколько строк, соответствующих классам в нашей задаче. По каждому классу рассчитаны метрики precision, recall и $F_1$. Последний столбец называется _support_ - это количество объектов данного класса в используемой выборке. Это тоже важный показатель, так как чем меньше объектов какого-то класса, тем хуже он обычно распознается.

Ниже приведены интегральные, то есть общие метрики эффективности модели. Это три последние строки таблицы. В первую очередь это accuracy - она всегда рассчитывается один раз. Обратите внимание, что в столбце _support_ здесь везде стоит 5 - это общее число объектов выборки. Ниже приведены средние значения по метрикам precision, recall и $F_1$. Почему же строк две? Дело в том, что усреднять эти метрики можно по-разному. 

Во-первых, можно взять обычное среднее арифметическое из метрик всех классов. Это называется _macro average_. Это самый простой способ, но у него есть одна проблема. Почему метрики очень малочисленных классов должны давать тот же вклад в итоговый результат, что и метрики очень многочисленных? Можно усреднить метрики используя в качестве весов долю каждого класса в выборке. Такое усреднение называется _weighted average_. Обратите внимание, что при усреднении метрика $F_1$ может получиться не между precision и recall.

Отчет о классификации - очень полезная функция, использование которой практически обязательно при анализе эффективности моделей классификации. Особенно для задач множественной классификации. Эта таблица может дать важную информацию о том, какие классы распознаются моделью лучше, какие - хуже, как это связано в численностью классов в выборке. Анализ этой таблицы может навести на необходимость определенных действий по повышению эффективности модели. Например, можно понять, какие данные полезно будет добавить в модель. 

{% capture notice %}
Выводы:
1. Метрики для каждого класса рассчитываются, полагая данный класс положительным, а все остальные - отрицательными.
1. Каждую метрику можно усреднить арифметически или взвешенно по классам. Весами выступают объемы классов.
1. В модуле _sklearn_ реализовано несколько алгоритмов усреднения они выбираются исходя их задачи.
1. В случае средневзвешенного, F1-метрика может получиться не между P и R. 
1. Отчет о классификации содержит всю необходимую информацию в стандартной форме.
1. Отчет показывает метрики для каждого класса, а так же объем каждого класса.
1. Также отчет показывает средние и средневзвешенные метрики для всей модели.
1. Отчет о классификации - обязательный элемент представления результатов моделирования.
1. По отчету можно понять сбалансированность задачи, какие классы определяются лучше, какие - хуже.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### PR-AUC

При рассмотрении разных моделей классификации мы упоминали о том, что они подразделяются на метрические и логические методы. Логические методы (дерево решений, k ближайших соседей) выдают конкретную метку класса,без какой-либо дополнительной информации. Метрические методы (логистическая регрессия, перцептрон, SVM) выдают принадлежность данного объекта к разным классам, присутствующим в задаче. При рассмотрении модели логистической регрессии мы говорили, что предсказывается положительный класс, если значение логистической функции больше 0,5. 

Но это пороговое значение можно поменять. Что будет, если мы измени его на 0,6? Тогда мы для некоторых объектовы выборки изменим предсказание с положительного класса на отрицательный. То есть без изменения модели можно менять ее предсказания. Это значит, что изменятся и метрики модели, то есть ее эффективность.

Чем больше мы установим порог, тем чаще будем предсказывать отрицательный класс. Это значит, что в среднем, у модели будет меньше ложноположительных предсказаний, но может стать больше ложноотрицательных. Значит, у модели может увеличится precision, то упадет recall. В крайнем случае, если мы возьмем порог равный 1, мы всегда будем предсказывать отрицательный класс. Тогда у модели будет $P = 1, R = 0$. Если же, наоборот, возьмем в качестве порога 0, то мы всегда будем предсказывать отрицательный класс, а значит у модели будет $P = 0, R = 1$, так как она не будет давать ложноположительных прогнозов, но будут встречаться ложноотрицательные. 

Это означает, что эффективность моделей метрической классификации зависит не только от того, как модель соотносится с данными, но и от значения порога. Из этого следует, кстати, что было бы не совсем правильно вообще сравнивать метрики двух разных моделей между собой. Ведь значение этих метрик будет зависеть не только от самих моделей, но и от порогов, которые они используют. Может, первая модель будет лучше, если немного изменить ее пороговое значение? Может, одна из метрик второй модели станет выше, если изменить ее порог.

Это все сильно затрудняет анализ метрических моделей классификации. Для сравнения разных моделей необходим способ "убрать" влияние порога, сравнить модели вне зависимости от его значения. И такой способ есть. Достаточно просто взять все возможные значения порога, посчитать метрики в каждом из них и затем усреднить. Для этого служит PR-кривая или кривая "precision-recall":

![PR_AUC](/assets/images/ml_text/ml4-17.png "PR_AUC"){: .align-center style="width: 800px;"}

Каждая точка на этом графике представляет собой значение precision и recall для конкретного значения порога. Для построения этого графика выбирают все возможные значение порога и отмечают на графике. Давайте рассмотрим простой пример из 10 точек. Истинные значения классов этих точек равны, соответственно, $y = \lbrace 0, 0, 0, 0, 0, 1, 1, 1, 1, 1 \rbrace$. Модель (сейчас совершенно неважно, какая) выдает следующие предсказания для этих объектов: $h(x) = \lbrace 0.1, 0.2, 0.3, 0.45, 0.6, 0.4, 0.55, 0.7, 0.8, 0.9 \rbrace$. Заметим, что модель немного ошибается для средних объектов, то есть она не будет достигать стопроцентной точности. Построим таблицу, в которой переберем некоторые значения порога и вычислим, к какому классу будет относиться объект при каждом значении порога:

|y | h(x)  | 0,1  | 0,15 | 0,2  | 0,3  | 0,4  | 0,5  | 0,6  | 0,7  | 0,8  | 0,9  | 1 |
|---|------|------|------|------|------|------|------|------|------|------|------|---|
|0 | 0,1   | 1    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0 |
|0 | 0,2   | 1    | 1    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0 |
|0 | 0,3   | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0    | 0    | 0 |
|0 | 0,45  | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0    | 0    | 0 |
|0 | 0,6   | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0 |
|1 | 0,4   | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0    | 0    | 0 |
|1 | 0,55  | 1    | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0    | 0 |
|1 | 0,7   | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0 |
|1 | 0,8   | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 0    | 0 |
|1 | 0,9   | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 0 |

Можно сразу заметить, что чем выше порог, тем чаще предсказывается отрицательный класс. В крайних случаях модель всегда предсказывает либо положительный класс (при малых значениях порога), либо отрицательный (при больших).

Далее, для каждого значения порога рассчитаем количество истинно положительных, истинно отрицательных, ложноположительных и ложноотрицательных предсказаний. На основе этих данных легко рассчитать и метрики precision и recall. Запишем это в таблицу:

|y | h(x)  | 0,1  | 0,15 | 0,2  | 0,3  | 0,4  | 0,5  | 0,6  | 0,7  | 0,8  | 0,9  | 1 |
|---|------|------|------|------|------|------|------|------|------|------|------|---|
|  | TP    | 5    | 5    | 5    | 5    | 5    | 4    | 3    | 3    | 2    | 1    | 0 |
|  | TN    | 0    | 0    | 1    | 2    | 3    | 4    | 4    | 5    | 5    | 5    | 5 |
|  | FP    | 5    | 5    | 4    | 3    | 2    | 1    | 1    | 0    | 0    | 0    | 0 |
|  | FN    | 0    | 0    | 0    | 0    | 0    | 1    | 2    | 2    | 3    | 4    | 5 |
|  | P     | 0,50 | 0,50 | 0,56 | 0,63 | 0,71 | 0,80 | 0,75 | 1,00 | 1,00 | 1,00 | 1,00 |
|  | R     | 1,00 | 1,00 | 1,00 | 1,00 | 1,00 | 0,80 | 0,60 | 0,60 | 0,40 | 0,20 | 0,00 |

При самом низком значении порога модель всегда предсказывает отрицательный класс, метрика recall равна 1, а метрика precision равна доли отрицательного класса в выборке. Причем ниже этого значения precision уже не опускается. Можно заметить, что в целом при повышении порога precision повышается, а recall понижается. В другом крайнем случае, когда порог равен 1, модель всегда предсказывает отрицательный класс, метрика recall равна 0, а precision - 1 (на самом деле эта метрика не определена, но считается равной именно 1, так как ее значение стремится к этому при повышении порога). За счет чего это происходит?

При повышении порога может произойти один из трех случаев. Первый заключается в том, что данное изменение может не влияет ни на одно предсказание. Так происходит, например, при повышении порога с 0,1 до 0,15. Оценка ни одного объекта не попадает в данный диапазон, поэтому ни одно предсказание не меняется. И, соответственно, не изменится ни одна метрика.

Если же повышение порога все-таки затрагивает один или несколько объектов, то изменение предсказания может произойти только с положительного на отрицательное. Допустим, для простоты, что повышение порога затрагивает только один объект. То есть мы изменяем предсказание по одному объекту с 1 на 0. Второй случай заключается в том, что это изменение правильное. То есть объект в действительности принадлежит отрицательному классу. Так происходит, например, при изменении порога с 0,15 до 0,2. В данном случае первый объект из ложноположительного стал истинно отрицательным. Такое изменение не влияет на recall, но повышает precision.

Третий случай заключается в том, что изменение предсказаные было неверным. То есть объект из истинно положительного стал ложноотрицательным. Это происходит, например, при изменении порога с 0,4 до 0,5 - в данном случае шестой объект становится классифицированным ошибочно. Уменьшение количества истинно положительных объектов снижает обе метрики - и precision и recall. 

Таким образом можно заключить, что recall при повышении порога может оставаться неизменным или снижаться, а precision может как повышаться, так и понижаться, но в среднем будет повышаться за счет уменьшения доли ложноположительных предсказаний. Если изобразить рассмотренный пример на графике можно получить такую кривую:

![PR_AUC](/assets/images/ml_text/ml4-18.png "PR_AUC"){: .align-center style="width: 800px;"}

PR-кривая не всегда монотонна, обе метрики могут изменяться как однонаправленно, так и разнонаправленно при изменении порогового значения. Но главный смысл этой кривой не в этом. При таком анализе очень просто обобщить эффективность модели вне зависимости от значения порога. Для этого нужно всего лишь найти площадь под графиком этой кривой. Эта метрика называется PR-AUC (area under the curve) или average precision (AP). Чем она выше, тем качественнее модель. 

Давайте порассуждаем, ка будет вести себя идеальная модель. Крайние случаи, когда порога равны 0 и 1, значения метрик будут такими же, как и всегда. Но вот при любом другом значении порога модель будет классифицировать все объекты правильно. И обе метрики у нее будут равны 1. Таким образом, PR-кривая выродится в два отрезка, один из которых проходит из точки (0, 1) в точку (1, 1). и площадь под графиком будет равна 1. У самой худшей же модели метрики будут равны 0, так как она всегда будет предсказывать неверно. И площадь тоже будет равна 0.

У случайной модели, как можно догадаться, площадь под графиком будет равна 0,5. Поэтому метрика PR-AUC может использоваться для сравнения разных моделей метрической классификации вне зависимости от значения порога. Также эта метрика показывает соотношение данной модели и случайной. Если PR-AUC модели меньше 0,5, значит она хуже предсказывает класс, чем простое угадывание.

{% capture notice %}
Выводы:
1. Кривая precision-recall используется для методов метрической классификации, которые выдают вероятность принадлежности объекта данному классу.
1. Дискретная классификации производится при помощи порогового значения.
1. Чем больше порог, тем больше объектов модель будет относить к отрицательному классу.
1. Повышение порога в среднем увеличивает precision модели, но понижает recall.
1. PR-кривая используется чтобы выбрать оптимальное значение порога.
1. PR-кривая нужна для того, чтобы сравнивать и оценивать модели вне зависимости от выбранного уровня порога.
1. PR-AUC - площадь под PR-кривой, у лучшей модели - 1.0, у тривиальной - 0.5, у худшей - 0.0.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### ROC_AUC

Помимо кривой PR есть еще один довольно популярный метод оценки эффективности метрических моделей классификации. Он использует тот же подход, что и PR-кривая, но немного другие координаты. ROC-кривая (receiver operating characteristic) - это график показывающий соотношение доли истинно положительных предсказаний и ложноположительных предсказаний в модели метрической классификации для разных значений порога. 

В этой кривой используются два новых термина - доля истинно положительных и доля ложноположительных предсказаний. Доля истинно положительных предсказаний (TPR, true positive rate), как можно догадаться, это отношение количества объектов выборки, правильно распознанных как положительные, ко всем положительным объектам. Другими словами, это всего лишь иное название метрики recall.

А вот доля ложноположительных предсказаний (FPR, false positive rate) считается как отношение количества отрицательных объектов, неправильно распознанных как положительные, в общем количестве отрицательных объектов выборки:

$$
TPR = \frac{TP}{TP + FN} = R \\
FRP = \frac{FP}{TN + FP} = 1 - S
$$

Обратите внимание, что FPR - мера ошибки модели. То есть, чем больше - тем хуже. У идеальной модели $FRP=0$, а у наихудшей - $FPR=1$. Для иллюстрации давайте рассчитаем эти метрики для нашего примера, который мы использовали выше (для дополнительной информации еще приведена метрика accuracy для каждого значения порога):

|y | h(x)  | 0,1  | 0,2  | 0,3  | 0,4  | 0,5  | 0,6  | 0,7  | 0,8  | 0,9  | 1 |
|---|------|------|------|------|------|------|------|------|------|------|---|
|  | TPR   | 1,00 | 1,00 | 1,00 | 1,00 | 0,80 | 0,60 | 0,60 | 0,40 | 0,20 | 0,00 |
|  | FPR   | 1,00 | 0,80 | 0,60 | 0,40 | 0,20 | 0,20 | 0,00 | 0,00 | 0,00 | 0,00 |
|  | A     | 0,50 | 0,60 | 0,70 | 0,80 | 0,80 | 0,70 | 0,80 | 0,70 | 0,60 | 0,50 |

Можно заметить, что при увеличении порога обе эти метрики увеличиваются, начиная со значения 1 до нуля. Причем, движения этих двух показателей всегда однонаправленно. Давайте опять же разберемся, почему так. Если увеличение порога приводит к правильному изменению классификации, то есть изменению ложноположительного значения на истинно отрицательное, то это уменьшит FRP, но не затронет TRP. Если же изменение будет неверным, то есть истинно положительное значение поменялось на ложноотрицательное, это однозначно уменьшит TPR, при этом FRP либо уменьшится так же, либо останется неименным.

В итоге, кривая получается монотонной, причем она всегда проходит через центр координат и через точку (1, 1). В нашем примере кривая будет выглядеть так:

![ROC_AUC](/assets/images/ml_text/ml4-19.png "ROC_AUC"){: .align-center style="width: 800px;"}

Более сложные данные могут выглядеть с большим количеством деталей, но общая форма и монотонность сохраняются:

![ROC_AUC](/assets/images/ml_text/ml4-20.png "ROC_AUC"){: .align-center style="width: 800px;"}

Также, как и с кривой PR, важное значение имеет площадь под графиком. Эта метрика называется ROC-AUC и является одной из самых популярных метрик качества метрических моделей классификации. Ее главное преимущество перед другими метриками состоит в том, что она позволяет объективно сопоставить уровень качества разных моделей классификации, решающих одну и ту же задачу, но обученных на разных данных. Это приводит к частому использованию ROC-AUC, например, в научной литературе для представления результатов моделирования.

Существует множество споров, какая диагностическая кривая более адекватно измеряет качество классификации - ROC или PR. Считается, что PR-кривая больше ориентирована на задачи, в которых присутствует дисбаланс классов. Это задачи в которых объектов одного класса значительно больше чем другого, классы имеют разное толкование и, как следствие, ошибки первого и второго рода не равнозначны. Зачастую это модели бинарной классификации. ROC же дает более адекватную картину в задачах, где классов примерно поровну в выборке. Но для полного анализа модели все равно рекомендуется использовать оба метода.

В случае с множественной классификацией построение диагностических кривых происходит отдельно по каждому классу. Так же, как и при расчете метрик precision и recall, каждый класс поочередно полагается положительным, а остальные - отрицательными. Каждая такая частная кривая показывает качество распознавания конкретного класса. Поэтому кривые могут выглядеть примерно так:

![MultiPR](https://scikit-learn.org/0.15/_images/plot_precision_recall_0011.png "MultiPR"){: .align-center style="width: 800px;"}
Источник: [sklearn](https://www.google.com/url?sa=i&url=https%3A%2F%2Fscikit-learn.org%2F0.15%2Fauto_examples%2Fplot_precision_recall.html&psig=AOvVaw15eJNKyR29Xy4Zqjn9s-jS&ust=1653408447730000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCND5hs2A9vcCFQAAAAAdAAAAABAI).
{: style="text-align: center; font-size:0.7em;"}

На данном графике мы видим PR-кривую модели множественной классификации из 3 классов. Кроме отдельных значений precision и recall в каждой точке рассчитываются и усредненные значения. Так формируется кривая средних значений. Интегральная метрика качества модели классификации считается как площадь под кривой средних значений. Алгоритм построения ROC-кривой полностью аналогичен.

{% capture notice %}
Выводы:
1. ROC-кривая показывает качество бинарной классификации при разных значениях порога.
1. В отличие от PR-кривой, ROC-кривая монотонна.
1. Площадь под графиком ROC-кривой, ROC_AUC - одна из основных метрик качества классификационных моделей. 
1. ROC_AUC можно использовать для сравнения качества разных моделей, обученных на разных данных.
1. ROC чаще используют для сбалансированных и множественных задач, PR - для несбалансированных.
1. Кривые для множественной классификации строятся отдельно для каждого класса.
1. Метрика AUC считается по кривой средних значений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Топ k классов

Все метрики, которые мы обсуждали выше оперируют точным совпадением предсказанного класса с истинным. В некоторых особых задачах может быть полезно немного смягчить это условие. Как мы говорили, метрические методы классификации выдают больше информации - степень принадлежности объекта выборки каждому классу. Обычно, мы выбираем из них тот класс, который имеет наибольшую принадлежность. Но можно выбрать не один класс, а несколько. Таким образом можно рассматривать не единственный вариант класса для конкретного объекта, а 3, 5, 10 и так далее.

Другими словами можно говорить о том, находится ли истинный класс объекта среди 3, 5 или 10 классов, которые выбрала для него модель. Количество классов, которые мы рассматриваем, можно брать любым. В данной метрике оно обозначается k. Таким образом, можно построить метрику, которая оценивает долю объектов выборки, для которых истинный класс находится среди k лучших предсказаний модели:

{% capture block %}
$$ 
tka(y, \hat{f}) = \frac{1}{n} \sum_{i=0}^{n-1} 
\sum_{j=1}^{k} 1(\hat{f_{ij}} = y_i) 
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

где $hat{f_{ij}}$ - это j-й в порядке убывания уверенности модели класс i-го объекта.

Рассмотрим такой пример. Пусть у нас есть задача классификации из 3 классов. Мы оцениваем 4 объекта, которые имеют на самом деле такие классы: 
$y = \lbrace 0, 1, 2, 2 \rbrace$. 

```py
>>> import numpy as np
>>> from sklearn.metrics import top_k_accuracy_score
>>> y_true = np.array([0, 1, 2, 2])
```

Модель предсказывает следующие вероятности для каждого объекта:

```py
>>> y_score = np.array([[0.5, 0.2, 0.2],
...                     [0.4, 0.3, 0.2],
...                     [0.2, 0.4, 0.3],
...                     [0.7, 0.2, 0.1]])
```

То есть для первого объекта она выбирает первый класс, но немного предполагает и второй. А вот, например, последний, четвертый объект она уверенно относит тоже к первому классу. Давайте посчитаем метрику топ-2 для этой модели. Для этого для каждого объекта рассмотрим, какие 2 класса модель называет наиболее вероятными. Для первого - это 0 и 1, для второго - также 0 и 1, причем модель отдает предпочтение 0 классу, хотя на самом деле объект относится к 1 классу. Для третьего - уже 2 и 2 класс, причем класс 1 кажется модели более вероятным, для четвертого - так же наиболее вероятными модели кажутся 0 и 1 класс.

Если бы мы говорили об обычной accuracy, то для такой модели она была бы равна 0,25. Ведь только для первого объекта модель дала правильное предсказание наиболее вероятного класса. Но по метрике топ-2, для целых трех объектов истинный класс находится среди двух наиболее вероятных. Модель полностью ошибается только в последнем случае. Так что эта метрика равна 0,75. Это же подтверждают и автоматические расчеты:

```py
>>> top_k_accuracy_score(y_true, y_score, k=2)
0.75
```

Как мы говорили, количество классов k можно взять любым. В частном случае $k=1$ эта метрика превращается в классическую accuracy. Чем больше возьмем k, тем выше будет значение данной метрики, но слабее условие. Так что брать очень большие k нет никакого смысла. В другом крайнем случае, когда k равно количеству классов, метрика будет равна 1 для любой модели.

Эта метрика имеет не очень много практического смысла. Ведь при прикладном применении моделей машинного обучения важен все-таки итоговый результат классификации. И если модель ошиблась, то модель ошиблась. Но эта метрика может пролить свет на внутреннее устройство модели, показать, насколько сильно она ошибается. Ведь одно дело, если модель иногда называет правильный ответ может и не наиболее вероятным, но в топ, скажем, 3. Совсем другое дело, если модель не находит правильный ответ и среди топ-10. Так что эта метрика может использоваться для диагностики моделей классификации и для поиска путей их совершенствования. Еще она бывает полезна, если две модели имеют равные значения метрики accuracy, но нужно понять, какая их них адекватнее имеющимся данным.

Такие проблемы часто возникают в задачах, где классов очень много. Например, в распознавании объектов на изображениях количество объектов может быть несколько тысяч. А в задачах обработки текста количество классов может определяться количеством слов в языке - сотни тысяч и миллионы (если учитывать разные формы слов). Естественно, что эффективность моделей классификации в таких задачах, измеренная обычными способами будет очень низкой. А данная метрика позволяет эффективно сравнивать и оценивать такие модели.

{% capture notice %}
Выводы:
1. Эта метрика - обобщение точности для случая, когда модель выдает вероятности отнесения к каждому классу.
1. Вычисляется как доля объектов, для которых правильный класс попадает в список k лучших предсказанных классов.
1. Чем больше k, тем выше метрика, но бесполезнее результат.
1. Эта метрика часто применяется в задачах с большим количеством классов.
1. Применимость этой метрики сильно зависит от характера задачи.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Проблема пере- и недообучения

#### Проблема Bias/Variance

При решении задачи методами машинного обучения всегда встает задача выбора вида модели. Как мы обсуждали в предыдущих главах, существует большое количество классов модели - достаточно вспомнить линейные модели, метод опорных векторов, перцептрон и другие. Каждая их этих моделей, будучи обученной на одном и том же наборе данных может давать разные результаты. Важно понимать, что мы не говорим о степени подстройки модели к данным. Даже если обучение прошло до конца, найдены оптимальные значения параметров, все равно модели могут и, скорее всего, будут различаться. 

Причем многие классы моделей представляют собой не одно, а целое множество семейств функций. Например, та же логарифмическая регрессия - это не одна функция, а бесконечное количество - квадратичные, кубические, четвертой степени и так далее. Множество функций или моделей, имеющих единую форму, но различающуюся значениями параметров составляет так называемое параметрическое семейство функций. Так, все возможные линейные функции - это одно параметрическое семейство, все возможные квадратические - другое, а, например, множество всех возможных однослойных перцептронов с 5 нейронами во входном, 3 нейронами в скрытом и одном нейроне в выходном слое - третье семейство.

Таким образом можно говорить, что перед аналитиком стоит задача выбора параметрического семейства модели, которую он будет обучать на имеющихся данных. Причем разные семейства дадут модели разного уровня качества после обучения. К сожалению, очень сложно заранее предугадать, какое семейство моделей после завершения обучения даст наилучшее качество предсказания по данной выборке. 

Что является главным фактором выбора этого семейства? Как показывает практика, самое существенное влияние на эффективность оказывает уровень сложности модели. Любое параметрическое семейство моделей имеет определенное количество степеней свободы, которое определяет то, насколько сложное и изменчивое поведение может демонстрировать получившаяся функция. 

Сложность модели можно определять разными способами, но в контексте нашего рассуждения сложность однозначно ассоциируется с количеством параметров в модели. Чем больше параметров, тем больше у модели степеней свободы, возможности изменять свое поведение при разных значениях входных признаков. Конечно, это не означает полной эквивалентности разных типов моделей с одинаковым количеством параметров. Например, никто не говорит, что модель, скажем, регрессии по методу опорных векторов эквивалентна модели нейронной сети с тем же самым количеством весов. Главное, что модели со сходным уровнем сложности демонстрируют сходное поведение по отношению к конкретному набору данных.

Влияние уровня сложности на поведение модели относительно данных наиболее наглядно можно проследить на примере модели полиномиальной модели. Степень полинома - это очень показательная характеристика уровня сложности модели. Давайте рассмотрим три модели регрессии - линейную (которую можно рассматривать как полином первой степени), полином четвертой и двадцатой степени. Мы обучили эти модели на одном и том же датасете и вот что получилось:

![Bias-variance](/assets/images/ml_text/ml4-11.png "Bias-variance"){: .align-center style="width: 800px;"}

Следует отдельно заметить, что в каждом из представленных случаев модель обучалась до конца, то есть до схождения метода численной оптимизации параметров. То есть для каждой модели на графике представлены оптимальные значения параметров. Гладя на эти три графика и то, как эти линии ложатся в имеющиеся точки, можно заметить некоторое противоречие. Естественно предположить, что модель, изображенная на втором графике показывает наилучшее описание точек данных. Но по любой метрике качества третья модель будет показывать более высокий результат.

Человек, глядя на график третьей модели, сразу сделает вывод, что она "слишком" хорошо подстроилась под имеющиеся данные. Сравните это поведение с первым графиком, который демонстрирует самую низкую эффективность на имеющихся данных. Можно проследить, как именно сложность модели влияет на ее применимость. Если модель слишком простая, то она может не выявить имеющиеся сложные зависимости между признаками и целевой переменной. Говорят, что у простых моделей низкая вариативность (variance). Слишком же сложная модель имеет слишком высокую вариативность, что тоже не очень хорошо. 

Те же самые рассуждения можно применить и к моделям классификации. Можно взглянуть на форму границы принятия решения для трех моделей разного уровня сложности, обученных на одних и тех же данных:

![Bias-variance](/assets/images/ml_text/ml4-3.png "Bias-variance"){: .align-center style="width: 800px;"}

В данном случае мы видим ту же картину - слишком простая модель не может распознать сложную форму зависимости между факторами и целевой переменной. Такая ситуация называется недообучение. Обратите внимание, что недообучение не говорит о том, что модель не обучилась не до конца. Просто недостаток сложности, вариативности модели не дает ни одной возможной функции их этого параметрического семейства хорошо описывать данные. 

Слишком сложные модели избыточно подстраиваются под малейшие выбросы в данных. Это увеличивает значение метрик эффективности, но снижает пригодность модели на практике, так как очевидно, что модель будет делать большие ошибки на новых данных из той же выборки. Такая ситуация называется переобучением. Переобучение - это очень коварная проблема моделей машинного обучения, ведь на "бумаге" все метрики показывают отличный результат. 

{% capture notice %}
Конечно, в общем случае не получится так наглядно увидеть то, как модель подстраивается под данные. Ведь в случае, когда данные имеют большую размерность, строить графики в проекции не даст представления об общей картине. Поэтому ситуацию пере- и недообучения довольно сложно обнаружить. Для этого нужно проводить отдельную диагностику.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

Это происходит потому, что в практически любой выборке данных конкретное положение точек, их совместное распределение определяется как существенной зависимостью между признаками и целевой переменной, так и случайными отклонениями. Эти случайные отклонения, выбросы, аномалии не позволяют сделать однозначный вывод, что модель, которая лучше описывает имеющиеся данные, является лучшей в глобальном смысле. 

{% capture notice %}
Выводы: 
1. Прежде чем обучать модель, нужно выбрать ее вид (параметрическое семейство функций).
1. Разные модели при своих оптимальных параметрах будут давать разный результат.
1. Чем сложнее и вариативнее модель, тем больше у нее параметров.
1. Простые модели быстрые, но им недостает вариативности, изменчивости, у них высокое смещение (bias).
1. Сложные модели могут описывать больше зависимостей, но вычислительно более трудоемкие и имеют большую дисперсию (variance).
1. Слишком вариативные (сложные) модели алгоритм может подстраиваться под случайный шум в данных - переобучение.
1. Слишком смещенные (простые) модели алгоритм может пропустить связь признака и целевой переменной - недообучение.
1. Не всегда модель, которая лучше подстраивается под данные (имеет более высокие метрики эффективности) лучше.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Обобщающая способность модели, тестовый набор

Как было показано выше, не всякая модель, которая показывает высокую эффективность на тех данных, на которых она обучалась, полезна на практике. Нужно всегда помнить, что модели машинного обучения строят не для того, чтобы точно описывать объекты из обучающего набора. На то он и обучающий набор, что мы уже знаем правильные ответы. Цель моделирования - создать модель, которая на примере этих данных формализует некоторые внутренние зависимости в данных для того, чтобы адекватно описывать новые объекты, которые модель не учитывала при обучении. 

Полезность модели машинного обучения определяется именно способность описывать новые данные. Это называется обобщающей способностью модели. И как мы показали в предыдущей главе, эффективность модели на тех данных, на которых она обучается, не дает адекватного понимания этой самой обобщающей способности модели. 

![Test set](/assets/images/ml_text/ml4-12.png "Test set"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Цель разработки моделей машинного обучения - не описывать обучающий набор, а на его примере описывать другие объекты реального мира.
1. Главное качество модели - описывать объекты, которых она не видела при обучении - обобщающая способность.
1. Для того, чтобы оценить обобщающую способность модели нужно вычислить метрики эффективности на новых данных.
1. Для этого исходный датасет разбивают на обучающую и тестовую выборки. Делить можно в любой пропорции, обычно 80-20.
1. Обучающая выборки используется для подбора параметров модели (обучения), а тестовая - для оценки ее эффективности.
1. Никогда не оценивайте эффективность модели на тех же данных, на которых она училась - оценка получится слишком оптимистичная.
1. Ошибка или эффективность на тестовых данных дает несмещенную оценку качества модели, ее предсказательной силы.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Кросс-валидация

![CV](https://miro.medium.com/max/1400/1*AAwIlHM8TpAVe4l2FihNUQ.png "CV"){: .align-center style="width: 800px;"}
Источник: [Towards Data Science](https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b).
{: style="text-align: center; font-size:0.7em;"}

```py
>>> from sklearn.model_selection import cross_validate
>>> from sklearn.metrics import recall_score

>>> scoring = ['precision_macro','recall_macro']
>>> clf = 
svm.SVC(kernel='linear', C=1, random_state=0)

>>> scores = 
cross_validate(clf, X, y, scoring=scoring)

>>> sorted(scores.keys())
['fit_time', 'score_time', 
'test_precision_macro', 'test_recall_macro']

>>> scores['test_recall_macro']
array([0.96..., 1.  ..., 0.96..., 0.96..., 1. ])

```

{% capture notice %}
Выводы:
1. Разбиение выборки на обучающую и тестовую может внести случайные ошибки.
1. Нужно повторить разбиение несколько раз, посчитать метрики и усреднить.
1. Кросс-валидация разбивает выборку на $k$ блоков, каждый из которых используется по очереди как тестовый.
1. Сколько задать $k$, столько и будет проходов. Обычно берут 3 или 5.
1. Чем больше $k$ тем надежнее оценка, но дольше ее получение, так как модель каждый раз заново обучается.
1. Использование кросс-валидации обязательно для получения робастных оценок.
1. В библиотеке _sklearn_ кросс-валидация (CV) встроена во многие функции.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Кривые обучения

![Learning curve](/assets/images/ml_text/ml4-6.png "Learning curve"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Кривая обучения - это зависимость эффективности модели от размера обучающей выборки.
1. Для построения кривых обучения модель обучают много раз, каждый раз с другим размером обучающей выборки (от одного элемента до всех, что есть).
1. При малых объемах обучающая эффективность будет очень большой, а тестовая - очень маленькой.
1. При увеличении объема обучающей выборки они будут сходиться, но обычно тестовая эффективность всегда ниже обучающей.
1. Кривые обучения позволяют увидеть, как быстро модель учится, хватает ли ей данных, а также обнаруживать пере- и недообучение.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Обнаружение пере- и недообучения

![Learning curve](/assets/images/ml_text/ml4-7.png "Learning curve"){: .align-center style="width: 800px;"}

![Learning curve](/assets/images/ml_text/ml4-8.png "Learning curve"){: .align-center style="width: 800px;"}

![Learning curve](/assets/images/ml_text/ml4-13.png "Learning curve"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. При недообучении тестовая и обучающая эффективности будут достаточно близкими, но недостаточными.
1. При переобучении тестовая и обучающая эффективности будут сильно различаться - тестовая будет значительно ниже.
1. Пере- и недообучение - это относительные понятия.
1. Более простые модели склонны к недообучению, более сложные - к переобучению.
1. Диагностика пере- и недообучения очень важна, так как для повышения эффективности предпринимаются противоположные меры.
1. Для построения можно использовать функцию ошибки, метрику эффективности или метрику ошибки, важна только динамика этих показателей.
1. Диагностика моделей машинного обучения - это не точная наука, здесь нужно принимать в расчет и задачу, и выбор признаков и многие другие факторы.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Методы повышения эффективности моделей

{% capture notice %}
Выводы:
1. Диагностика модели нужна для того, чтобы подсказать пути увеличения ее эффективности
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Регуляризация

![Bias vs complexity](/assets/images/ml_text/ml4-14.png "Bias vs complexity"){: .align-center style="width: 800px;"}

![Bias vs regularization](/assets/images/ml_text/ml4-4.png "Bias vs regularization"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Регуляризация - это способ искусственно ограничить вариативность моделей.
1. При использовании регуляризации можно применять более сложные модели и снижать склонность к переобучению.
1. Регуляризация модифицирует функцию ошибки модели, добавляя в нее штрафы за повышение сложности.
1. Основная идея регуляризации - отдавать предпочтение низким значениям параметров в модели.
1. Регуляризация обычно не затрагивает свободный коэффициент $b_0$.
1. Регуляризация обычно параметрическая, можно управлять ее степенью.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Ridge

{% capture block %}
$$ 
J(\vec{b}) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 + \lambda \sum_{j=1}^{n} b_j^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. $\lambda > 0$ - параметр регуляризации.
1. Чем он больше, тем сильнее штрафуются сложные модели.
1. Этот прием может применяться как к классификации, так и к регрессии.
1. Ridge еще называют регуляризацией по L2-норме. Она же - гребневая регрессия.
1. Такая регуляризация делает параметры более робастными к мультиколлинеарности признаков.
1. В классификации такая модель может обучаться заметно быстрее за счет внутренней оптимизации вычислений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Lasso

{% capture block %}
$$ 
J(\vec{b}) = \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 + \lambda \sum_{j=1}^{n} \| b_j \|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. Lasso еще называют регуляризацией по L1-норме.
1. Lasso заставляет модель использовать меньше ненулевых коэффициентов.
1. Фактически, эта регуляризация уменьшает количество признаков, от которых зависит модель.
1. Может использоваться для отбора признаков.
1. Полезна в задачах с разреженной матрицей признаков.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Elastic net

{% capture block %}
$$ 
J(\vec{b}) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 + 
\lambda_1 \sum_{j=1}^{n} \| b_j \| + \lambda_2 \sum_{j=1}^{n} b_j^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. По сути, это комбинация регуляризации по L1 и L2 нормам.
1. Имеет два параметра, которые определяют соотношение соответствующих норм.
1. Комбинирует достоинства предыдущих двух методов.
1. Недостаток в необходимости задавать сразу два параметра регуляризации.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы борьбы с недообучением

{% capture notice %}
Выводы:
1. Ввести в модель новые данные об объектах (атрибуты).
1. Уменьшение степени регуляризации модели.
1. Введение полиномиальных и других признаков.
1. В целом, инжиниринг признаков.
1. Использование более сложных моделей.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы борьбы с переобучением

{% capture notice %}
Выводы:
1. Ввести в модель данные о новых объектах, использовать большую выборку.
1. Убрать признаки из модели, использовать отбор признаков.
1. Увеличить степень регуляризации модели.
1. Использовать более простые модели.
1. Регуляризация обычно работает лучше уменьшения количества параметров.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Анализ ошибок

{% capture notice %}
Выводы:
1. Анализ ошибок - это ручная проверка объектов, на которых модель делает ошибки.
1. Анализ характеристик таких объектов может подсказать направление инжиниринга признаков.
1. Можно сравнить эти объекты с остальной выборкой. Может, это аномалии.
1. В задачах регрессии в первую очередь обращать внимание на объекты с самым высоким отклонением.
1. Полезно бывает проинтерпретировать модель - проанализировать ее предметный смысл.
1. Для сложных моделей есть методы локальной линейной интерпретации. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Выбор модели

{% capture notice %}
Выводы:
1. Задача выбора класса модели для решения определенной задачи.
1. Очень сложно сказать априори какой класс модели будет работать лучше на конкретных данных.
1. Следует учитывать нефункциональные требования к задаче.
1. Обычно начинают с самых простых моделей - они быстро считаются и дают базовый уровень эффективности.
1. По результатам диагностики простых моделей принимают решение о дальнейших действиях.
1. Можно провести поиск по разным классам моделей для определения самых перспективных.
1. Выбор модели - это творческий и исследовательский процесс.
1. Есть подходы автоматизации выбора модели (AutoML), но они пока несовершенны.
1. В исследовательских задачах модели сравниваются со state-of-the-art.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Гиперпараметры модели

{% capture notice %}
Выводы:
1. Гиперпараметр модели - это численное значение, которое влияет на работу модели, но не подбирается в процессе обучения.
1. Примеры гиперпараметров - k в kNN, параметр регуляризации, степень полиномиальной регрессии, глубина дерева решения.
1. У каждой модели множество гиперпараметров, которые можно посмотреть в документации.
1. Гиперпараметры модели нужно задавать до начала обучения.
1. Если значение гиперпараметра изменилось, то обучение надо начинать заново.
1. Существуют скрытые гиперпараметры модели - степень полинома, количество нейронов и слоев, ядерная функция.
1. Оптимизация гиперпараметров и задача выбора модели - одно и то же.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Поиск по сетке

```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

tuned_parameters = [
    {"kernel": ["rbf"], 
    "gamma": [1e-3, 1e-4], 
    "C": [1, 10, 100, 1000]},

    {"kernel": ["linear"], 
    "C": [1, 10, 100, 1000]},
]
scores = ["precision", "recall"]

grid_search = GridSearchCV(SVC(), tuned_parameters, 
       scoring=scores).fit(X_train, y_train)
```

{% capture notice %}
Выводы:
1. Поиск по сетке - полный перебор всех комбинаций значений гиперпараметров для поиска оптимальных значений.
1. Для его организации надо задать список гиперпараметров и их конкретных значений.
1. Непрерывные гиперпараметры надо дискретизировать.
1. Поиск по сетке имеет экспоненциальную сложность.
1. Чем больше параметров и значений задать, тем лучше модель, но дольше поиск.
1. Можно задать критерии поиска - целевые метрики.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Случайный поиск

```python
clf = SGDClassifier(loss="hinge", penalty="elasticnet", fit_intercept=True)

param_dist = {
    "average": [True, False],
    "l1_ratio": stats.uniform(0, 1),
    "alpha": loguniform(1e-2, 1e0),
}

n_iter_search = 15
random_search = RandomizedSearchCV(
    clf, param_distributions=param_dist, n_iter=n_iter_search
).fit(X, y)
```

{% capture notice %}
Выводы:
1. Случайный поиск позволяет задать распределение гиперпараметра, в котором будет вестись поиск.
1. Случайный поиск семплирует набор значений гиперпараметров из указанных распределений.
1. Можно задать количество итераций поиска независимо от количества гиперпараметров.
1. Добавление параметров не влияет на продолжительность поиска.
1. Результат не гарантируется. Воспроизводимость можно настроить.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Сравнение эффективности моделей (валидационный набор)

![CV](/assets/images/ml_text/ml4-9.png "CV"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. При сравнении нескольких моделей между собой возникает проблема оптимистичной оценки эффективности.
1. Поэтому для исследования выбранной модели нужно использовать третью часть выборки - валидационную.
1. В терминах существует путаница, главное - три непересекающиеся части выборки.
1. Обучающая (train) используется для оптимизации параметров (обучения) модели.
1. Валидационная (validation) - для оптимизации гиперпараметров и выбора модели.
1. Тестовая (test, holdout) - для итоговой оценки качества, представления результатов.
1. Во многих случаях использование кросс-валидации автоматически разбивает выборку. Поэтому тестовая играет роль валидационной.
1. Есть проблема глобального переобучения моделей на известных датасетах.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>