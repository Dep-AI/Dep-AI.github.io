---
section: ml
title: "Диагностика систем машинного обучения"
---

### Что такое метрики эффективности?

Для того, чтобы эффективно проводить обучение моделей необходимо иметь способ оценки, насколько хорошо та или иная модель выполняет свою работу - предсказывает значение целевой переменной. Кажется, мы уже что-то подобное изучали. У каждой модели есть функция ошибки, которая показывает, на сколько модель соответствует эмпирическим значениям. Однако, использование функции ошибки не очень удобно для оценки именно "качества" уже построенных моделей. Ведь эта функция специально создается для единственной цели - организации процесса обучения. Поэтому для оценки уже построенных моделей используется не функция ошибки, а так называемые метрики эффективности - специальные функции, которые показывают, насколько эффективна уже готовая, обученная модель. 

Метрики эффективности на первый взгляд очень похожи на функции ошибки, ведь у них одна цель - отличать хорошие модели от плохих. Но делают они это по-разному, по-разному и применяются. К метрикам эффективности предъявляются совершенно другие требования, нежели к функциям ошибки. Поэтому давайте рассмотрим, для чего нужны и те и другие.

Функция ошибки нужна в первую очередь для формализации процесса обучения модели. То есть для того, чтобы подбирать параметры модели именно такими, чтобы модель как можно больше соответствовала реальным данным в обучающей выборке. Да, значение этой функции можно использовать как некоторую оценку качества модели уже после того, как она обучена, но это не удобно. 

Функция ошибки нужна, чтобы формализовать отклонения предсказанных моделью значений от реальных. Например, в методе линейной регрессии функция ошибки (среднеквадратическое отклонение) используется для метода градиентного спуска. Поэтому функция ошибки обязательно должна быть везде дифференцируемой, мы это отдельно отмечали, когда говорили про метод градиентного спуска. Это требование - дифференцируемость - нужно исключительно для метода оптимизации, то есть для обучения модели.

Зато функция, которая используется для оценки качества модели совершенно не должна быть аналитической и гладкой. Ведь мы не будем вычислять ее производную, мы только вычислим ее один раз для того, чтобы понять, насколько хорошая модель получилась. Так что не любую метрику эффективности вообще физически возможно использовать как функцию ошибки - метод обучения может просто не сработать.

Кроме того, функция ошибки должна быть вычислительно простой, ведь ее придется считать много раз в процессе обучения - тысячи или миллионы раз. Это еще одно требование, которое совершенно необязательно для метрики эффективности. Она как раз может считаться довольно сложно, ведь вычислять ее приходится всего несколько раз.

Зато метрика эффективности должна быть понятной и интерпретируемой, в отличие от функции ошибки. Раньше мы подчеркивали, что само абсолютное значение функции ошибки ничего не показывает. Важно лишь, снижается ли оно в процессе обучения. И разные значения функции ошибки имеет смысл сравнивать только на одних и тех же данных. Что значит, если значение функции ошибки модели равно 35 000? Да ничего, только то, что эта модель хуже, чем та, у которой ошибка 32 000. 

Для того, чтобы значение было более понятно, метрики эффективности зачастую выражаются в каких-то определенных единицах измерения - чеще всего в натуральных или в процентах. Натуральные единицы - это единицы измерения целевой переменной. Допустим, целевая переменная выражается в рублях. То есть, мы предсказываем некоторую стоимость. В таком случае будет вполне понятно, если качество этой модели мы тоже выразим в рублях. Например, так: модель в среднем ошибается на 500 рублей. И сразу становится ясно, насколько эта модель применима на практике.

Еще одно важное отличие. Как мы сказали, требования к функции ошибки определяются алгоритмом оптимизации. Который, в свою очередь зависит от типа модели. У линейной регрессии будет один алгоритм (и одна функция ошибки), а у, например, решающего дерева - другой алгоритм и совершенно другая функция ошибки. Это в частности значит, что функцию ошибки невозможно применять для сравнения нескольких разных моделей, обученных на одной и той же задаче.

И вот для этого как раз и нужны метрики эффективности. Они не зависят от типа модели, а выбираются исходя из задачи и тех вопросов, ответы на которые мы хотим получить. Например, в одной задаче качество модели лучше измерять через среднеквадратическую логарифмическую ошибку, а в другой - через медианную ошибку. Как раз в этом разделе мы посмотрим на примеры разных метрик эффективности, на их особенности и сферы применения.

Кстати, это еще означает, что в каждой конкретной задаче вы можете применять сразу несколько метрик эффективности, для более глубокого понимания работы модели. Зачастую так и поступают, ведь одна метрика не может дать полной информации о сильных и слабых сторонах модели. Тут исследователи ничем не ограничены. А вот функция ошибки обязательно должна быть только одна, ведь нельзя одновременно находить минимум сразу нескольких разных функций (на самом деле можно, но многокритериальная оптимизация - это гораздо сложнее и не используется для обучения моделей).

| Функция ошибки | Метрика эффективности|
|---|---|
| Используется для организации процесса обучения | Используется для оценки качества полученной модели |
| Используется для нахождения оптимума | Используется для сравнения моделей между собой |
| Должна быть быстро вычислимой | Должна быть понятной |
| Должна конструироваться исходя их типа модели | Должна выбираться исходя из задачи |
| Может быть только одна | Может быть несколько |

Еще раз определим, эффективность - это свойство модели машинного обучения давать предсказания значения целевой переменной, как можно ближе к реальным данным. Это самая главная характеристика модели. Но надо помнить, что исходя из задачи и ее условий, к моделям могут предъявляться и другие требования, как сказали бы в программной инженерии - нефункциональные. Типичный пример - скорость работы. Иногда маленький выигрыш в эффективности не стоит того, что модель стала работать в десять раз меньше. Другой пример - интерпретируемость модели. В некоторых областях важно не только сделать точное предсказание, но и иметь возможность обосновать его, провести анализ, выработать рекомендации по улучшению ситуации и так далее. Все эти нефункциональные требования - скорость обучения, скорость предсказания, надежность, робастность, федеративность, интерпретируемость - выходят за рамки данного пособия. Здесь мы сконцентрируемся на измерении именно эффективности модели.

{% capture notice %}
Обратите внимание, что мы старательно избегаем употребления слова "точность" при описании качества работы модели. Хотя казалось бы, оно подходит как нельзя лучше. Дело в том, что "точностью" называют одну из метрик эффективности моделей классификации. Поэтому мы не хотим внести путаницу в термины.
{% endcapture %}
<div class="notice--warning">{{ notice | markdownify }}</div>

Как мы говорили, метрики эффективности не зависят от самого типа модели. Для их вычисления обычно используется два вектора - вектор эмпирических значений целевой переменной (то есть тех, которые даны в датасете) и вектор теоретических значений (то есть тех, которые выдала модель). Естественно, эти вектора должны быть сопоставимы - на соответствующих местах должны быть значения целевой переменной, соответствующие одном у и тому же объекту. И, конечно, у них должна быть одинаковая длина. То есть метрика зависит от самих предсказаний, но не от модели, которая их выдала. Причем, большинство метрик устроены симметрично - если поменять местами эти два вектора, результат не изменится. 

При рассмотрении метрик надо помнить следующее - чем выше эффективность модели, тем лучше. Но некоторые метрики устроены как измерение ошибки модели. В таком случае, конечно, тем ниже, тем лучше. Так что эффективность и ошибка модели - это по сути противоположные понятия. Так сложилось, что метрики регрессии чаще устроены именно как ошибки, а метрики классификации - как метрики именно эффективности. При использовании конкретной метрики на это надо обращать внимание.

{% capture notice %}
Выводы:
1. Метрики эффективности - это способ показать, насколько точно модель отражает реальный мир.
1. Метрики эффективность должны выбираться исходя из задачи, которую решает модель.
1. Функция ошибки и метрика эффективности - это разные вещи, к ним предъявляются разные требования.
1. В задаче можно (и, зачастую, нужно) применять несколько метрик эффективности.
1. Наряду с метриками эффективности есть и другие характеристики моделей - скорость обучения, скорость работы, надежность, робастность, интерпретируемость.
1. Метрики эффективности вычисляются как правило из двух векторов - предсказанных (теоретических) значений целевой переменной и эмпирических (реальных) значений.
1. Обычно метрики устроены таким образом, что чем выше значение, тем модель лучше.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Метрики эффективности для регрессии

Как мы говорили в предыдущем пункте, метрики зависят от конкретной задачи. А все задачи обучения с учителем разделяются на регрессию и классификацию. Совершенно естественно, что метрики для регрессии и для классификации будут разными. 

Метрики эффективности для регрессии оценивают отклонение (расстояние) между предсказанными значениями и реальными. Кажется, что это очевидно, но метрики эффективности классификации устроены по-другому. Предполагается, что чем меньше каждое конкретное отклонение, тем лучше. Разница между разными метриками в том, как учитывать индивидуальные отклонения в общей метрике и в том, как агрегировать ряд значений в один интегральный показатель.

Все метрики эффективности моделей регрессии покажутся вам знакомыми, если вы изучали математическую статистику, ведь именно статистические методы легли в основу измерения эффективности моделей машинного обучения. Причем, метрики эффективности - это лишь самые простые статистические показатели, которые можно использовать для анализа качества модели. При желании можно и нужно задействовать более мощные статистические методы исследования данных. Например, можно проанализировать вид распределения отклонений, и сделать из этого вывод о необходимость корректировки моделей. Но в 99% случаев можно обойтись простым вычислением одной или двух рассматриваемых ниже метрик.

Так как метрики эффективности позволяют интерпретировать оценку качества модели, они зачастую неявно сравнивают данную модель с некоторой тривиальной. Тривиальна модель - это очень простая, даже примитивная модель, которая выдает предсказания оценки целевой переменной абсолютно без оглядки на эффективность и вообще соответствие реальным данным. Тривиальной моделью может выступать, например, предсказание для любого объекта среднего значения целевой переменной из обучающей выборки. Такие тривиальные модели нужны, чтобы оценить, насколько данная модель лучше или хуже них.

Естественно, мы хотим получить модель, которая лучше тривиальной. Причем, у нас есть некоторый идеал - модель, которая никогда не ошибается, то есть чьи предсказания всегда совпадают с реальными значениями. Поэтому реальная модель может быть лучше тривиальной только до этого предела. У такой идеальной модели, говорят, 100% эффективность или нулевая ошибка.

Но надо помнить, что в задачах регрессии модель предсказывает непрерывное значение. Это значит, что величина отклонения может быть неограниченно большой. Так что не бывает нижнего предела качества модели. Модель регрессии может быть бесконечно далекой от идеала, бесконечно хуже даже тривиальной модели. Поэтому ошибки моделей регрессии не ограничиваются сверху (или, что то же самое, эффективность моделей регрессии не ограничивается снизу).

Поэтому в задачах регрессии

{% capture notice %}
Выводы:
1. Метрики эффективности для регрессий обычно анализируют отклонения предсказанных значений от реальных.
1. Большинство метрик пришло в машинное обучение из математической статистики.
1. Результаты работы модели можно исследовать более продвинутыми статистическими методами.
1. Обычно метрики сравнивают данную модель с тривиальной - моделью, которая всегда предсказывает среднее реальное значение целевой переменной.
1. Модель могут быть точны на 100%, но плохи они могут быть без ограничений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Коэффициент детерминации (r-квадрат)

Те, кто раньше хотя бы немного изучал математическую статистику, без труда узнают первую метрику эффективности моделей регрессии. Это так называемый коэффициент детерминации. Это доля дисперсии (вариации) целевой переменной, объясненная данной моделью. Данная метрика вычисляется по такой формуле:

{% capture block %}
$$
R^2(y, \hat{y}) = 1 - \frac
{\sum_{i=1}^n (y_i - \hat{y_i})^2}
{\sum_{i=1}^n (y_i - \bar{y_i})^2}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

где 
$y$ - вектор эмпирических (истинных) значений целевой переменной, 
$\hat{y}$ - вектор теоретических (предсказанных) значений целевой переменной,
$y_i$ - эмпирическое значение целевой переменной для $i$-го объекта,
$\hat{y_i}$ - теоретическое значение целевой переменной для $i$-го объекта,
$\bar{y_i}$ - среднее из эмпирических значений целевой переменной для $i$-го объекта.

Если модель всегда предсказывает идеально (то есть ее предсказания всегда совпадают с реальностью, другими словами, теоретические значения - с эмпирическими), то числитель дроби в формуле будет равен 0, а значит, вся метрика будет равна 1. Если же мы рассмотрим тривиальную модель, которая всегда предсказывает среднее значение, то числитель будет равен знаменателю, дробь будет равна 1, а метрика - 0. Если модель хуже идеальной, но лучше тривиальной, то метрика будет в диапазоне от 0 до 1, причем чем ближе к 1 - тем лучше.

Если же модель предсказывает такие значения, что отклонения их от теоретических получаются больше, чем от среднего значения, то числитель будет больше знаменателя, а значит, что метрика будет принимать отрицательные значения. Запомните, что отрицательные значения коэффициента детерминации означают, что модель хуже, чем тривиальная.

В целом эта метрика показывает силу линейной связи между двумя случайными величинами. В нашем случае этими величинами выступают теоретические и эмпирические значения целевой переменной (то есть предсказанные и реальные). Если модель дает точные предсказания, то будет наблюдаться сильная связь (зависимость) между теоретическим значением и реальным, то есть высокая детерминация, близкая к 1. Если эе модель дает случайные предсказания, никак не связанные с реальными значениями, то связь будет отсутствовать.

Причем так как нас интересует, насколько значения совпадают, нам достаточно использовать именно линейную связь. Ведь когда мы оцениваем связь, например, одного из факторов в целевой переменной, то связь может быть нелинейной, и линейный коэффициент детерминации ее не покажет, то есть пропустит. Но в данному случае это не важно, так как наличие нелинейной связи означает, что предсказанные значения все-таки отклоняются от реальных. Такую линейную связь можно увидеть на графике, если построить диаграмму рассеяния между теоретическими и эмпирическими значениями, вот так:

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression().fit(X, Y)
Y_ = reg.predict(X)

plt.scatter(Y, Y_)
plt.plot(Y, Y)
```

Здесь мы еще строим прямую $y = y$. Она нужна только для удобства. Вот как может выглядеть этот график:

![](/assets/images/ml_text/ml4-15.png "Зависимость в целевой переменной"){: .align-center style="width: 50%;"}

Здесь мы видим, что точки немного отклоняются от центральной линии, но в целом ей следуют. Такая картина характерна для высокого коэффициента детерминации. А вот как может выглядеть менее точная модель:

![](/assets/images/ml_text/ml4-16.png "Зависимость в целевой переменной"){: .align-center style="width: 50%;"}

И в целом, чем точки ближе к центральной линии, тем лучше модель и тем ближе коэффициент детерминации к 1.

В англоязычной литература эта метрика называется $R^2$, так как в определенных случаях она равна квадрату коэффициента корреляции. Пусть это название не вводит вас в заблуждение. Некоторые думаю, что раз метрика в квадрате, то она не может быть отрицательной. Это лишь условное название.

Пару слов об использовании метрик эффективности в библиотеке _sklearn_. Именно коэффициент детерминации чаще всего используется как метрика по умолчанию, которую можно посмотреть при помощи метода _score()_ у модели регрессии. Обратите внимание, что этот метод принимает на вход саму обучающую выборку. Это сделано для единообразия с методами наподобие _fit()_. 

Но более универсально будет использовать эту метрику независимо от модели. Все метрики эффективности собраны в отдельный пакет _metrics_. Данная метрика называется _r2_score_. Обратите внимание, что при использовании этой функции ей надо передавать два вектора целевой переменной - сначала эмпирический, а вторым аргументом - теоретический.

```py
from sklearn.metrics import r2_score

def r2(y, y_):
  return 1 - ((y - y_)**2).sum() / ((y - y.mean())**2).sum()

print(reg.score(X, Y))
print(r2_score(Y, Y_))
print(r2(Y, Y_))
```

В данном коде мы еще реализовали самостоятельный расчет данной метрики, чтобы пояснить применение формулы выше. Можете самостоятельно убедиться, что три этих вызова напечатают одинаковые значения.

Коэффициент детерминации, или $R^2$ - это одна из немногих метрик эффективности для моделей регрессии, значение которой чем больше, тем лучше. Почти все остальные измеряют именно ошибку, что мы и увидим ниже. Еще это одна из немногих несимметричных метрик. Ведь если в формуле поменять теоретические и эмпирические значения, ее смысл и значение могут поменяться. Поэтому при использовании этой метрики нужно обязательно следить за порядком передачи аргументов.

При использовании этой метрики есть один небольшой подводный камень. Так как в знаменатели у этой формулы стоит вариация реального значения целевой переменной, важно следить, чтобы эта вариация присутствовала. Ведь если реальное значение целевой переменной будет одинаковым для всех объектов выборки, то вариация этой переменной будет равна 0. А значит, метрика будет не определена. Причем это единственная причина, почему эта метрика может быть неопределена. Надо понимать, что отсутствие вариации целевой переменной ставит под сомнение вообще целесообразность машинного обучения и моделирования в целом. Ведь что нам предсказывать если $y$ всегда один и тот же? С другой стороны, такая ситуация может случиться, например, при случайном разбиении выборки на обучающую и тестовую. Но об этом мы поговорим дальше.

{% capture notice %}
Выводы:
1. Коэффициент детерминации показывает силу связи между двумя случайными величинами.
1. Если модель всегда предсказывает точно, метрика равна 1. Для тривиальной модели - 0.
1. Значение метрики может быть отрицательно, если модель предсказывает хуже, чем тривиальная.
1. Это одна из немногих несимметричных метрик эффективности.
1. Эта метрика не определена, если $y=const$. Надо следить, чтобы в выборке присутствовали разные значения целевой переменной.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Средняя абсолютная ошибка (MAE)

Коэффициент детерминации - не единственная возможная характеристика эффективности моделей регрессии. Иногда полезно оценить отклонения предсказаний от истинных значений более явно. Как раз для этого служат сразу несколько метрик ошибок моделей регрессии. Самая простая из них - средняя абсолютная ошибка (mean absolute error, MAE). Она вычисляется по формуле:

{% capture block %}
$$
MAE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1} |y_i - \hat{y_i}|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Данная метрика действительно очень проста: это средняя величина разницы между предсказанными и реальными значениями целевой переменной. Причем эта разница берется по модулю, чтобы компенсировать возможные отрицательные отклонения. Мы уже рассматривали похожую функцию, когда говорили о конструировании функции ошибки для градиентного спуска. Но тогда мы отмели использование абсолютного значения, так как эта функция не везде дифференцируема. Но вот для метрики эффективности такого требования нет и MAE вполне можно использовать.

Если модель предсказывает идеально, то, естественно, все отклонения равны 0 и MAE в целом равна нулю. Но эта метрика не учитывает явно сравнение с тривиальной моделью - она просто тем хуже, чем больше. Ниже нуля она быть, конечно, не может.

Данная метрика выражается в натуральных единицах и имеет очень простой и понятный смысл - средняя ошибка модели. Степень применимости модели в таком случае можно очень просто понять исходя из предметной области. Например, наша модель ошибается в среднем на 500 рублей. Хорошо это или плохо? Зависит от размерности исходных данных. Если мы предсказываем цены на недвижимость - то модель прекрасно справляется с задачей. Если же мы моделируем цены на спички - то такая модель скорее всего очень неэффективна.

Использование данной метрики в пакете _sklearn_ очень похоже на любую другую метрику, меняется только название:

```py
>>> from sklearn.metrics import mean_absolute_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_absolute_error(y_true, y_pred)
0.5
```

{% capture notice %}
Выводы:
1. MAE показывает среднее абсолютное отклонение предсказанных значений от реальных.
1. Чем выше значение MAE, тем модель хуже. У идеальной модели $MAE=0$
1. MAE очень легко интерпретировать - на сколько в среднем ошибается модель.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Средний квадрат ошибки (MSE)

Средний квадрат ошибки (mean squared error, MSE) очень похож на предыдущую метрику, но вместо абсолютного значения (модуля) используется квадрат:

{% capture block %}
$$
MSE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1} (y_i - \hat{y_i})^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Граничные случаи у этой метрики такие же, как у предыдущей - 0 у идеальной модели, а в остальном - чем больше, тем хуже. MSE у тривиальной модели будет равна дисперсии целевой переменной. Но это не то, чтобы очень полезно на практике.

Эта метрика используется во многих моделях регрессии как функция ошибки. Но вот как метрику эффективности ее применяют довольно редко. Дело в ее интерпретируемости. Ведь она измеряется в квадратах натуральной величины. А какой физический смысл имеют, например, рубли в квадрате? На самом деле никакого. Поэтому несмотря на то, что математически MAE и MSE в общем-то эквивалентны, первая более проста и понятна, и используется гораздо чаще.

Единственное существенное отличие данной метрики от предыдущей состоит в том, что она чуть больший "вес" в общей ошибке придает большим значениям отклонений. То есть чем больше значение отклонения, тем сильнее оно будет вкладываться в значение MSE. Это иногда бывает полезно, когда исходя из задачи стоит штрафовать сильные отклонения предсказанных значений от реальных. Но с другой стороны это свойство делает эту метрику чувствительной к аномалиям.

Пример расчета метрики MSE:

```py
>>> from sklearn.metrics import mean_squared_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_squared_error(y_true, y_pred, squared=False)
0.612...
```

{% capture notice %}
Выводы:
1. MAE показывает средний квадрат отклонений предсказанных значений от реальных.
1. Чем выше значение MSE, тем модель хуже. У идеальной модели $MSE=0$
1. MSE больше учитывает сильные отклонения, но хуже интерпретируется, чем MAE.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Среднеквадратичная ошибка (RMSE)

Если главная проблема метрики MSE в том, что она измеряется в квадратах натуральных величин, что что будет, если мы возьмем от нее квадратный корень? Тогда мы получим среднеквадратичную ошибку (root mean squared error, RMSE):

{% capture block %}
$$
RMSE(y, _\hat{y}) = \sqrt{\frac{1}{n} \sum_{i=0}^{n-1} (y_i - \hat{y_i})^2}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Использование данной метрики достаточно привычно при статистическом анализе данных. Однако, для интерпретации результатов машинного обучения она имеет те же недостатки, что и MSE. Главный из них - чувствительность к аномалиям. Поэтому при интерпретации эффективности моделей регрессии чаще рекомендуется применять метрику MAE.

Пример использования:

```py
>>> from sklearn.metrics import mean_squared_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_squared_error(y_true, y_pred)
0.375
```

{% capture notice %}
Выводы:
1. RMSE - это по сути корень из MSE. Выражается в тех же единицах, что и целевая переменная.
1. Чаще применяется при статистическом анализа данных.
1. Данная метрика очень чувствительна к аномалиям и выбросам.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Среднеквадратичная логарифмическая ошибка (MSLE)

Еще одна довольно редкая метрика - среднеквадратическая логарифмическая ошибка (mean squared logarithmic error, MSLE). Она очень похожа на MSE, но квадрат вычисляется не от самих отклонений, а от разницы логарифмов (про то, зачем там +1 поговорим позднее):

{% capture block %}
$$
MSLE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1} (
ln(1 + y_i) - ln(1 + \hat{y_i})
)^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Данная материка имеет специфическую, но довольно полезную сферу применения. Она применяется в тех случаях, когда значения целевой переменной простираются на несколько порядков величины. Например, если мы анализируем доходы физических лиц, они могут измеряться от тысяч до сотен миллионов. Понятно, что при использовании более привычных метрик, таких как MSE, RMSE и даже MAE, отклонения в больших значениях, даже небольшие относительно, будут полностью доминировать над отклонениями в малых значениях. 

Это приведет к тому, что оценка моделей в подобных задачах классическими метриками будет давать преимущество моделям, которые более точны в одной части выборки, но почти не будут учитывать ошибки в других частях выборки. Это может привести к несправедливой оценке моделей. А вот использование логарифма поможет сгладить это противоречие.

Чаще всего, величины с таким больших размахом, что имеет смысл использовать логарифмическую ошибку, возникают в тех задачах, которые моделируют некоторые естественные процессы, характеризующиеся экспоненциальным ростом. Например, моделирование популяций, эпидемий, финансов. Такие процессы часто порождают величины, распределенные по экспоненциальному закону. А они чаще всего имеют область значений от нуля до плюс бесконечности, то есть иногда могут обращаться в ноль.

Проблема в том, что логарифм от нуля не определен. Именно поэтому в формуле данной метрики присутствует +1. Это искусственный способ избежать неопределенности. Конечно, если вы имеете дело с величиной, которая может принимать значение -1, то у вас опять будут проблемы. Но на практике такие особые распределения не встречаются почти никогда. 

Использование данной метрике в коде полностью аналогично другим:

```py
>>> from sklearn.metrics import mean_squared_log_error
>>> y_true = [3, 5, 2.5, 7]
>>> y_pred = [2.5, 5, 4, 8]
>>> mean_squared_log_error(y_true, y_pred)
0.039...
```

{% capture notice %}
Выводы:
1. MSLE это среднее отклонение логарифмов реальных и предсказанных данных.
1. Так же, идеальная модель имеет $MSLE = 0$.
1. Данная метрика используется, когда целевая переменная простирается на несколько порядков величины.
1. Еще эта метрика может быть полезна, если моделируется процесс в экспоненциальным ростом.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Среднее процентное отклонение (MAPE)

Все метрики, которые мы рассматривали до этого рассчитывали абсолютную величину отклонения. Но ведь отклонение в 5 единиц при истинном значении 5 и при значении в 100 - разные вещи. В первом случае мы имеем ошибку в 100%, а во втором - только в 5%. Очевидно, что первый и второй случай должны по-разному учитываться в ошибке. Для этого придумана средняя абсолютная процентная ошибка (mean absolute percentage error, MAPE). В ней каждое отклонение оценивается в процентах от истинного значения целевой переменной:

{% capture block %}
$$
MAPE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1}
\frac{|y_i - \hat{y_i}|}{max(\epsilon, |y_i|)}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Эта метрика имеет одно критическое преимущество над остальными - с ее помощью можно сравнивать эффективность моделей на разных обучающих выборках. Ведь если мы возьмем классические метрики (например, MAE), то размер отклонений будет очевидно зависеть от самих данных. А в двух разных выборках и средняя величина скорее всего будет разная. Поэтому метрики MAE, MSE, RMSE, MSLE не сопоставимы при сравнении предсказаний, сделанных на разных выборках.

А вот по метрике MAPE можно сравнивать разные модели, которые были обучены на разных данных. Это очень полезно, например, в научных публикациях, где метрика MAPE (и ее вариации) практически обязательны для описания эффективности моделей регрессии.Ведь если одна модель ошибается в среднем на 3,9%, а другая - на 3,5%, очевидно, что вторая более точна. А вот если оперировать той же MAE, так сказать нельзя. Ведь если одна модель ошибается в среднем на 500 рублей, а вторая - на 490, очевидно ли, что вторая лучше? Может, она даже хуже, просто в исходных данных величина целевой переменной во втором случае была чуть меньше.

При этом у метрики MAPE есть пара недостатков. Во-первых, она не определена, если истинное значение целевой переменной равно 0. Именно для преодоления этого в знаменателе формулы этой метрики присутствует $max(\epsilon, \|y_i\|)$. $\epsilon$ - это некоторое очень маленькое значение. Оно нужно только для того, чтобы избежать деления на ноль. Это, конечно, настоящий математический костыль, но позволяет без опаски применять эту метрику на практике.

Во-вторых, данная метрика дает преимущество более низким предсказаниям. Ведь если предсказание ниже, чем реальное значение, процентное отклонение может быть от 0% до 100%. В это же время если предсказание выше реального, то верхней границы нет, предсказание может быть больше и на 200%, и на 1000%.

В-третьих, эта метрика несимметрична. Ведь в этой формуле $y$ и $\hat{y}$ не взаимозаменяемы. Это не большая проблема и может быть исправлена использованием симметричного варианта этой метрики, который называется SMAPE (symmetric mean absolute percentage error):

{% capture block %}
$$
MAPE(y, _\hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1}
\frac{|y_i - \hat{y_i}|}{max(\epsilon, (|\hat{y_i}|, |y_i|) / 2)}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В русскоязычной литературе данная метрика часто называется относительной ошибкой, так как она учитывает отклонение относительно целевого значения. В английском названии метрики она называется абсолютной. Тут нет никакого противоречия, так как "абсолютный" здесь значит просто взятие по модулю.

С точки зрения использования в коде, все полностью аналогично:

```py
>>> from sklearn.metrics import mean_absolute_percentage_error
>>> y_true = [1, 10, 1e6]
>>> y_pred = [0.9, 15, 1.2e6]
>>> mean_absolute_percentage_error(y_true, y_pred)
0.2666...
```

{% capture notice %}
Выводы:
1. Идея этой метрики - это чувствительность к относительным отклонениям.
1. Данная модель выражается в процентах и имеет хорошую интерпретируемость.
1. Идеальная модель имеет $MAPE = 0$. Верхний предел - не ограничен.
1. Данная метрика отдает предпочтение предсказанию меньших значений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Абсолютная медианная ошибка

Практически во всех ранее рассмотренных метриках используется среднее арифметическое для агрегации частных отклонений в общую величину ошибки. Иногда это может быть не очень уместно, если в выборке присутствует очень неравномерное распределение по целевой переменной. В таких случаях может быть целесообразно использование медианной ошибки:

{% capture block %}
$$
MedAE(y, _\hat{y}) = \frac{1}{n} median_{i=0}^{n-1}
|y_i - \hat{y_i}|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Эта метрика полностью аналогична MAE за одним исключением: вместо среднего арифметического подсчитывается медианное значение. Медиана - это такое значение в выборке, больше которого и меньше которого примерно половина объектов выборки (с точностью до одного объекта).

Эта метрика чаще всего применяется при анализе демографических и экономических данных. Ее особенность в том, что она не так чувствительна к выбросам и аномальным значениям, ведь они практически не влияют на медианное значение выборки, что делает эту метрику более надежной и робастной, чем абсолютная ошибка.

Пример использования:

```py
>>> from sklearn.metrics import median_absolute_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> median_absolute_error(y_true, y_pred)
0.5
```

{% capture notice %}
Выводы:
1. Медианная абсолютная ошибка похожа на среднюю абсолютную, но более устойчива к аномалиям.
1. Применяется в задачах, когда известно, что в данных присутствуют выбросы, аномальные , непоказательные значения.
1. Эта метрика более робастная, нежели MAE. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Максимальная ошибка

Еще одна достаточно экзотическая, но очень простая метрика эффективности регрессии - максимальная ошибка:

{% capture block %}
$$
ME(y, _\hat{y}) = max_{i=0}^{n-1}
|y_i - \hat{y_i}|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Как следует из названия, это просто величина максимального абсолютного отклонения предсказанных значений от теоретических. Особенность этой метрики в том, что она вообще не характеризует распределение отклонений в целом. Поэтому она практически никогда не применяется самостоятельно, в качестве единственной метрики.

Эта метрика именно вспомогательная. В сочетании с другими метриками, она может дополнительно охарактеризовать, насколько сильно модель может ошибаться в самом худшем случае. Опять же, в зависимости от задачи, это может быть важно. В некоторых задачах модель, которая в среднем ошибается пусть чуть больше, но при этом не допускает очень больших "промахов", может быть предпочтительнее, чем более точная модель в среднем, но у которой встречаются сильные отклонения.

Применение этой метрики та же просто, как и других:

```py
>>> from sklearn.metrics import max_error
>>> y_true = [3, 2, 7, 1]
>>> y_pred = [9, 2, 7, 1]
>>> max_error(y_true, y_pred)
6
```

{% capture notice %}
Выводы:
1. Максимальная ошибка показывает наихудший случай предсказания модели.
1. В некоторых задачах важно, чтобы модель не ошибалась сильно, а небольшие отклонения не критичны.
1. Зачастую эта метрика используется как вспомогательная совместно с другими.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Метрики эффективности для классификации

Приступим к рассмотрению метрик эффективности, которые применяются для оценки моделей классификации. Для начала ответим на вопрос, почему для них нельзя использовать те метрики, которые мы уже рассмотрели в предыдущей части? Дело в том, что метрики эффективности регрессии так или иначе оценивают расстояние от предсказанного значения до реального. Это подразумевает, что в значениях целевой переменной существует определенный порядок. Формально говоря, предполагается, что целевая переменная измеряется по относительной шкале. Это значит, что разница между значениями имеет какой-то смысл. Например, если мы ошиблись в предполагаемой цене товара на 10 рублей, это лучше, чем ошибка на 20 рублей. Причем, можно сказать, что это в два раза лучше. 

Но вот целевые переменные, которые существуют в задачах классификации обычно не обладают таким свойством. Да, метки классов часто обозначают числами (класс 0, класс 1, класс 5 и так далее). И мы используем эти числа в качестве значения переменных в программе. Но это ничего не значит. Представим объект, принадлежащий 0 классу, что бы этот класс не значил. Допустим, мы предсказали 1 класс. Было бы хуже, если бы мы предсказали 2 класс. Можно ли сказать, что во втором случае модель ошиблась в два раза сильнее? В общем случае, нельзя. Что в первом, что во втором случае модель просто ошиблась. Имеет значение только разница между правильным предсказанием и неправильным. Отклонение в задачах классификации не играет роли.

Поэтому метрики эффективности для классификации оценивают количество правильно и неправильно классифицированных (иногда еще говорят, распознанных) объектов. При этом разные метрики, как мы увидим, концентрируются на разных соотношениях этих количеств, особенно в случае, когда классов больше двух, то есть имеет место задача множественной классификации.

Причем метрики эффективности классификации тоже нельзя применять для оценки регрессионных моделей. Дело в том, что в задачах регрессии почти никогда не встречается полное совпадение предсказанного и реального значения. Так как мы работам с непрерывным континуумом значений, вероятность такого совпадения равна, буквально, нулю. Поэтому по метрикам для классификации практически любая регрессионная модель будет иметь нулевую эффективность, даже очень хорошая и точная модель. Именно потому, что для метрик классификации даже самая небольшая ошибка уже считается как промах.

Как мы говорили ранее,для оценки конкретной модели можно использовать несколько метрик одновременно. Это хорошая практика для задач регрессии, но для классификации - это практически необходимость. Дело в том, что метрики классификации гораздо легче "обмануть" с помощью тривиальных моделей, особенно в случае несбалансированных классов (об этом мы поговорим чуть позже). Тривиальной моделью в задачах классификации может выступать модель, которая предсказывает случайный класс (такая используется чаще всего), либо которая предсказывает всегда какой-то определенный класс.

Надо обратить внимание, что по многим метрикам, ожидаемая эффективность моделей классификации сильно зависит от количества классов в задаче. Чем больше классов, тем на меньшую эффективность в среднем можно рассчитывать.Поэтому метрики эффективности классификации не позволяют сопоставить задачи, состоящие из разного количества классов. Это следует помнить при анализе моделей. Если точность бинарной классификации составляет 50%, это значит, что модель работает не лучше случайного угадывания. Но в модели множественной классификации из, допустим, 10 000 классов, точность 50% - это существенно лучше случайного гадания.

Еще обратим внимание, что некоторые метрики учитывают только само предсказание, в то время, как другие - степень уверенности модели в предсказании. Вообще, все модели классификации разделяются на логические и метрические. Логические методы классификации выдают конкретное значение класса, без дополнительной информации. Типичные примеры - дерево решений, метод ближайших соседей. Метрические же методы выдают степень уверенности (принадлежности) объекта к одному или, чаще, ко всем классам. Так, например, работает метод логистической регрессии в сочетании с алгоритмом "один против всех". Так вот, в зависимости, от того, какую модель классификации вы используете, вам могут быть доступны разные метрики. Те метрики, которые оценивают эффективность классификации в зависимости от выбранной величины порога не могут работать с логическими методами. Поэтому, например, нет смысла строить PR-кривую для метода ближайших соседей. Остальные метрики, которые не используют порог, могут работать с любыми методами классификации.

{% capture notice %}
Выводы:
1. Метрики эффективности классификации подсчитывают количество правильно распознанных объектов.
1. В задачах классификации почти всегда надо применять несколько метрик одновременно.
1. Тривиальной моделью в задачах классификации считается та, которая предсказывает случайный класс, либо самый популярный класс.
1. Качество бинарной классификации при прочих равных почти всегда будет сильно выше, чем для множественной.
1. Вообще, чем больше в задаче классов, тем ниже ожидаемые значения эффективности.
1. Некоторые метрики работают с метрическими методами, другие - со всеми.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Доля правильных ответов (accuracy)

Если попробовать самостоятельно придумать способ оценить качество модели классификации, ничего не зная о существующих метриках, скорее всего получится именно метрика точности (accuracy). Это самая простая и естественная метрика эффективности классификации. Она подсчитывается как количество объектов в выборке, которые были классифицированы правильно (то есть, для которых теоретическое и эмпирическое значение метки класса - целевой переменной - совпадает), разделенное на общее количество объектов выборки. Вот формула для вычисления точности классификации:

{% capture block %}
$$ 
acc(y, \hat{y}) = \frac{1}{n} \sum_{i=0}^{n} 1(\hat{y_i} = y_i) 
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В этой формуле используется так называемая индикаторная функция $1()$. Эта функция равна 1 тогда, когда ее аргумент - истинное выражение, и 0 - если ложное. В данном случае она равна единице для всех объектов, у которых предсказанное значение равно реальному ($\hat{y_i} = y_i$). Суммируя по всем объектам мы получим количество объектов, классифицированных верно. Перед суммой стоит множитель $\frac{1}{n}$, где $n$ - количество объектов в выборке. То есть в итоге мы получаем долю правильных ответов исследуемой модели.

Значение данной метрики может быть выражено в долях единицы, либо в процентах, домножив значение на 100%. Чем выше значение accuracy, тем лучше модель классифицирует выборку, то есть тем лучше ответы модели соответствуют значениям целевой переменной, присутствующим в выборке. Если модель всегда дает правильные предсказания, то ее accuracy будет равн 1 (или 100%). Худшая модель, которая всегда предсказывает неверно будет иметь accuracy, равную нулю, причем это нижняя граница, хуже быть не может.

{% capture notice %}
В дальнейшем, для обозначения названий метрик эффективности я буду использовать именно английские названия - accuracy, precision, recall. У каждого из этих слов есть перевод на русский, но так случилось, что в русскоязычных терминах существует путаница. Дело в том, что и accuracy и precision чаще всего переводятся словом "точность". А это разные метрики, имеющие разный смысл и разные формулы. Accuracy еще называют "правильность", precision - "прецизионность". Причем у последнего термина есть несколько другое значение в метрологии. Поэтому, пока будем обозначать эти метрики изначальными названиями.
{% endcapture %}
<div class="notice--warning">{{ notice | markdownify }}</div>

А вот accuracy тривиальной модели будет как раз зависеть от количества классов. Если мы имеем дело с бинарной классификацией, то модель будет ошибаться примерно в половине случаев. То есть ее accuracy будет 0,5. В общем же случае, если есть $m$ классов, то тривиальная модель, которая предсказывает случайный класс будет иметь accuracy в среднем около $\frac{1}{m}$.

Но это в случае, если в выборке объекты разных классов встречаются примерно поровну. В реальности же часто встречаются несбалансированные выборки, в которых распределение объектов по классам очень неравномерно. Например, может быть такое, что объектов одного класса в десять раз больше, чем другого. В таком случае, accuracy тривиальной модели может быть как выше, так и ниже $1/m$. Вообще, метрика accuracy очень чувствительна к соотношению классов в выборке. И именно поэтому мы рассматриваем другие способы оценки качества моделей классификации.

Использование метрики accuracy в библиотеке _sklearn_ ничем принципиальным не отличается от использования других численных метрик эффективности:

```py
>>> import numpy as np
>>> from sklearn.metrics import accuracy_score
>>> y_pred = [0, 2, 1, 3]
>>> y_true = [0, 1, 2, 3]
>>> accuracy_score(y_true, y_pred)
0.5
```

В данном примере в задаче 4 класса (0, 1, 2, 3) и столько же объектов, по одному на каждый класс. Модель правильно классифицировала первый и третий объект, то есть половину. Поэтому ее accuracy составляет 0,5 или 50%.

{% capture notice %}
Выводы:
1. Точность (accuracy) - самая простая метрика качества классификации, доля правильных ответов.
1. Может быть выражена в процентах и в долях единицы.
1. Идеальная модель дает точность 1.0, тривиальная - 0.5, самая худшая - 0.0.
1. Тривиальная модель в множественной сбалансированной задаче классификации дает точность 1/m.
1. Метрика точности очень чувствительная к несбалансированности классов.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Матрица классификации

```py
>>> from sklearn.metrics import confusion_matrix
>>> y_true = [2, 0, 2, 2, 0, 1]
>>> y_pred = [0, 0, 2, 2, 0, 2]
>>> confusion_matrix(y_true, y_pred)
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])
```

![Classification matrix](https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png "Classification matrix"){: .align-center style="width: 800px;"}
Источник: [sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. Матрица классификации, или матрица ошибок представляет собой количество объектов по двум осям - истинный класс и предсказанный класс.
1. Обычно, истинный класс располагается по строкам, а предсказанный - по столбцам.
1. Для идеальной модели матрица должна содержать ненулевые элементы только на главной диагонали.
1. Матрица позволяет наглядно представить результаты классификации и увидеть, в каких случаях модель делает ошибки.
1. Матрица незаменима при анализе ошибок, когда исследуется, какие объекты были неправильно классифицированы.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Метрики классификации для неравных классов (precision, recall, F1)

Как мы говорили ранее, метрика accuracy может быть чувствительна к несбалансированности классов. Рассмотрим типичный пример - диагностика заболевания. Допустим, в случайной выборке людей заболевание встречается один раз на 100 человек. То есть в выборке у нас может быть всего 1% объектов, принадлежащих положительному классу и 99% - отрицательному, то есть почти в 100 раз больше. Какая accuracy будет у абсолютно тривиальной модели, которая всегда предсказывает отрицательный класс? Такая модель будет права в 99% случаев и ошибаться только в 1%. То есть иметь accuracy 0,99. Естественно, ценность такой модели минимальна, несмотря на высокий показатель метрики. Поэтому в случае с сильно несбалансированными классами метрика accuracy не то, чтобы неверна, она непоказательна, то есть не дает хорошего представления о качественных характеристиках модели. 

Для более полного описания модели используется ряд других метрик. Для того, чтобы понять, как они устроены и что показывают нужно разобраться с понятием ошибок первого и второго рода. Пока будем рассматривать случай бинарной классификации, а о том, как эти метрики обобщаются на множественные задачи, поговорим позднее. Итак, у нас есть задача бинарной классификации, объекты положительного и отрицательного класса. Идеальным примером для этого будет все та же медицинская диагностика.

По отношению к модели бинарной классификации все объекты выборки можно разделить на четыре непересекающихся множества. Истинноположительные (true positive, TP) - это те объекты, которые отнесены моделью к положительному классу и действительно ему принадлежат. Истинноотрицательные (true negative, TN) - соответственно те, которые правильно распознаны моделью как принадлежащие отрицательному классу. Ложноположительные объекты (FP, false positive) - это те, которые модель распознала как положительные, хотя на самом деле они отрицательные. В математической статистике такая ситуация называется ошибкой первого рода. И, наконец, ложноотрицательные значения (false negative, FN) - это те, которые ошибочно отнесены моделью к отрицательному классу, хотя на самом деле они принадлежат положительному.

В примере с медицинско диагностикой, ложноположительные объекты или ошибки первого рода - это здоровые пациенты, которых при диагностике ошибочно назвали больными. Ложноотрицательные, или ошибки второго рода, - это больные пациенты, которых диагностическая модель "пропустила", ошибочно приняв за здоровых. Очевидно, что в этой задаче, как и во многих других, ошибки первого и второго рода не равнозначны. В медицинской диагностике, например, гораздо важнее распознать всех здоровых пациентов, то есть не допустить ложноотрицательных объектов или ошибок второго рода. Ошибки же первого рода, или ложноположительные предсказания, тоже нежелательны, но значительно меньше, чем ложноотрицательные.

Так вот, метрика accuracy учитывает и те и другие ошибки одинаково, абсолютно симметрично. В терминах наших четырех классов она может выражаться такой формулой:

$$
A = \frac{TP + TN}{TP + TN + FP + FN}
$$

Обратите внимание, что если в модели переименовать положительный класс в отрицательный и наоборот, то это никак не повлияет на accuracy. Так вот, в зависимости от решаемой задачи, нам может быть необходимо воспользоваться другими метриками. Вообще, их существует большое количество, но на практике чаще других применяются метрики precision и recall.

Precision (чаще переводится как "точность", "прецизионность") - это доля объектов, плавильно распознанных как положительные из всех, распознанных как положительные. Считается этот показатель по следующей формуле: $P = \frac{TP}{TP + FP}$. Как можно видеть, precision будет равен 1, если модель не делает ошибок первого рода, то есть не дает ложноположительных предсказаний. Причем ошибки второго рода (ложноотрицательные) вообще не влияют на величину precision, так как эта метрика рассматривает только объекты, отнесенные моделью к положительным.

Precision характеризует способность модели отличать положительный класс от отрицательного, не делать ложноположительных предсказаний. Ведь если мы будем всегда предсказывать отрицательный класс, precision будет не определен. А вот если модель будет всегда предсказывать положительный класс, то precision будет равен доли объектов этого класса в выборке. В нашем примере с медицинской диагностикой, модель, всех пациентов записывающая в больные даст precision всего 0,01.

Метрика recall (обычно переводится как "полнота" или "правильность") - это доля положительных объектов выборки, распознанных моделью. То есть это отношение все тех же истинноположительных объектов к числу всех положительных объектов выборки: $R = \frac{TP}{TP + FN}$. Recall будет равен 1 только в том случае, если модель не делает ошибок второго рода, то есть не дает ложноотрицательных предсказаний. А вот ошибки первого рода (ложноположительные) не влияют на эту метрику, так как она рассматривает только объекты, которые на самом деле принадлежат положительному классу. 

Recall характеризует способность модели обнаруживать все объекты положительного класса. Если мы будем всегда предсказывать отрицательный класс, то данная метрика будет равна 0, а если всегда положительный - то 1. Метрика Recall еще называется 

В примере с медицинской диагностикой нам гораздо важнее, как мы говорили, не делать ложноотрицательных предсказаний. Поэтому метрика recall будет для нас важнее, чем recision и даже accuracy. Однако, как видно из примеров, каждый из этих метрик легко можно максимизировать довольно тривиальной моделью. Если мы будет ориентироваться на recall, то наилучшей моделью будет считаться та, которая всегда предсказывает положительный класс. Если только на precision - то "выиграет" модель, которая всегда предсказывает наоборот, положительный. А если брать в расчет только accuracy, то при сильно несбалансированных классах модель, предсказывающая самый популярный класс. Поэтому эти метрики нелья использовать по отдельности, только сразу как минимум две из них. 

{% capture block %}
$$
P = \frac{TP}{TP + FP} \\
R = \frac{TP}{TP + FN} \\
S = \frac{TN}{TN + FP}
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

![PR_F1](/assets/images/ml_text/ml4-1.png "PR_F1"){: .align-center style="width: 800px;"}

```py
>>> from sklearn import metrics
>>> y_pred = [0, 1, 0, 0]
>>> y_true = [0, 1, 0, 1]
>>> metrics.precision_score(y_true, y_pred)
1.0
>>> metrics.recall_score(y_true, y_pred)
0.5
>>> metrics.f1_score(y_true, y_pred)
0.66...
```

{% capture notice %}
Выводы:
1. Если классы в задаче не сбалансированы, то метрика точности не дает полного представления о качестве работы моделей.
1. Для бинарной классификации подсчитывается количество истинно положительных, истинно отрицательных, ложно положительных и ложно отрицательных объектов.
1. Прецизионность (precision) - доля истинно положительных объектов во всех, распознанных как положительные.
1. Прецизионность характеризует способность модели не помечать положительные объекты как отрицательные (не делать ложно положительных прогнозов).
1. Правильность (recall) - для истинно положительных объектов во всех положительных.
1. Правильность характеризует способность модели выявлять все положительные объекты (не делать ложно отрицательных прогнозов).
1. F1 - среднее гармоническое между этими двумя метриками. F1 - это частный случай. Вообще, семейство F-метрик - это взвешенное среднее гармоническое.
1. Часто используют все вместе для более полной характеристики модели.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### PR-AUC

![PR_AUC](https://scikit-learn.org/stable/_images/sphx_glr_plot_precision_recall_001.png "PR_AUC"){: .align-center style="width: 800px;"}
Источник: [sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. Кривая precision-recall используется для методов метрической классификации, которые выдают вероятность принадлежности объекта данному классу.
1. Дискретная классификации производится при помощи порогового значения.
1. Чем больше порог, тем больше объектов модель будет относить к отрицательному классу.
1. Повышение порога в среднем увеличивает прецизионность модели, но понижает правильность.
1. PR-кривая используется чтобы выбрать оптимальное значение порога.
1. PR-кривая нужна для того, чтобы сравнивать и оценивать модели вне зависимости от выбранного уровня порога.
1. PR-AUC - площадь под PR-кривой, у лучшей модели - 1.0б у тривиальной - 0.5, у худшей - 0.0.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Метрики для множественной классификации

```py
>>> from sklearn import metrics
>>> y_true = [0, 1, 2, 0, 1, 2]
>>> y_pred = [0, 2, 1, 0, 0, 1]
>>> metrics.precision_score(y_true, y_pred, average='macro')
0.22...
>>> metrics.recall_score(y_true, y_pred, average='micro')
0.33...
>>> metrics.f1_score(y_true, y_pred, average='weighted')
0.26...
>>> metrics.fbeta_score(y_true, y_pred, average='macro', beta=0.5)
0.23...
```

![MultiPR](https://scikit-learn.org/0.15/_images/plot_precision_recall_0011.png "MultiPR"){: .align-center style="width: 800px;"}
Источник: [sklearn](https://www.google.com/url?sa=i&url=https%3A%2F%2Fscikit-learn.org%2F0.15%2Fauto_examples%2Fplot_precision_recall.html&psig=AOvVaw15eJNKyR29Xy4Zqjn9s-jS&ust=1653408447730000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCND5hs2A9vcCFQAAAAAdAAAAABAI).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. Для множественной классификации точность считается традиционно, а все остальные метрики - отдельно для каждого класса.
1. Каждую метрику можно усреднить арифметически или взвешенно по классам. Весами выступают объемы классов.
1. В модуле sklearn реализовано несколько алгоритмов усреднения они выбираются исходя их задачи.
1. В случае средневзвешенного, F1-метрика может получиться не между P и R. 
1. PR-кривая тоже может строиться для каждого класса отдельно, либо кривая средних значений P и R. 
1. Метрика PR_AUC считается по кривой средних значений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>


#### Отчет о классификации

```py
>>> from sklearn.metrics import classification_report
>>> y_true = [0, 1, 2, 2, 0]
>>> y_pred = [0, 0, 2, 1, 0]
>>> target_names = ['class 0', 'class 1', 'class 2']
>>> print(classification_report(y_true, y_pred, target_names=target_names))
#              precision    recall  f1-score   support
#
#     class 0       0.67      1.00      0.80         2
#     class 1       0.00      0.00      0.00         1
#     class 2       1.00      0.50      0.67         2
#
#    accuracy                           0.60         5
#   macro avg       0.56      0.50      0.49         5
#weighted avg       0.67      0.60      0.59         5
```

{% capture notice %}
Выводы:
1. Отчет о классификации содержит всю необходимую информацию в стандартной форме.
1. Отчет показывает метрики для каждого класса, а так же объем каждого класса.
1. Также отчет показывает средние и средневзвешенные метрики для всей модели.
1. Отчет предполагает, что порог уже выбран.
1. Отчет о классификации - обязательный элемент представления результатов моделирования.
1. По отчету можно понять сбалансированность задачи, какие классы определяются лучше, какие - хуже.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### ROC_AUC

$$
TPR = \frac{TP}{TP + FN} = R \\
FRP = \frac{FP}{TN + FP} = 1 - S
$$

```py
>>> import numpy as np
>>> from sklearn.metrics import roc_curve
>>> y = np.array([1, 1, 2, 2])
>>> scores = np.array([0.1, 0.4, 0.35, 0.8])
>>> fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)
>>> fpr
array([0. , 0. , 0.5, 0.5, 1. ])
>>> tpr
array([0. , 0.5, 0.5, 1. , 1. ])
>>> thresholds
array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])
```

![ROC_AUC](https://scikit-learn.org/stable/_images/sphx_glr_plot_roc_001.png "ROC_AUC"){: .align-center style="width: 800px;"}
Источник: [sklearn](https://scikit-learn.org/stable/_images/sphx_glr_plot_roc_001.png).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. ROC-кривая показывает качество бинарной классификации при разных значениях порога.
1. В отличие от PR-кривой, ROC-кривая монотонна.
1. Площадь под графиком ROC-кривой, ROC_AUC - одна из основных метрик качества классификационных моделей. 
1. ROC_AUC можно использовать для сравнения качества разных моделей, обученных на разных данных.
1. Для множественной классификации также есть несколько алгоритмов усредения (но они устроены немного иначе).
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Топ k классов

{% capture block %}
$$ 
tka(y, \hat{f}) = \frac{1}{n} \sum_{i=0}^{n-1} 
\sum_{j=1}^{k} 1(\hat{f_{ij}} = y_i) 
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>


```py
>>> import numpy as np
>>> from sklearn.metrics import top_k_accuracy_score
>>> y_true = np.array([0, 1, 2, 2])
>>> y_score = np.array([[0.5, 0.2, 0.2],
...                     [0.3, 0.4, 0.2],
...                     [0.2, 0.4, 0.3],
...                     [0.7, 0.2, 0.1]])
>>> top_k_accuracy_score(y_true, y_score, k=2)
0.75
```

{% capture notice %}
Выводы:
1. Эта метрика - обобщение точности для случая, когда модель выдает вероятности отнесения к каждому классу.
1. Вычисляется как доля объектов, для которых правильный класс попадает в список k лучших предсказанных классов.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Проблема пере- и недообучения

#### Проблема Bias/Variance

![Bias-variance](/assets/images/ml_text/ml4-11.png "Bias-variance"){: .align-center style="width: 800px;"}

![Bias-variance](/assets/images/ml_text/ml4-3.png "Bias-variance"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Прежде чем обучать модель, нужно выбрать ее вид (параметрическое семейство функций).
1. Разные модели при своих оптимальных параметрах будут давать разный результат.
1. Чем сложнее и вариативнее модель, тем больше у нее параметров.
1. Простые модели быстрые, но им недостает вариативности, изменчивости, у них высокое смещение (bias).
1. Сложные модели могут описывать больше зависимостей, но вычислительно более трудоемкие и имеют большую дисперсию (variance).
1. Слишком вариативные (сложные) модели алгоритм может подстраиваться под случайный шум в данных - переобучение.
1. Слишком смещенные (простые) модели алгоритм может пропустить связь признака и целевой переменной - недообучение.
1. Не всегда модель, которая лучше подстраивается под данные (имеет более высокие метрики эффективности) лучше.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Обобщающая способность модели, тестовый набор

![Test set](/assets/images/ml_text/ml4-12.png "Test set"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Цель разработки моделей машинного обучения - не описывать обучающий набор (мы уже знаем ответы), а на его примере описывать другие объекты реального мира.
1. Главное качество модели - описывать объекты, которых она не видела при обучении - обобщающая способность.
1. Для того, чтобы оценить обобщающую способность модели нужно вычислить метрики эффективности на новых данных.
1. Для этого исходный датасет разбивают на обучающую и тестовую выборки. Делить можно в любой пропорции, обычно 80-20.
1. Обучающая выборки используется для подбора параметров модели (обучения), а тестовая - для оценки ее эффективности.
1. Никогда не оценивайте эффективность модели на тех же данных, на которых она училась - оценка получится слишком оптимистичная.
1. Ошибка или эффективность на тестовых данных дает несмещенную оценку качества модели, ее предсказательной силы.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Кривые обучения

![Learning curve](/assets/images/ml_text/ml4-6.png "Learning curve"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Кривая обучения - это зависимость эффективности модели от размера обучающей выборки.
1. Для построения кривых обучения модель обучают много раз, каждый раз с другим размером обучающей выборки (от одного элемента до всех, что есть).
1. При малых объемах обучающая эффективность будет очень большой, а тестовая - очень маленькой.
1. При увеличении объема обучающей выборки они будут сходиться, но обычно тестовая эффективность всегда ниже обучающей.
1. Кривые обучения позволяют увидеть, как быстро модель учится, хватает ли ей данных, а также обнаруживать пере- и недообучение.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Обнаружение пере- и недообучения

![Learning curve](/assets/images/ml_text/ml4-7.png "Learning curve"){: .align-center style="width: 800px;"}

![Learning curve](/assets/images/ml_text/ml4-8.png "Learning curve"){: .align-center style="width: 800px;"}

![Learning curve](/assets/images/ml_text/ml4-13.png "Learning curve"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. При недообучении тестовая и обучающая эффективности будут достаточно близкими, но недостаточными.
1. При переобучении тестовая и обучающая эффективности будут сильно различаться - тестовая будет значительно ниже.
1. Пере- и недообучение - это относительные понятия.
1. Более простые модели склонны к недообучению, более сложные - к переобучению.
1. Диагностика пере- и недообучения очень важна, так как для повышения эффективности предпринимаются противоположные меры.
1. Для построения можно использовать функцию ошибки, метрику эффективности или метрику ошибки, важна только динамика этих показателей.
1. Диагностика моделей машинного обучения - это не точная наука, здесь нужно принимать в расчет и задачу, и выбор признаков и многие другие факторы.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Регуляризация

![Bias vs complexity](/assets/images/ml_text/ml4-14.png "Bias vs complexity"){: .align-center style="width: 800px;"}

![Bias vs regularization](/assets/images/ml_text/ml4-4.png "Bias vs regularization"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. Регуляризация - это способ искусственно ограничить вариативность моделей.
1. Регуляризация в математике
1. При использовании регуляризации можно применять более сложные модели и снижать склонность к переобучению.
1. Регуляризация модифицирует функцию ошибки модели, добавляя в нее штрафы за повышение сложности.
1. Основная идея регуляризации - отдавать предпочтение низким значениям параметров в модели.
1. Регуляризация обычно не затрагивает свободный коэффициент $b_0$.
1. Регуляризация обычно параметрическая, можно управлять ее степенью.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Ridge

{% capture block %}
$$ 
J(\vec{b}) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 + \lambda \sum_{j=1}^{n} w_j^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. $\lambda > 0$ - параметр регуляризации.
1. Чем он больше, тем сильнее штрафуются сложные модели.
1. Этот прием может применяться как к классификации, так и к регрессии.
1. Ridge еще называют регуляризацией по L2-норме. Она же - гребневая рергессия.
1. Такая регуляризация делает параметры более робастными к мультиколлинеарности признаков.
1. В классификации такая модель может обучаться заметно быстрее за счет внутренней оптимизации вычислений.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Lasso

{% capture block %}
$$ 
J(\vec{b}) = \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 + \lambda \sum_{j=1}^{n} \| w_j \|
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. Lasso еще называют регуляризацией по L1-норме.
1. Lasso заставляет модель использовать меньше ненулевых коэффициентов.
1. Фактически, эта регуляризация уменьшает количество признаков, от которых зависит модель.
1. Может использоваться для отбора признаков.
1. Полезна в задачах с разреженной матрицей признаков.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Elastic net

{% capture block %}
$$ 
J(\vec{b}) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 + 
\lambda_1 \sum_{j=1}^{n} w_j + \lambda_2 \sum_{j=1}^{n} w_j^2
$$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. По сути, это комбинация регуляризации по L1 и L2 нормам.
1. Имеет два параметра, которые определяют соотношение соответствующих норм.
1. Комбинирует достоинства предыдущих двух методов.
1. Недостаток в необходимости задавать сразу два параметра регуляризации.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Методы повышения эффективности моделей

{% capture notice %}
Выводы:
1. Диагностика модели нужна для того, чтобы подсказать пути увеличения ее эффективности
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Анализ ошибок

{% capture notice %}
Выводы:
1. Анализ ошибок - это ручная проверка объектов, на которых модель делает ошибки.
1. Анализ характеристик таких объектов может подсказать направление инжиниринга признаков.
1. Можно сравнить эти объекты с остальной выборкой. Может, это аномалии.
1. В задачах регрессии в первую очередь обращать внимание на объекты с самым высоким отклонением.
1. Полезно бывает проинтерпретировать модель - проанализировать ее предметный смысл.
1. Для сложных моделей есть методы локальной линейной интерпретации. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы борьбы с недообучением

{% capture notice %}
Выводы:
1. Ввести в модель новые данные об объектах (атрибуты).
1. Уменьшение степени регуляризации модели.
1. Введение полиномиальных и других признаков.
1. В целом, инжиниринг признаков.
1. Использование более сложных моделей.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы борьбы с переобучением

{% capture notice %}
Выводы:
1. Ввести в модель данные о новых объектах, использовать большую выборку.
1. Убрать признаки из модели, использовать отбор признаков.
1. Увеличить степень регуляризации модели.
1. Использовать более простые модели.
1. Регуляризация обычно работает лучше уменьшения количества параметров.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Выбор модели

{% capture notice %}
Выводы:
1. Задача выбора класса модели для решения определенной задачи.
1. Очень сложно сказать априори какой класс модели будет работать лучше на конкретных данных.
1. Следует учитывать нефункциональные требования к задаче.
1. Обычно начинают с самых простых моделей - они быстро считаются и дают базовый уровень эффективности.
1. По результатам диагностики простых моделей принимают решение о дальнейших действиях.
1. Можно провести поиск по разным классам моделей для определения самых перспективных.
1. Выбор модели - это творческий и исследовательский процесс.
1. Есть подходы автоматизации выбора модели (AutoML), но они пока несовершенны.
1. В исследовательских задачах модели сравниваются со state-of-the-art.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Кросс-валидация

![CV](https://miro.medium.com/max/1400/1*AAwIlHM8TpAVe4l2FihNUQ.png "CV"){: .align-center style="width: 800px;"}
Источник: [Towards Data Science](https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b).
{: style="text-align: center; font-size:0.7em;"}

```py
>>> from sklearn.model_selection import cross_validate
>>> from sklearn.metrics import recall_score

>>> scoring = ['precision_macro','recall_macro']
>>> clf = 
svm.SVC(kernel='linear', C=1, random_state=0)

>>> scores = 
cross_validate(clf, X, y, scoring=scoring)

>>> sorted(scores.keys())
['fit_time', 'score_time', 
'test_precision_macro', 'test_recall_macro']

>>> scores['test_recall_macro']
array([0.96..., 1.  ..., 0.96..., 0.96..., 1. ])

```

{% capture notice %}
Выводы:
1. Разбиение выборки на обучающую и тестовую может внести случайные ошибки.
1. Нужно повторить разбиение несколько раз, посчитать метрики и усреднить.
1. Кросс-валидация разбивает выборку на $k$ блоков, каждый из которых используется по очереди как тестовый.
1. Сколько задать $k$, столько и будет проходов. Обычно берут 3 или 5.
1. Чем больше $k$ тем надежнее оценка, но дольше ее получение, так как модель каждый раз заново обучается.
1. Использование кросс-валидации обязательно для получения робастных оценок.
1. В библиотеке _sklearn_ кросс-валидация (CV) встроена во многие функции.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Гиперпараметры модели

{% capture notice %}
Выводы:
1. Гиперпараметр модели - это численное значение, которое влияет на работу модели, но не подбирается в процессе обучения.
1. Примеры гиперпараметров - k в kNN, параметр регуляризации, степень полиномиальной регрессии, глубина дерева решения.
1. У каждой модели множество гиперпараметров, которые можно посмотреть в документации.
1. Гиперпараметры модели нужно задавать до начала обучения.
1. Если значение гиперпараметра изменилось, то обучение надо начинать заново.
1. Существуют скрытые гиперпараметры модели - степень полинома, количество нейронов и слоев, ядерная функция.
1. Оптимизация гиперпараметров и задача выбора модели - одно и то же.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Поиск по сетке

```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

tuned_parameters = [
    {"kernel": ["rbf"], 
    "gamma": [1e-3, 1e-4], 
    "C": [1, 10, 100, 1000]},

    {"kernel": ["linear"], 
    "C": [1, 10, 100, 1000]},
]
scores = ["precision", "recall"]

grid_search = GridSearchCV(SVC(), tuned_parameters, 
       scoring=scores).fit(X_train, y_train)
```

{% capture notice %}
Выводы:
1. Поиск по сетке - полный перебор всех комбинаций значений гиперпараметров для поиска оптимальных значений.
1. Для его организации надо задать список гиперпараметров и их конкретных значений.
1. Непрерывные гиперпараметры надо дискретизировать.
1. Поиск по сетке имеет экспоненциальную сложность.
1. Чем больше параметров и значений задать, тем лучше модель, но дольше поиск.
1. Можно задать критерии поиска - целевые метрики.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Случайный поиск

```python
clf = SGDClassifier(loss="hinge", penalty="elasticnet", fit_intercept=True)

param_dist = {
    "average": [True, False],
    "l1_ratio": stats.uniform(0, 1),
    "alpha": loguniform(1e-2, 1e0),
}

n_iter_search = 15
random_search = RandomizedSearchCV(
    clf, param_distributions=param_dist, n_iter=n_iter_search
).fit(X, y)
```

{% capture notice %}
Выводы:
1. Случайный поиск позволяет задать распределение гиперпараметра, в котором будет вестись поиск.
1. Случайный поиск семплирует набор значений гиперпараметров из указанных распределений.
1. Можно задать количество итераций поиска независимо от количества гиперпараметров.
1. Добавление параметров не влияет на продолжительность поиска.
1. Результат не гарантируется. Воспроизводимость можно настроить.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Сравнение эффективности моделей (валидационный набор)

![CV](/assets/images/ml_text/ml4-9.png "CV"){: .align-center style="width: 800px;"}

{% capture notice %}
Выводы:
1. При сравнении нескольких моделей между собой возникает проблема оптимистичной оценки эффективности.
1. Поэтому для исследования выбранной модели нужно использовать третью часть выборки - валидационную.
1. В терминах существует путаница, главное - три непересекающиеся части выборки.
1. Обучающая (train) используется для оптимизации параметров (обучения) модели.
1. Валидационная (validation) - для оптимизации гиперпараметров и выбора модели.
1. Тестовая (test, holdout) - для итоговой оценки качества, представления результатов.
1. Во многих случаях использование кросс-валидации автоматически разбивает выборку. Поэтому тестовая грает роль валидационной.
1. Есть проблема глобального переобучения моделей на известных датасетах.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>