---
section: ml
title: "Классификация как задача машинного обучения"
---

### Что такое классификация в машинном обучении?

Задача классификации на практике встречается гораздо чаще, чем задача регрессии. По счастливому совпадению, и решать ее в каком-то смысле гораздо проще. Формально, задача классификации состоит в предсказании какого-то дискретного значения, в противоположность регрессии - предсказанию непрерывного значения. Но в реальности задачи классификации очень непохожи на регрессионные. Задачи регрессии - часто экономические или статистические - состоят именно в прогнозировании некоторого уровня какой-то величины. Задача классификации (как, впрочем и следует из названия) сводится к отнесению конкретного объекта к одному из заранее известных классов. Вот эта "метка" - название класса - и выступает в роли целевой переменной. И, совершенно естественно, что классов может быть только конечное количество, поэтому целевая переменная - дискретная.

Важно, что классы должны быть заранее известны. Мы должны знать сколько их всего, и к какому классу относится каждый объект обучающей выборки. Если чего-то из этого мы не знаем, то это уже совершенно другая задача - кластеризация - которая относится к обучению без учителя. А для классификации в датасете должны быть приведены метки классов для каждого объекта. Иначе говорят, что датасет должен быть "размечен". Если у нас этих данных нет, то данные надо разметить - указать для каждого объекта правильный класс.

Задачи классификации очень разнообразны. Почти любая прикладная задача машинного обучения может быть представлена в виде классификации. Например - распознавание объектов на изображении. Мы все пользуемся умными камерами в смартфонах, которые умеют автоматически определять, есть ли лицо на изображении в объективе. Вот там как раз работает алгоритм классификации, который разделяет все изображения на два класса - имеющих лицо и не имеющих. Другой пример - определение, является электронное письмо спамом или нет. Здесь так же идет разделение объектов на два класса. Или, например, выявление подозрительных банковских транзакций.

Все эти примеры имеют одну общую черту - в них идет речь о двух классах. Это примеры так называемой бинарной классификации. Такая постановка задачи действительно встречается довольно часто. И все эти задачи можно сформулировать как определение наличия или отсутствия какого-либо признака у объекта. Например, наличие лица на фото, подозрительности транзакции, и так далее. Но вообще не все задачи классификации обязаны быть бинарными. Иногда случается такое, что классов больше двух. Тогда мы говорим о задаче множественной классификации. Например, вместо распознавания конкретного объекта на изображении весьма распространена задача идентификации объекта - то есть определения, какой именно объект изображен.

Это называется задача идентификации объекта. К задачам множественной классификации еще относятся, например, рубрикация текстов - определение тематики текста, классификация изображений, сегментация рынка, классификация товаров, и еще множество других. Более того, к задачам классификации относятся такие задачи, про которые вообще с первого взгляда непонятно, куда их относить и как их решать. Типичный пример - машинный перевод. При всей своей специфике, его тоже можно представить как задачу классификации - подбор следующего слова в тексте, соответствующего контексту и тексту на другом языке. Так как мы выбираем какое-то оптимальное значение из пусть большого, но не бесконечного количества значений - всех возможных слов языка. Так что перевод - это очень множественная, но все-таки классификация. То же можно сказать и о задаче генерации текста. Аналогично к классификации относится распознавание рукописных или сканированных текстов, преобразование речи в текст и многие другие задачи обработки естественных языков.

Кроме бинарной и множественной классификации еще выделяют одноклассовую и мультиклассовую. Одноклассовая - это когда один объект может принадлежать только одному классу. В мультиклассовой классификации каждый объект может принадлежать сразу нескольким классам. Например, текст может относиться сразу к нескольким темам. А на изображении может присутствовать сразу несколько объектов. Отдельно выделяют нечеткую классификацию - это когда объект может принадлежать некоторым классам с разной принадлежностью или вероятностью. 

Еще следует отметить, что иногда имеет смысл преобразовать задачу регрессии в классификацию. Например, рассмотрим задачу предсказания цены финансового актива. Из-за того, что на цену актива влияют множество факторов, эта задача очень сложная, ведь мы выбираем из бесконечно большого количества вариантов. Но ее можно решать по-другому. Зачастую нам не важен конкретный уровень будущего значения цены, важнее то, будет цена больше или меньше, чем текущая. В таком случае, можно заменить сложную и зачастую нерешаемую задачу предсказания уровня более простой задачей предсказания тренда. У тренда можно выделить конечное число состояний - восходящий, нисходящий или боковой. То есть мы выбираем из, например, трех вариантов - будет цена больше, меньше или примерно такая же, как текущая. Другими словами мы заменили задачу регрессии классификацией. И такой прием используется очень часто.

{% capture notice-2 %}
Выводы:
1. Классификация - это задача машинного обучения, которая выражается в предсказании дискретного значения.
1. Классификация - это задача обучения с учителем, поэтому в датасете должны быть "правильные ответы" - значения целевой переменной.
1. Классификация - самая распространенная задача машинного обучения на практике.
1. Классификация бывает бинарной и множественной, одноклассовой и мультиклассовой.
1. Примеры задач классификации - распознавание объектов, генерация текстов, подбор тематики текстов, идентификация объектов на изображениях, распознавание речи, машинный перевод и так далее.
1. Почти любую практическую задачу машинного обучения можно сформулировать как задачу классификации.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>

### Как определяется задача классификации?

Итак, рассмотрим математическую формализацию задачи классификации. В такой задаче, так же как и в регрессии, на вход модели подается вектор признаков $ x^{(i)} = (x_1, x_2, ... x_n)$. Как и ранее, введем искусственный признак $ x_0 = 1 $. Он нужен для удобства представления многих моделей классификации. Можете представлять его как еще один столбец в датасете, в котором во всех строчках стоят единицы.

Функция гипотезы в таком случае будет иметь точно такой же вид: $ y = h_\theta (x) $. Существенное отличие в том, что целевая переменная $y$ будет принимать одно из конечного множества значений: $ y \in \lbrace y_1, y_2, y_k \rbrace $, где $k$ - это количество классов.

{% capture block %}
$$ {(x_1, y_1), (x_2, y_2), (x_3, y_3), ...,  (x_m, y_m)} $$

$$ y_i \in {1, 2, 3, ..., k} $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В дальнейшем для лучшего интуитивного понимания задач и алгоритмов классификации мы будем изображать объекты из датасета в виде точек на двумерном графике. А цвет или форма точек будут показывать, какому классу они относятся. Это хорошее визуальное представление. Но следует помнить, что на практике входной вектор может иметь сколько угодно измерений. То есть в датасете может быть сколько угодно признаков у каждого объекта. Тысячу или миллион признаков невозможно изобразить на графике, но это вполне реальный случай. 

![classification](https://production-media.paperswithcode.com/tasks/classification-algorithm-in-machine-learning_ta1IkVQ.png "classification"){: .align-center style="width: 600px;"}
Источник: [Papers with code](https://www.google.com/url?sa=i&url=https%3A%2F%2Fpaperswithcode.com%2Ftask%2Fclassification&psig=AOvVaw0l7A1DkviKQ8seWu7fktWH&ust=1652360072615000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCPDo4ZG_1_cCFQAAAAAdAAAAABAZ).
{: style="text-align: center; font-size:0.7em;"}

Как мы уже говорили, классов тоже может быть произвольное количество. Но мы в основном будем рассматривать именно бинарную классификацию. Более сложные модели множественной или мультиклассовой классификации все равно строятся на основе бинарной. И на этих алгоритмах мы тоже остановимся. В такой формулировке мы будем предполагать, что $ y \in \lbrace 0, 1 \rbrace $, где 0 обычно принимается как «отрицательный класс» и 1 как «положительный класс», но вы можете назначить этим значениям любое представление. 

{% capture block %}
$y = \lbrace 0, 1 \rbrace$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice-2 %}
Выводы:
1. На вход модели классификации подается вектор признаков объекта.
1. На выходе модель классификации предсказывает одно из конечного набора значений - метку класса объекта.
1. Мы часто будем изображать классификацию на графике, но имейте в виду, что на практике это обычно многомерная задача.
1. Обычно сначала рассматривается бинарная классификация, остальные типы строятся на ее основе. 
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


### Логистическая регрессия

Одним из самых простых и распространенных алгоритмов классификации является логистическая регрессия. Пусть название «логистическая регрессия» не вводит в заблуждение. Метод назван таким образом по историческим причинам и на самом деле является подходом к проблемам классификации, а не регрессионным проблемам.

Почему мы не можем применить для классификации уже известные нам методы линейной регрессии? В самом деле, пусть модель предсказывает непрерывное значение, а мы будем его интерпретировать, как 0 или 1. 

![Регрессия как классификация](/assets/images/ml_text/ml2-6.png "Регрессия как классификация"){: .align-center style="width: 50%;"}

В этом подходе заключается проблема. Регрессионные модели по сути свое непрерывны и их значение может возрастать или убывать неограниченно. Предположим. что если модель выдает значение больше 0.5, мы предсказываем положительный класс, если меньше - то отрицательный. 

![Функция принятия решения](/assets/images/ml_text/ml2-12.png "Регрессия как классификация"){: .align-center style="width: 50%;"}

Такой подход, в принципе имеет право на существование. Но есть один существенный недостаток: нам придется подгонять порог под наши исходные данные. 

![Смещенный датасет](/assets/images/ml_text/ml2-7.png "Регрессия как классификация"){: .align-center style="width: 80%;"}

Предположим, что данные сместились, как на графике. Тогда нам нужно брать другое пороговое значение. Ведь предыдущая модель даст огромную ошибку в появившейся новой точке:

![Большая ошибка](/assets/images/ml_text/ml2-13.png "Регрессия как классификация"){: .align-center style="width: 80%;"}

Чтобы избежать больших ошибок, алгоритм обучения регрессии сместит линию модели вниз, вот так:

![Смещенная регрессия](/assets/images/ml_text/ml2-14.png "Регрессия как классификация"){: .align-center style="width: 80%;"}

Это очень неудобно и ненадежно. И происходит потому, что регрессионные функции как правило неограничены. Но идея использовать регрессию здравая. Надо только преобразовать нашу функцию таким образом, чтобы вместо области значений $ y \in (-\inf, \inf) $ она имела, скажем, $ y \in [0, 1] $.

Это можно легко сделать, используя нелинейное преобразование. Например, так:

{% capture block %}
$$ h_b (x) = \frac{1}{1 + e^{-z}} $$

где $ z = X \cdot \vec{b}$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

то есть обычная линейная комбинация значений факторов и параметров. 

![Логистическая функция](/assets/images/ml_text/ml2-15.png "Регрессия как классификация"){: .align-center style="width: 80%;"}

В таком случае, значение функции гипотезы будет ограничено и асимптотически приближаться к 1 при неограниченном увеличении $z$ и приближаться к 0 при неограниченном уменьшении $z$. 

В такой формулировке значение функции гипотезы $h_\theta (x)$ может быть проинтерпретировано как вероятность того, что данный объект принадлежит к положительному классу. Например, $h_\theta (x) = 0.7$ дает нам вероятность 70%, что наш выход равен 1. Другими словами, 

$$ h_b(x) = P(y=1 \vert x, \vec{b}) = 1 - P(y=0 \vert x, \vec{b}) $$


Наша вероятность того, что наше предсказание равна 0, является просто дополнением нашей вероятности того, что она равна 1 (например, если вероятность того, что она равна 1, равна 70%, то вероятность того, что она равна 0, равна 30%).

{% capture notice-2 %}
Выводы:
1. Логистическая регрессия - это самый простой алгоритм бинарной классификации.
1. Можно взять регрессионную модель и ввести пороговое значение.
1. Обычная регрессия плохо работает в задачах классификации за счет своей чувствительности и неограниченности.
1. Метод логистической регрессии основан на применении логистической или сигмоидной функции.
1. Логистическая регрессия - это линейная модель.
1. Результат работы логистической функции часто интерпретируется как вероятность отнесения объекта к положительному классу.
1. Для четкой классификации обычно выбирают некоторое пороговое значение, обычно - 0,5.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


#### Граница принятия решений

Чтобы получить нашу дискретную классификацию 0 или 1, мы можем перевести вывод функции гипотезы следующим образом:

{% capture block %}
$$ h_b (x) \ge 0.5 \rightarrow y=1 $$

$$ h_b (x) \lt 0.5 \rightarrow y=0 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Логистическая функция g ведет себя таким образом, что когда ее вход больше или равен нулю, его выход больше или равен 0,5. Следует запомнить:

{% capture block %}
$$ z = 0 \rightarrow h_b (x) = 0.5 $$

$$ z = -\inf \rightarrow h_b (x) = 0 $$

$$ z = \inf \rightarrow h_b (x) = 1 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Таким образом, область пространства признаков, где $z = 0$ формирует границу между областью, токи которой модель относит к положительному классу и областью, точки которой модель относит к отрицательному. Граница принятия решения - это линия, которая разделяет область, где y = 0 и где y = 1. Она создается нашей функцией гипотезы. Так как мы используем линейную функцию внутри логистической, граница принятия решений такой модели всегда будет прямой линией, плоскостью или, в общем случае, гиперплоскостью.

Форма границы принятия решения полностью определяется видом модели, который мы применяем. В данном случае мы имеем линейную модель. Поэтому граница тоже может быть только линейной. Если бы мы взяли другую функцию, например, полином второй степени, то граница принятия решения была бы поверхностью второго порядка.

А вот конкретное положение границы принятия решения зависит от значений параметров модели. И именно это мы и подбираем в ходе машинного обучения. Поэтому обучения модели классификации можно представить как процесс нахождения оптимальной границы принятия решения.

Отсюда, кстати, следует основное ограничение метода логистической регрессии. Она будет показывать хорошие результаты тогда, когда объекты нашей выборки могут быть разделены гиперплоскостью.

![classification](https://upload.wikimedia.org/wikipedia/commons/1/13/Main-qimg-48d5bd214e53d440fa32fc9e5300c894.png "classification"){: .align-center style="width: 800px;"}
Источник: [Wikimedia](https://commons.wikimedia.org/wiki/File:Main-qimg-48d5bd214e53d440fa32fc9e5300c894.png).
{: style="text-align: center; font-size:0.7em;"}

Такое свойство датасета называется линейной разделимостью. Имейте в виду, что это свойство именно данных, а не модели. На рисунке слева вы видите линейно разделимые данные, а справа - неразделимые. И логистическая регрессия хорошо работает именно на линейно разделимых данных. Поэтому важным этапом предварительного анализа данных является анализ, разделимы ли данные линейно. От этого зависит, какие модели на них будут хорошо работать. 

И не забывайте, что данные у нас обычно многомерны. Это значит, что нельзя так просто нарисовать их на графике и понять визуально, разделимы они или нет. Ведь двумерный график - это лишь проекция многомерного многообразия на определенные оси. И то, что разделимо в высших размерностях может не показаться таким в проекции.

{% capture notice-2 %}
Выводы:
1. Граница принятия решений - это область, отделяющая один класс от другого.
2. Форма границы принятия решения определяется видом используемой модели.
3. Данные бывают линейно разделимые или нет.
4. Логистическая регрессия - это линейный метод, поэтому она хорошо работает с линейно разделимыми данными.
5. Если данные линейно неразделимы можно попробовать ввести в модель полиномиальные признаки.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


#### Функция ошибки логистической регрессии

Мы не можем использовать ту же самую функцию ошибки, которую мы используем для линейной регрессии, потому что логистическая функция породит немонотонную производную, имеющую множество локальных оптимумов. Другими словами, это не будет выпуклая функция.

Вместо этого функция ошибки для логистической регрессии выглядит так:

{% capture block %}
$$ J(\vec{b}) = \frac{1}{m} \sum_{i-1}^{m} Cost(h_b(x), y) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

где 

{% capture block %}
$$ Cost(h_b(x), y) = -log(h_b(x)) \vert y=1 $$

$$ Cost(h_b(x), y) = -log(1 - h_b(x)) \vert y=0 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Чем больше конкретная функция гипотезы отклоняется от y, тем больше получающая функция ошибки. Если гипотеза равна истинным значениям $y$, то ошибка равна 0. Если правильный ответ $y$ равен 0, тогда функция ошибки будет равна 0 тогда, когда функция гипотезы также выдает 0. Если же значение функции гипотезы приближается к 1, то функция ошибки будет приближаться к бесконечности. Если правильный ответ $y$ равен 1, функция ошибки будет равна 0 в том случае, когда  функция гипотезы выйдет 1. Если наша гипотеза приближается к 0, то функция стоимости приблизится к бесконечности.

![Функция ошибки](/assets/images/ml_text/ml2-5.png "Функция ошибки"){: .align-center style="width: 800px;"}

Заметим, что запись функции ошибки таким образом гарантирует, что J(b) выпукла для логистической регрессии.


#### Градиентный спуск для логистической регрессии

Мы можем сжать два условных случая функции ошибки в одно выражение, используя тот факт, что истинные значения $y$ могут принимать только значения 0 или 1:

{% capture block %}
$$ Cost(h_b(x), y) = - y \cdot log(h_b(x)) - (1 - y)(1 - log(h_b(x))) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Обратите внимание, что когда $y$ равно 1, то второе слагаемое будет равен нулю и не повлияет на результат. Если $y$ равно 0, то, наоборот, первое слагаемое будет равен нулю и не повлияет на результат.

Мы можем полностью сформулировать общую функцию ошибки следующим образом:

{% capture block %}
$$ J(\vec{b}) = -\frac{1}{m} \sum_{i-1}^{m} y_i \cdot log(h_b(x_i)) + (1 - y_i)(1 - log(h_b(x_i))) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Теперь мы готовы найти частную производную функции ошибки:

{% capture block %}
$$ \frac{\partial}{\partial b_i} J(\vec{b}) = \frac{1}{m} \sum_{i=1}^{m} (h_b (x_i) -y_i) x_i $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Обратите внимание, что мы получили точно такое же выражение, что и в случае с линейной регрессией. Также, как и в том случае, формула для частной производной выражена через функцию гипотезы. И опять же это не случайно. Так мы получаем, что алгоритм градиентного спуска полностью аналогичен для логистической и для линейной регрессии.

Получаем, что общая форма градиентного спуска:

$$ b_i := b_i -\alpha \frac{\partial}{\partial b_i} J(b) $$

Подставляя выражение для частной производной получаем следующее выражение:

{% capture block %}
$$ b_i := b_i - \frac{\alpha}{m} \sum_{i=1}^{m} (h_b (x) -y)x_i $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Обратите внимание, что этот алгоритм идентичен тому, который мы использовали в линейной регрессии. Мы все также должны одновременно обновлять все значения $b$ одновременно.

#### Многоклассовая классификация: один против всех

Теперь мы рассмотрим классификацию данных более чем в двух категориях. Вместо $y = \lbrace 0, 1 \rbrace$ мы расширим наше определение так, чтобы 

{% capture block %}
$$ y = \lbrace 0,1 ... n \rbrace $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Пример множественной классификации набора данных, содержащих два признака и три класса можно увидеть на рисунке:

![Multiclassification](/assets/images/ml_text/ml2-8.png "Multiclassification"){: .align-center style="width: 50%;"}
{: style="text-align: center; font-size:0.7em;"}

Алгоритм классификации в данном случае очень прост. Мы берем последовательно каждый имеющийся класс в данных, делаем его "положительным", а все остальные - "отрицательным", и обучаем модель, которая стремится отделить данный класс от остальных. Схематично алгоритм классификации "один против всех" можно увидеть на рисунке:

![Multiclassification](https://miro.medium.com/max/700/1*4Ii3aorSLU50RV6V5xalzg.png "Multiclassification"){: .align-center style="width: 80%"}
Источник: [Medium](https://www.google.com/url?sa=i&url=https%3A%2F%2Fantonhaugen.medium.com%2Fintroducing-mllibs-one-vs-rest-classifier-402eeab22493&psig=AOvVaw1MR6k70nP2mdGdtR_eFmIh&ust=1647355347284000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCIDI3oTrxfYCFQAAAAAdAAAAABAD).
{: style="text-align: center; font-size:0.7em;"}

В этом случае мы делим нашу задачу на $ n + 1 $ (потому что индекс начинается с 0) двоичных задач классификации. В каждом из них мы прогнозируем вероятность того, что $y$ является членом одного из наших классов.

{% capture block %}
$$ h_b^{(0)} = P(y=0 \vert x, \vec{b}); $$

$$ h_b^{(1)} = P(y=1 \vert x, \vec{b}); $$

$$ ... $$

$$ h_b^{(n)} = P(y=n \vert x, \vec{b}); $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Таким образом мы выбираем один класс, а затем объединяем все остальные объекты в один второй класс. Мы делаем это неоднократно, применяя двоичную логистическую регрессию к каждому случаю, а затем используем гипотезу, которая вернула наивысшее значение в качестве нашего прогноза.

Другими словами, построив несколько моделей бинарной классификации мы можем использовать их, чтобы получить оценки вероятности принадлежности любого объекта ко всем имеющимся классам. После этого для окончательной классификации выбирается тот класс, чья модель дала наивысший результат.

Данный метод называется "один против всех" (one vs all или one vs rest). Надо отметить, что во всех современных программных инструментах для машинного обучения, он уже реализован и встроен в существующие методы классификации, так что разработчику не придется программировать его специально.

Кроме того, чуть позже мы познакомимся с моделями, которые сами по себе способны решать задачи множественной классификации, а значит, не требуют реализации схемы "один против всех". Она нужна только для моделей, которые способны решать только бинарную классификацию, чтобы "приспособить" их для задач, где классов больше двух.

### Практическое построение классификации

#### Как подготовить данные для классификации?

Для решения задач классификации в языке программирования Python с использованием _sklearn_ остается справедливым все то, о чем мы говорили в конце предыдущей главы о подготовке данных для регрессионных задач. Так же нам нужно сформировать два массива данных - двумерный массив признаков _X_ и одномерный массив значений целевой переменной _y_. 

Раньше, в векторе значений целевой переменной находились сами численные значения. В данных для классификации метки классов могут обозначаться разными способами - числом, названием, аббревиатурой. Дальше мы будем подразумевать, что значения в массиве _y_ заданы просто числами - _[0, 1]_, если классов два (бинарная классификация), _[0, 1, 2]_ - если классов три и так далее. Если в вашем датасете это не так и классы обозначаются как-то по другому, то обратитесь к одной из следующих глав, где мы обсуждаем преобразование и подготовку данных.

Здесь хотелось бы упомянуть еще об одной полезной функции библиотеки _sklearn_ - процедурной генерации датасетов. Данная библиотека включает в себя несколько функций, которые используются для создания случайных наборов данных для тестирования моделей машинного обучения. В частности, существует функция _make_classification_, которая позволяет быстро создать случайный набор данных для классификации, обладающий определенными свойствами. Вы можете настроить количество точек, количество классов и признаков, насколько они будут линейно разделимы. Более полно информацию об этой и других функциях смотрите в официальной документации _sklearn_, в разделе, посвященном пакету _datasets_. Приведем пример использования этой функции:

```python
from sklearn.datasets import make_classification

X, Y = make_classification( n_features=2)
```

В результате мы получаем и массив признаков и вектор значений целевой переменной. Они уже готовы для использования в моделях классификации.

Если возможно, всегда нужно стремится визуализировать данные, которые вы собираетесь анализировать. В случае с данными для классификации это немного сложнее, чем для парной регрессии, ведь нам нужно на графике как-то выделить классы. Можно воспользоваться встроенной возможностью задания цвета точек через массив вот так:

```python
plt.scatter(X[:, 0], X[:, 1], marker="o", c=Y, s=25, edgecolor="k")
plt.show()
```

Обратите внимание, что в данном случае мы явно указываем, какие признаки будут расположены по осям. В данном примере мы откладываем первый столбец (с индексом 0) по горизонтальной оси, а второй (с индексом 1) - по вертикальной. Вот так это выглядит на графике:

![Данные для классификации](/assets/images/ml_text/ml2-1.png "Данные для классификации"){: .align-center style="width: 50%;"}
{: style="text-align: center; font-size:0.7em;"}

Есть другой способ - визуализировать каждый класс отдельно. В таком случае мы можем более гибко управлять отображением разных классов - задавать явно произвольные цвета, размеры, форму маркеров точек. Обратите внимание, как в данном примере используется условная индексация одного массива (признаков) другим массивом (целевой переменной):

```python
plt.scatter(X[:, 0][Y==0], X[:, 1][Y==0], marker="o", c='r', s=100)
plt.scatter(X[:, 0][Y==1], X[:, 1][Y==1], marker="x", c='b', s=100)
plt.show()
```

Вот так это выглядит на графике:

![Данные для классификации](/assets/images/ml_text/ml2-11.png "Данные для классификации"){: .align-center style="width: 50%;"}
{: style="text-align: center; font-size:0.7em;"}

Помимо визуализации с данными такой структуры можно работать абсолютно так же, как и с данными для регрессии.

#### Как реализовать логистическую регрессию?

Рассмотрим простейшую модель логистической регрессии. Как мы увидели в этой главе, она мало чем отличается от модели линейной регрессии, поэтому возьмем за основу класс, который реализовали в предыдущей главе, посвященной задаче регрессии. 

Мы будем рассматривать двумерную задачу классификации. То есть у нас будет два непрерывных признака - $x_1$ и $x_2$. Поэтому в модели будет 3 параметра - $b_0, b_1, b_2$. Еще мы предполагаем решение бинарной задачи, так как множественная классификация решается отдельным алгоритмом "один-против-всех"

Ключевым отличием метода _predict_ будет то, что мы считаем линейную комбинацию, а затем считаем логистическую функцию от нее:

```python
def predict(self, x):
    x1, x2 = x
    z = self.b0 + self.b1 * x1 + self.b2 * x2
```

Модифицируем функцию ошибки так, чтобы она соответствовала формуле логарифмической ошибки для логистической регрессии:

```python
def error(self, X, Y):
    return -sum(Y * np.log2(self.predict(X)) + (1 - Y) *(1 - np.log2(self.predict(X)))) / len(X[0])
```

Теперь перейдем к методу градиентного спуска. И вот здесь все останется поразительно похожим на линейную регрессию, за исключением большего количества параметров:

```python
def BGD(self, X, Y):  
    alpha = 0.5
    for _ in range(1000):
      dJ0 = sum(self.predict(X) - Y) /len(X)
      dJ1 = sum((self.predict(X) - Y) * X[0]) /len(X[0])
      dJ2 = sum((self.predict(X) - Y) * X[1]) /len(X[0])
      self.b0 -= alpha * dJ0
      self.b1 -= alpha * dJ1
      self.b2 -= alpha * dJ2
```

Полностью код, реализующий метод логистической регрессии, выглядит так:

```py
class hypothesis(object):
    """Модель логистической регрессии"""
    def __init__(self):
        self.b0 = 0
        self.b1 = 0
        self.b2 = 1
    def predict(self, x):
        x1, x2 = x
        z = self.b0 + self.b1 * x1 + self.b2 * x2
        return 1 / (1 + np.exp(-z))
    def error(self, X, Y):
        return -sum(Y * np.log2(self.predict(X)) + (1 - Y) *(1 - np.log2(self.predict(X)))) / len(X[0])
    def BGD(self, X, Y):  
        alpha = 0.5
        for _ in range(1000):
          dJ0 = sum(self.predict(X) - Y) /len(X)
          dJ1 = sum((self.predict(X) - Y) * X[0]) /len(X[0])
          dJ2 = sum((self.predict(X) - Y) * X[1]) /len(X[0])
          self.b0 -= alpha * dJ0
          self.b1 -= alpha * dJ1
          self.b2 -= alpha * dJ2
```

Обратите внимание на задание начальных значений параметров. В данном примере мы создаем регрессию со следующими значениями параметров по умолчанию: $b_0 = 0; b_1 = 0; b_2 = 1$. Задание одного из параметров в 1 нужно будет потом, чтобы получился более понятный график модели без обучения. На практике можно задавать начальные значения всеми нулями.

#### Как оценить качество классификационной модели?

После создания модели логистической регрессии логичным шагом будет вывести ее на график вместе с точками данных. Проблема в том, что это не так просто, как в случае с линейной регрессией, так как мы имеем два измерения признаков плюс еще значение самой функции модели. Для того, чтобы наглядно увидеть, как сочетается значение модели с точками воспользуемся построением контурного графика.

Для начала создадим экземпляр модели с параметрами по умолчанию:

```python
hyp = hypothesis()
print(hyp.predict((0, 0)))
J = hyp.error(X, Y)
print("initial error:", J)
```

Теперь надо подготовить равномерные данные для рисования функции гипотезы. Нам понадобится создать двумерную сетку. К счастью, в _numpy_ есть необходимые элементы. Подробный разбор кода выходит за рамки данного пособия, так как использует продвинутые возможности библиотеки _numpy_. Если вам интересно, как работает этот код, обратитесь к документации к используемым методам:

```python
xx, yy = np.meshgrid(
    np.arange(X.min(axis=0)[0]-1, X.max(axis=0)[0]+1, 0.01), 
    np.arange(X.min(axis=0)[1]-1, X.max(axis=0)[1]+1, 0.01))
XX = np.array(list(zip(xx.ravel(), yy.ravel()))).reshape((-1, 2))
```

В данном коде мы создаем двумерную матрицу, содержащую все комбинации значений признаков в заданном диапазоне. Другими словами, мы создаем равномерную сетку в прямоугольнике от минимального до максимального значения каждого признака (отступая для красоты 1 в обоих направлениях). Попробуйте вывести получившиеся переменные, чтобы понять принцип построения данной сетки. А после мы используем матрицу _XX_ как исходные данные для модели:

```python
Z = hyp.predict(XX)
Z = Z.reshape(xx.shape)
```

Данный код выполнит предсказание модели в каждой точке нашей сетки. Эти данные мы сможем использовать для того, чтобы построить контурный график вот так:

```python
plt.contourf(xx, yy, Z, alpha=0.4)
plt.scatter(X[:, 0][Y==0], X[:, 1][Y==0], marker="o", c='r', s=100)
plt.scatter(X[:, 0][Y==1], X[:, 1][Y==1], marker="x", c='b', s=100)
```

В итоге мы должны получить график, похожий на следующий рисунок:

![Классификация](/assets/images/ml_text/ml2-2.png "Классификация"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

На графике мы видим наши точки данных, они выглядят так же, как и в предыдущих частях. Кроме него график заполняет заливка цветом. Цвет показывает значение функции гипотезы в данной точке. Так как мы задавали начальные значения параметров модели специально, параметр $b_2 = 1$ дает нам такой ровный градиент, который увеличивается равномерно с ростом значения признака $x_1$. Конечно, такой градиент никак не учитывает положение точек. Это и логично, ведь наша модель еще не обучена. Давайте запустим градиентный спуск и увидим модель после обучения:

```py
hyp.BGD(X, Y)

Z = hyp.predict((xx, yy))
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.4)
plt.scatter(X.T[:, 0], X.T[:, 1], marker="o", c=Y, s=25, edgecolor="k")
plt.show()
```

Обратите внимание, что мы переиспользуем сетку, которую создавали на предыдущем шаге. Ведь сами значения не меняются, меняется только набор значений модели. После обучения вы должны увидеть примерно такой график:

![Классификация](/assets/images/ml_text/ml2-3.png "Классификация"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

На нем мы видим, что функция гипотезы подстроилась к точкам таким образом, чтобы для точек положительного класса (желтых) выдавать значения, близкие к единице (желтая область), а для точек отрицательного класса (черных) - значения, близкие к нулю (фиолетовая область). То есть модель стала гораздо лучше соответствовать данным. Посередине между двумя областями мы видим более узкую полоску градиента. Это область, для точек которой модель не уверена в своих предсказаниях и выдает значения, ближе к 0,5. Именно в этой полосе располагается граница принятия решения нашей модели.

#### Как построить простую классификацию в scikit-learn?

Так же, как и в случае с линейной регрессией, самостоятельная реализация данного метода нужна только для того, чтобы на практике прочувствовать алгоритм его работы. В реальной жизни лучше всего пользоваться существующими профессиональными реализациями. Именно поэтому мы используем _sklearn_. Работа с моделью классификации в этой библиотеке практически не отличается от работы с линейной регрессией. Для начала нужно импортировать нужный класс, создать его экземпляр и обучить его на имеющихся данных:

```py
from sklearn import linear_model

X = X.T

reg = linear_model.LogisticRegression()
reg.fit(X, Y)
print(reg.score(X, Y))
```

Обратите внимание, на то, что названия методов полностью совпадают у всех моделей машинного обучения в этой библиотеке. За счет этого ей очень приятно и просто пользоваться - у всех моделей единый интерфейс.

Точно так же, как и в самостоятельной реализации мы можем использовать модель для построения предсказания по сетке и для построения контурного графика. Давайте сравним самостоятельную реализацию логистической регрессии с библиотечной:

```python
Z = reg.predict(XX)
Z = Z.reshape(xx.shape)

plt.figure(figsize=(12, 9))
plt.contourf(xx, yy, Z, alpha=0.4)
plt.scatter(X[:, 0][Y==0], X[:, 1][Y==0], marker="o", c='r', s=100)
plt.scatter(X[:, 0][Y==1], X[:, 1][Y==1], marker="x", c='b', s=100)
```

В результате выполнения данного кода вы должны увидеть график наподобие следующего:

![Библиотечная классификация](/assets/images/ml_text/ml2-4.png "Библиотечная классификация"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Обратите внимание, что граница принятия решения расположена примерно в том же месте, что и у нашей реализации. Однако полоса "неопределенности", область, где проявляется цветовой градиент, значительно уже. На библиотечной модели ее вообще почти невозможно разглядеть. Это не значит, что наша модель обучилась хуже. Ведь наша модель все еще способна точно отделить точки обучающей выборки разных классов. Но библиотечная модель обучилась "сильнее" - она более уверенно классифицирует точки, которые ближе к границе принятия решения.
