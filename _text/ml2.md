---
section: ml
title: "Классификация как задача машинного обучения"
---

### Что такое классификация в машинном обучении?

{% capture notice-2 %}
Выводы:
1. Классификация - это задача машинного обучения, которая выражается в предсказании дискретного значения.
1. Классификация - это задача обучения с учителем, поэтому в датасете должны быть "правильные ответы" - значения целевой переменной.
1. Классификация - самая распространенная задача машинного обучения на практике.
1. Классификация бывает бинарной и множественной, одноклассовой и мультиклассовой.
1. Примеры задач классификации - распознавание объектов, генерация текстов, подбор тематики текстов, идентификация объектов на изображениях, распознавание речи, машинный перевод и так далее.
1. Почти любую практическую задачу машинного обучения можно сформулировать как задачу классификации.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>

### Как определяется задача классификации?

Итак, рассмотрим математическую формализацию задачи классификации. В такой задаче, так же как и в регрессии, на вход модели подается вектор признаков $ x^{(i)} = (x_1, x_2, ... x_n)$. Как и ранее, введем искусственный признак $ x_0 = 1 $. Он нужен для удобства представления многих моделей классификации. Можете представлять его как еще один столбец в датасете, в котором во всех строчках стоят единицы.

Функция гипотезы в таком случае будет иметь точно такой же вид:$ y = h_\theta (x) $. Существенное отличие в том, что целевая переменная $y$ будет принимать одно из конечного множества значений: $ y \in \lbrace y_1, y_2, y_k \rbrace $, где $k$ - это количество классов.

{% capture block %}
$$ {(x_1, c_1), (x_2, c_2), (x_3, c_3), ...,  (x_m, c_m)} $$

$$ c_i \in {1, 2, 3, ..., k} $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В дальнейшем для лучшего интуитивного понимания задач и алгоритмов классификации мы будем изображать объекты из датасета в виде точек на двумерном графике. А цвет или форма точек будут показывать, какому классу они относятся. Это хорошее визуальное представление. Но следует помнить, что на практике входной вектор может иметь сколько угодно измерений. То есть в датасете может быть сколько угодно признаков у каждого объекта. Тысяча или миллион признаков невозможно изобразить на графике, но это вполне реальный случай. 

![classification](https://production-media.paperswithcode.com/tasks/classification-algorithm-in-machine-learning_ta1IkVQ.png "classification"){: .align-center style="width: 600px;"}
Источник: [Papers with code](https://www.google.com/url?sa=i&url=https%3A%2F%2Fpaperswithcode.com%2Ftask%2Fclassification&psig=AOvVaw0l7A1DkviKQ8seWu7fktWH&ust=1652360072615000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCPDo4ZG_1_cCFQAAAAAdAAAAABAZ).
{: style="text-align: center; font-size:0.7em;"}

Как мы уже говорили, классов тоже может быть произвольное количество. Но мы в основном будем рассматривать именно бинарную классификацию. Более сложные модели множественной или мультиклассовой классификации все равно строятся на основе бинарной. И на этих алгоритмах мы тоже остановимся. В такой формулировке мы будем предполагать, что $ y \in \lbrace 0, 1 \rbrace $, где 0 обычно принимается как «отрицательный класс» и 1 как «положительный класс», но вы можете назначить этим значениям любое представление. 

{% capture notice-2 %}
Выводы:
1. На вход модели классификации подается вектор признаков объекта.
1. На выходе модель классификации предсказывает одно из конечного набора значений - метку класса объекта.
1. Мы часто будем изображать классификацию на графике, но имейте в виду, что на практике это обычно многомерная задача.
1. Обычно сначала рассматривается бинарная классификация, остальные типы строятся на ее основе. 
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


### Логистическая регрессия

Одним из самых простых и распространенных алгоритмов классификации является логистическая регрессия. Пусть название «логистическая регрессия» не вводит в заблуждение. Метод назван таким образом по историческим причинам и на самом деле является подходом к проблемам классификации, а не регрессионным проблемам.

{% capture block %}
$y = \lbrace 0, 1 \rbrace$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Почему мы не можем применить для классификации уже известные нам методы линейной регрессии? В самом деле, пусть модель предсказывает непрерывное значение, а мы будем его интерпретировать, как 0 или 1. 

![Регрессия как классификация](/assets/images/ml_text/ml2-6.png "Регрессия как классификация"){: .align-center style="width: 50%;"}

В этом подходе заключается проблема. Регрессионные модели по сути свое непрерывны и их значение может возрастать или убывать неограниченно. Предположим. что если модель выдает значение больше 0.5, мы предсказываем положительный класс, если меньше - то отрицательный. 

Такой подход, в принципе имеет право на существование. Но есть один существенный недостаток: нам придется подгонять порог под наши исходные данные. 

![Регрессия как классификация](/assets/images/ml_text/ml2-7.png "Регрессия как классификация"){: .align-center style="width: 80%;"}

Предположим, что данные сместились, как на графике. Тогда нам нужно брать другое пороговое значение. Это очень неудобно и ненадежно. И происходит потому, что регрессионные функции как правило неограничены. Но идея использовать регрессию здравая. Надо только преобразовать нашу функцию таким образом, чтобы вместо области значений $ y \in (-\inf, \inf) $ она имела, скажем, $ y \in [0, 1] $.

Это можно легко сделать, используя нелинейное преобразование. Например, так:

{% capture block %}
$$ h_b (x) = \frac{1}{1 + e^{-z}} $$

$ z = X \cdot \vec{b}$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

то есть обычная линейная комбинация значений факторов и параметров. 

![logistic regression](https://miro.medium.com/max/725/0*tLu8lvAEomHZm2YK.png "logistic regression"){: .align-center style="width: 800px;"}
Источник: [Medium](https://www.google.com/url?sa=i&url=https%3A%2F%2Fmedium.com%2F%40mvanshika25%2Flogistic-regression-ee47cc89345f&psig=AOvVaw25bUtmwo2_U65MI7QVCupr&ust=1647350393254000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCKD8rcvYxfYCFQAAAAAdAAAAABAD).
{: style="text-align: center; font-size:0.7em;"}

В таком случае, значение функции гипотезы будет ограничено и асимптотически приближаться к 1 при неограниченном увеличении $z$ и приближаться к 0 при неограниченном уменьшении $z$. 

В такой формулировке значение функции гипотезы $h_\theta (x)$ может быть проинтерпретировано как вероятность того, что данный объект принадлежит к положительному классу. Например, $h_\theta (x) = 0.7$ дает нам вероятность 70%, что наш выход равен 1. Другими словами, 

$$ h_b(x) = P(y=1 \vert x, \vec{b}) = 1 - P(y=0 \vert x, \vec{b}) $$


Наша вероятность того, что наше предсказание равна 0, является просто дополнением нашей вероятности того, что она равна 1 (например, если вероятность того, что она равна 1, равна 70%, то вероятность того, что она равна 0, равна 30%).

![regression 4 classification](https://datascienceunwind.files.wordpress.com/2019/09/logistic-reg2.png "regression 4 classification"){: .align-center style="width: 500px;"}
Источник: [GMC India](https://www.google.com/url?sa=i&url=http%3A%2F%2Fwww.gmcindia.in%2Fperuse.aspx%3Fcname%3Dlogistic%2Bregression%2Btitanic%2Bpython%26cid%3D23&psig=AOvVaw3CVtMk6ZZYuC_SgQQQpLo4&ust=1652360261367000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCIiPm-m_1_cCFQAAAAAdAAAAABAO).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice-2 %}
Выводы:
1. Логистическая регрессия - это самый простой алгоритм бинарной классификации.
1. Можно взять регрессионную модель и ввести пороговое значение.
1. Обычная регрессия плохо работает в задачах классификации за счет своей чувствительности и неограниченности.
1. Метод логистической регрессии основан на применении логистической или сигмоидной функции.
1. Логистическая регрессия - это линейная модель.
1. Результат работы логистической функции часто интерпретируется как вероятность отнесения объекта к положительному классу.
1. Для четкой классификации обычно выбирают некоторое пороговое значение, обычно - 0,5.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


#### Граница принятия решений

Чтобы получить нашу дискретную классификацию 0 или 1, мы можем перевести вывод функции гипотезы следующим образом:

{% capture block %}
$$ h_b (x) \ge 0.5 \rightarrow y=1 $$

$$ h_b (x) \lt 0.5 \rightarrow y=0 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Логистическая функция g ведет себя таким образом, что когда ее вход больше или равен нулю, его выход больше или равен 0,5. Следует запомнить:

{% capture block %}
$$ z = 0 \rightarrow h_b (x) = 0.5 $$

$$ z = -\inf \rightarrow h_b (x) = 0 $$

$$ z = \inf \rightarrow h_b (x) = 1 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>$

Таим образом, область пространства признаков, где $z = 0$ формирует границу. Граница принятия решения - это линия, которая разделяет область, где y = 0 и где y = 1. Она создается нашей функцией гипотезы. Так как мы используем линейную функцию внутри логистической. Граница принятия решений такой модели всегда будет прямой линией, плоскостью или, в общем случае, гиперплоскостью.

Форма границы принятия решения полностью определяется видом модели, который мы применяем. В данном случае мы имеем линейную модель. Поэтому граница тоже может быть только линейной. Если бы мы взяли другую функцию, например, полином второй степени, то граница принятия решения была бы поверхностью второго порядка.

А вот конкретное положение границы принятия решения зависит от значений параметров модели. И именно это мы и подбираем в ходе машинного обучения. Поэтому обучения модели классификации можно представить как процесс нахождения оптимальной границы принятия решения.

Отсюда, кстати, следует основное ограничение метода логистической регрессии. Она будет показывать хорошие результаты тогда, когда объекты нашей выборки могут быть разделены гиперплоскостью.

![classification](https://upload.wikimedia.org/wikipedia/commons/1/13/Main-qimg-48d5bd214e53d440fa32fc9e5300c894.png "classification"){: .align-center style="width: 800px;"}
Источник: [Wikimedia](https://commons.wikimedia.org/wiki/File:Main-qimg-48d5bd214e53d440fa32fc9e5300c894.png).
{: style="text-align: center; font-size:0.7em;"}

Такое свойство датасета называется линейной разделимостью. Имейте в виду, что это свойство именно данных, а не модели. На рисунке слева вы видите линейно разделимые данные, а справа - неразделимые. И логистическая регрессия хорошо работает именно на линейно разделимых данных. Поэтому важным этапом предварительного анализа данных является анализ, разделимы ли данные линейно. От этого зависит, какие модели на них будут хорошо работать. 

И не забывайте, что данные у нас обычно многомерны. Это значит, что нельзя так просто нарисовать их на графике и понять визуально, разделимы они или нет. Ведь двумерный график - это лишь проекция многомерного многообразия на определенные оси. И то, что разделимо в высших размерностях может не показаться таким в проекции.

{% capture notice-2 %}
Выводы:
1. Граница принятия решений - это область, отделяющая один класс от другого.
2. Форма границы принятия решения определяется видом используемой модели.
3. Данные бывают линейно разделимые или нет.
4. Логистическая регрессия - это линейный метод, поэтому она хорошо работает с линейно разделимыми данными.
5. Если данные линейно неразделимы можно попробовать ввести в модель полиномиальные признаки.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


#### Функция ошибки логистической регрессии

Мы не можем использовать ту же самую функцию ошибки, которую мы используем для линейной регрессии, потому что логистическая функция породит немонотонную производную, имеющую множество локальных оптимумов. Другими словами, это не будет выпуклая функция.

Вместо этого наша функция стоимости для логистической регрессии выглядит так:

{% capture block %}
$$ J(\vec{b}) = \frac{1}{m} \sum_{i-1}^{m} Cost(h_b(x), y) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

где 

{% capture block %}
$$ Cost(h_b(x), y) = -log(h_b(x)) \vert y=1 $$

$$ Cost(h_b(x), y) = -log(1 - h_b(x)) \vert y=0 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Чем больше наша гипотеза отклоняется от y, тем больше получающая функция ошибки. Если наша гипотеза равна y, то наша стоимость равна 0.
Если наш правильный ответ y равен 0, тогда функция стоимости будет равна 0, если наша функция гипотезы также выдает 0. Если наша гипотеза приближается к 1, то функция стоимости будет приближаться к бесконечности.

Если наш правильный ответ y равен 1, функция стоимости будет равна 0, если наша функция гипотезы выйдет 1. Если наша гипотеза приближается к 0, то функция стоимости приблизится к бесконечности.

![Функция ошибки](/assets/images/ml_text/ml2-5.png "Функция ошибки"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Заметим, что запись функции стоимости таким образом гарантирует, что J(b) выпукла для логистической регрессии.


#### Градиентный спуск для логистической регрессии

Мы можем сжать два условных случая функции стоимости в один случай:

{% capture block %}
$$ Cost(h_b(x), y) = - y \cdot log(h_b(x)) - (1 - y)(1 - log(h_b(x))) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Обратите внимание, что когда y равно 1, то второй член будет равен нулю и не повлияет на результат. Если y равно 0, то первый член будет равен нулю и не повлияет на результат.

Мы можем полностью выписать всю нашу функцию затрат следующим образом:

{% capture block %}
$$ J(\vec{b}) = -\frac{1}{m} \sum_{i-1}^{m} y_i \cdot log(h_b(x_i)) + (1 - y_i)(1 - log(h_b(x_i))) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Теперь мы готовы найти полученную частную производную:

{% capture block %}
$$ \frac{\partial}{\partial \theta_i} J(\vec{b}) = \frac{1}{m} \sum_{i=1}^{m} (h_b (x_i) -y_i) x_i $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Обратите внимание, что мы получили точно такое же выражение, что и в случае с линейной регрессией. Также у нас выражение для частной производной выражено через функцию гипотезы. И опять же это не случайно. Так мы получаем, что алгоритм градиентного спуска полностью аналогичен для логистической и для линейной регрессии.

Помните, что общая форма градиентного спуска:

$$ \theta_i := \theta_i -\alpha \frac{\partial}{\partial \theta_i} J(\theta) $$

Подставляя частную производную получаем следующее выражение:

{% capture block %}
$$ \theta_i := \theta_i - \frac{\alpha}{m} \sum_{i=1}^{m} (h_\theta (x) -y)x_i $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Обратите внимание, что этот алгоритм идентичен тому, который мы использовали в линейной регрессии. Мы все также должны одновременно обновлять все значения $\theta$ одновременно.

#### Многоклассовая классификация: один против всех

Теперь мы рассмотрим классификацию данных более чем в двух категориях. Вместо $y = \lbrace 0, 1 \rbrace$ мы расширим наше определение так, чтобы 

{% capture block %}
$y = \lbrace 0,1 ... n \rbrace$.
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

![Multiclassification](/assets/images/ml_text/ml2-8.png "Multiclassification"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

![Multiclassification](https://miro.medium.com/max/700/1*4Ii3aorSLU50RV6V5xalzg.png "Multiclassification"){: .align-center style="width: 800px;"}
Источник: [Medium](https://www.google.com/url?sa=i&url=https%3A%2F%2Fantonhaugen.medium.com%2Fintroducing-mllibs-one-vs-rest-classifier-402eeab22493&psig=AOvVaw1MR6k70nP2mdGdtR_eFmIh&ust=1647355347284000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCIDI3oTrxfYCFQAAAAAdAAAAABAD).
{: style="text-align: center; font-size:0.7em;"}

В этом случае мы делим нашу задачу на $ n + 1 $ (потому что индекс начинается с 0) двоичных задач классификации. В каждом из них мы прогнозируем вероятность того, что $y$ является членом одного из наших классов.

{% capture block %}
$$ h_b^{(0)} = P(y=0 \vert x, \vec{b}); $$

$$ h_b^{(1)} = P(y=1 \vert x, \vec{b}); $$

$$ ... $$

$$ h_b^{(n)} = P(y=n \vert x, \vec{b}); $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Таким образом мы выбираем один класс, а затем объединяем все остальные объекты в один второй класс. Мы делаем это неоднократно, применяя двоичную логистическую регрессию к каждому случаю, а затем используем гипотезу, которая вернула наивысшее значение в качестве нашего прогноза.

Данный метод называется "один против всех" (one vs all или one vs rest). Надо отметить, что во вех современных программных инструментах для машинного обучения, он уже реализован и встроен в существующие методы классификации, так что разработчику не придется программировать его специально.

### Практическое построение классификации

#### Как подготовить данные для классификации?

```py
from sklearn.datasets import make_classification

X, Y = make_classification( n_features=2, n_redundant=0, 
    n_informative=2, n_samples=20,
    n_clusters_per_class=1, random_state=7,
)

plt.figure(figsize=(12, 9))
plt.scatter(X[:, 0], X[:, 1], marker="o", c=Y, s=25, edgecolor="k")
plt.show()

X = X.T
```

![Данные для классификации](/assets/images/ml_text/ml2-1.png "Данные для классификации"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

#### Как реализовать логистическую регрессию?

```py
class hypothesis(object):
    """Модель логистической регрессии"""
    def __init__(self):
        self.b0 = 0
        self.b1 = 0
        self.b2 = 1
    def predict(self, x):
        x1, x2 = x
        z = self.b0 + self.b1 * x1 + self.b2 * x2
        return 1 / (1 + np.exp(-z))
    def error(self, X, Y):
        return -sum(Y * np.log2(self.predict(X)) + (1 - Y) *(1 - np.log2(self.predict(X)))) / len(X[0])
    def BGD(self, X, Y):  
        alpha = 0.5
        for _ in range(1000):
          dJ0 = sum(self.predict(X) - Y) /len(X)
          dJ1 = sum((self.predict(X) - Y) * X[0]) /len(X[0])
          dJ2 = sum((self.predict(X) - Y) * X[1]) /len(X[0])
          self.b0 -= alpha * dJ0
          self.b1 -= alpha * dJ1
          self.b2 -= alpha * dJ2
```

#### Как оценить качество классификационной модели?

```py
hyp = hypothesis()
print(hyp.predict((0, 0)))
J = hyp.error(X, Y)
print("initial error:", J)
hyp.BGD(X, Y)
J = hyp.error(X, Y)
print("error after gradient descent:", J)

xx, yy = np.meshgrid(np.arange(-2, 3, 0.1), np.arange(-3, 2, 0.1))
Z = hyp.predict((xx, yy))
Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, alpha=0.4)
plt.scatter(X.T[:, 0], X.T[:, 1], marker="o", c=Y, s=25, edgecolor="k")
plt.show()
```

![Классификация](/assets/images/ml_text/ml2-2.png "Классификация"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

![Классификация](/assets/images/ml_text/ml2-3.png "Классификация"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

#### Как построить простую классификацию в scikit-learn?

```py
from sklearn import linear_model

X = X.T

reg = linear_model.LogisticRegression()
reg.fit(X, Y)
print(reg.score(X, Y))
```

![Библиотечная классификация](/assets/images/ml_text/ml2-4.png "Библиотечная классификация"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

<!-- ### Более сложные методы классификации

#### Метод опорных векторов

Метод опорных векторов (support vector machines, SVM) является еще одним типом алгоритма машинного обучения с учителем для задач классификации. Иногда он работает быстрее и точнее логистической регрессии. Чтобы использовать метод опорных векторов, мы модифицируем первый член функции стоимости 

, так что при 


 (здесь и далее будем обозначать эту величину как z) больше 1, оно выводит 0. Кроме того, для значений z, меньших 1, мы будем использовать прямую убывающую линию вместо сигмовидной кривой (в англоязычной литературе это называется функцией hinge loss). Аналогично, мы модифицируем второй член функции стоимости 


, так что, когда z меньше -1, алгоритм выдает 0. Мы также модифицируем его так, чтобы при значениях z больше -1, вместо сигмоидной кривой мы используем прямую растущую линию.

Мы будем обозначать соответствующие компоненты функции ошибки как 


 и 


 (соответственно, обратите внимание, что 


 является стоимостью для классификации при y = 1 и 


 - это стоимость классификации при y = 0), и мы можем определить их следующим образом (где k - произвольная константа, определяющая величину наклона линии):





Вспомните полную функцию стоимости из регуляризованной логистической регрессии. Мы можем преобразовать ее в функцию стоимости для векторных машин поддержки, заменив cost<sub>0</sub> и cost<sub>1</sub>.



Кроме того, общепринятое соглашение диктует, что мы регуляризуем с использованием фактора C вместо λ, тогда функция ошибки будет выглядеть следующим образом:



Это эквивалентно умножению уравнения на 


и, таким образом, приводит к тем же значениям при оптимизации. Теперь, когда мы хотим еще больше регуляризовать (то есть сократить возможность переобучения), мы уменьшаем C, и когда мы хотим регуляризовать меньше (то есть уменьшать возможность недообучения), мы увеличиваем C.

Наконец, обратите внимание, что значение функции гипотезы в методе опорных векторов не интерпретируется как вероятность того, что y будет равен 1 или 0 (как для гипотезы логистической регрессии). Вместо этого он выводит либо 1, либо 0 дискретно. 

Полезный способ думать о методе опорных векторов - как о методе, максимизирующем расстояние между классами и границей принятия решения.  Когда мы установим нашу константу C в очень большое значение (например, 100 000), наша оптимизирующая функция будет ограничивать b так, чтобы уравнение суммы ошибки каждого примера равна 0. Мы накладываем следующие ограничения на b:




Если C очень велико, мы должны выбрать такие параметры b, что:




Напомним, что граница принятия решения в логистической регрессии - это линия, отделяющая положительные и отрицательные примеры. В SVM граница решения имеет особое свойство, заключающееся в том, что она как можно дальше от положительного и отрицательного примеров.

SVM будет отделять отрицательные и положительные примеры с большим отрывом. Этот большой запас достигается только тогда, когда C очень большой.

Данные называются линейно разделимыми, когда прямая линия, плоскости или гиперплоскость (в зависимости от размерности данных) может отделить положительные и отрицательные примеры. Увеличение и уменьшение C аналогично уменьшению и увеличению λ и может упростить вид границы принятия решения.


#### Ядра

Ядра (kernels) позволяют нам создавать сложные нелинейные классификаторы с использованием метода опорных векторов.

При данном x, можно ввести новые признаки в зависимости от близости x к определенным заранее выбранным точкам (ориентирам), скажем 

. Для этого мы находим «подобие» x и некоторой точки  


:



Эта функция «подобия» называется гауссовским ядром. Это конкретный пример ядра. Существует несколько свойств функции подобия: 



*   Если 


, тогда 



*   Если x далек от 


, тогда 




Другими словами, если x и ориентир близки, то сходство будет близким к 1, и если x и ориентир находятся далеко друг от друга, сходство будет близко к 0.

Каждый ориентир дает нам набор признаков для нашей модели:





σ<sup>2</sup> - параметр гауссовского ядра, и его можно модифицировать, чтобы увеличить или уменьшить область действия нашей функции f<sub>i</sub>. В сочетании с изменением значений внутри b, мы можем выбрать эти ориентиры, чтобы получить общую форму границы принятия решения.

Один из способов получить ориентиры - разместить их в тех же точках гиперпространства, что и все учебные примеры. Это дает нам набор ориентиров, с одним ориентиром на каждый пример обучения. Это дает нам «вектор функций» 


 для всех наших изначальных признаков, например 


. Мы можем также установить 


, чтобы соответствовать b<sub>0</sub>. Таким образом, данный пример обучения 


.

Теперь, чтобы получить параметры b, мы можем использовать алгоритм минимизации SVM, но с заменой 


 на 


:


Использование ядер для генерации f<sub>(i)</sub> не является исключительным для SVM и может также применяться к логистической регрессии. Однако из-за вычислительной оптимизации в алгоритмах SVM,  ядра работают с SVM, намного быстрее, чем с другими алгоритмами, поэтому ядра почти всегда встречаются вместе только с SVM.


#### Выбор параметров SVM

Выбор C (напомним, что 

) производится с учетом следующих условия:



*   Если C велико, то мы получаем более высокую дисперсию / низкое смещение
*   Если C мало, то мы получаем более низкую дисперсию / более высокое смещение

Другим параметром, который мы должны выбрать, является σ<sup>2</sup> для функции гауссовского ядра:



*   При большом σ<sup>2</sup> характеристики f<sub>i</sub> изменяются более плавно, что приводит к более высокому смещению и более низкой дисперсии.
*   При малом σ<sup>2</sup> функции f<sub>i</sub> изменяются менее плавно, вызывая более низкое смещение и более высокую дисперсию.

В практическом применении выбор, который вам нужно сделать, это:



*   Выбор параметра C
*   Выбор ядра (функция подобия)
    *   Нет ядра («линейное» ядро) - дает стандартный линейный классификатор. Выберем, когда n велико, а m мало
    *   Гауссовское ядро ​​(описанное выше) - нужно выбрать σ<sup>2</sup>. Выберите, когда n мало и m велико
    *   Полиномиальное: 


    *   Радиальная базисная функция: 


    *   Гауссова радиальная базисная функция: 


    *   Сигмоид: 




Выполняйте масштабирование признаков перед использованием гауссовского ядра.

Не все функции подобия являются допустимыми ядрами. Они должны удовлетворять теореме Мерсера, которая гарантирует правильную работу оптимизаций пакета SVM и не расходится.
 -->