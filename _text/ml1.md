---
section: ml
title: "Регрессия как задача машинного обучения"
---

### Постановка задачи регрессии

![Задача регрессии](https://editor.analyticsvidhya.com/uploads/87851lr.png "Задача регрессии"){: .align-center style="width: 800px;"}
Источник: [Analytics Vidhya](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2021%2F05%2F5-regression-algorithms-you-should-know-introductory-guide%2F&psig=AOvVaw2c_ybzX_oF5s5EZjCsWfH0&ust=1651764035488000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCLiPvfSSxvcCFQAAAAAdAAAAABAD).
{: style="text-align: center; font-size:0.7em;"}

Задача регрессии - это одна из основных задач машинного обучения. И хотя, большинство задач на практике относятся к другому типу - классификации, мы начнем знакомство с машинным обучением именно с регрессии. Регрессионные модели были известны задолго до появления машинного обучения как отрасли и активно применяются в статистике, эконометрике, математическом моделировании. Машинное обучение предлагает новый взгляд на уже известные модели. И этот новый взгляд позволит строить более сложные и мощные модели, чем классические математические дисциплины.

Задача регрессии относится к категории задач обучения с учителем. Это значит, что в наборе данных, который используется для обучения, должен иметь определенную структуру. Обычно, наборы данных для машинного обучения представляют собой таблицу, в которой по строкам перечислены разные объекты наблюдений или измерений. В столбцах - различные характеристики, или атрибуты, объектов. А на пересечении строк и столбцов - значение данной характеристики у данного объекта. Обычно один атрибут (или переменная) имеет особый характер - именно ее значение мы и хотим научиться предсказывать с помощью модели машинного обучения. Эта характеристика объекта называется целевая переменная. И если эта целевая переменная выражена числом (а точнее, некоторой непрерывной величиной) - то мы говорим о задаче регрессии.

Задачи регрессии на практике встречаются довольно часто. Например, предсказание цены объекта недвижимости - классическая регрессионная задача. В таких проблемах атрибутами выступают разные характеристики квартир или домов - площадь, этажность, расположение, расстояние до центра города, количество комнат, год постройки. В разных наборах данных собрана разная информация И, соответственно, модели тоже должны быть разные. Другой пример - предсказание цены акций или других финансовых активов. Или предсказание температуры завтрашним днем. 

Во всех таких задачах нам нужно иметь данные, которые позволят осуществить такое предсказание. Да, "предсказание" - это условный термин, не всегда мы говорим о будущих событиях. Регрессионные модели используют информацию об объектах в обучающем наборе данных, чтобы сделать вывод о возможном значении целевой переменной. И для этого нужно, чтобы ее значение имело какую-то зависимость от имеющихся у нас атрибутов. Если построить модель предсказания цены акции, но на вход подать информацию о футбольных матчах - ничего не получится. Мы предполагаем, что в наборе данных собраны именно те атрибуты объектов, которые имеют влияние на на значение целевой переменной. И чем больше это предположение выполняется, тем точнее будет потенциально наша модель.

Немного поговорим о терминах. Набор данных который мы используем для обучения модели называют датасетом (dataset) или обучающей выборкой (training set). Объекты, которые описываются в датасете еще называют точками данных (data points). Целевую переменную еще называют на статистический манер зависимой переменной (dependent variable) или результативной, выходной (output), а остальные атрибуты - независимыми переменными (dependent variables), или признаками (features), или факторами, или входными переменными (input). Значения одного конкретного атрибута для всех объектов обучающей выборки часто представляют как вектор этого признака (feature vector). А всю таблицу всех атрибутов называют матрицей атрибутов (feature matrix). Соответственно, еще есть вектор целевой переменной, он не входит в матрицу атрибутов.

С точки зрения информатики, регрессионная модель - это функция, которая принимает на вход значения атрибутов какого-то конкретного объекта и выдает на выходе предполагаемое значение целевой переменной. В большинстве случаев мы предполагаем, что целевая переменная у нас одна. Если стоит задача предсказания нескольких характеристик, то их чаще воспринимают как несколько независимых задач регрессии на одних и тех же атрибутах.

Мы пока ничего не говорили о том, как изнутри устроена регрессионная модель. Это потому, что она может быть какой угодно. Это может быть математическое выражение, условный алгоритм, сложная программа со множеством ветвлений и циклов, нейронная сеть - все это можно представить регрессионной моделью. Единственное требование к модели машинного обучения - она должна быть параметрической. То есть иметь какие-то внутренние параметры, от которых тоже зависит результат вычисления. В простых случаях, чаще всего в качестве регрессионной модели используют аналитические функции. Таких функций бесконечное количество, но чаще всего используется самая простая функция, с которой мы и начнем изучение регрессии - линейная функция.

Так же надо сказать, что иногда регрессионные модели подразделяют на парную и множественную регрессии. Парная регрессия - это когда у нас всего один атрибут. Множественная - когда больше одного. Конечно, на практике парная регрессия почти не встречается, но на примере такой простой модели мы поймем основные концепции машинного обучения. Плюс, парную регрессию очень удобно и наглядно можно изобразить на графике. Когда у нас больше двух переменных, графики уже не особо построишь, и модели приходится визуализировать иначе, более косвенно.

{% capture notice-2 %}
Выводы:
1. Регрессия - это задача машинного обучения с учителем, которая заключается в предсказании некоторой непрерывной величины.
1. Для использования регрессионных моделей нужно, чтобы в датасете были характеристики объектов и "правильные" значения целевой переменной.
1. Примеры регрессионных задач - предсказание цены акции, оценка цены объекта недвижимости.
1. Задача регрессии основывается на предположении, что значение целевой переменной зависит от значения признаков.
1. Регрессионная модель принимает набор значений и выдает предсказание значения целевой переменной.
1. В качестве регрессионных моделей часто берут аналитические функции, например, линейную.
{% endcapture %}
<div class="notice--info">{{ notice-2 | markdownify }}</div>


### Линейная регрессия с одной переменной


#### Функция гипотезы

![Модель регрессии](/assets/images/ml_text/ml1-1.png "Модель регрессии"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Напомним, что в задачах регрессии мы принимаем входные переменные и пытаемся получить более-менее достоверное значение целевой переменной. Ведь любая функция, даже самая простая линейная может выдавать совершенно разные значения для одних и тех же входных данных, если в функции будут разные параметры. Поэтому, любая регрессионная модель - это не какая-то конкретная математическая функция, а целое семейство функций. И задача алгоритма обучения - подобрать значения параметров таким образом, чтобы для объектов обучающей выборки, для которых мы уже знаем правильные ответы, предсказанные (или теоретические, вычисленные из модели) значения были как можно ближе к тем, которые есть в датасете (эмпирические, истинные значения).

Парная, или одномерная (univariate) регрессия используется, когда вы хотите предсказать одно выходное значение (чаще всего обозначаемое $y$), зависящее от одного входного значения (обычно обозначается $x$). Сама функция называется функция гипотезы. 

В случае парной линейной регрессии функция гипотезы имеет следующий общий вид:

$$ \hat{y} = h_b (x) = b_0 + b_1 x $$

Обратите внимание, что это похоже на уравнение прямой. Эта модель соответствует множеству всех возможных прямых на плоскости. Когда мы конкретизируем модель значениями параметров (в данном случае - $b_0$ и $b_0$), мы получаем конкретную прямую. И наша задача состоит в том, чтобы выбрать такую прямую, которая бы лучше всего "легла" в точки из нашей обучающей выборки.

в данном случае, мы пытаемся подобрать функцию _h(x)_ таким образом, чтобы отобразить данные нам значения _x_ в данные значения _y_.

Допустим, мы имеем следующий обучающий набор данных:


<table>
  <tr>
   <td>входная переменная x
   </td>
   <td>выходная переменная y
   </td>
  </tr>
  <tr>
   <td>0
   </td>
   <td>4
   </td>
  </tr>
  <tr>
   <td>1
   </td>
   <td>7
   </td>
  </tr>
  <tr>
   <td>2
   </td>
   <td>7
   </td>
  </tr>
  <tr>
   <td>3
   </td>
   <td>8
   </td>
  </tr>
</table>


Мы можем составить случайную гипотезу с параметрами $ b_0 = 2, b_1 = 2 $. Тогда для входного значения $ x=1, y=4 $, что на 3 меньше данного. Задача регрессии состоит в нахождении таких параметров функции гипотезы, чтобы она отображала входные значения в выходные как можно более точно, или, другими словами, описывала линию, наиболее точно ложащуюся в данные точки на плоскости (x, y). 

{% capture notice %}
Выводы:
1. Модель машинного обучения - это параметрическая функция
1. Задача обучения состоит в том, чтобы подобрать параметры модели таким образом, чтобы она лучше всего описывала обучающие данные.
1. Парная линейная регрессия работает, если есть всего одна входящая переменная.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>


#### Функция ошибки

![Разные модели](/assets/images/ml_text/ml1-2.png "Разные модели"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Мы можем измерить точность нашей функции гипотезы, используя функцию ошибки. Для этого требуется средняя (фактически чуть усложненная версия среднего арифметического) всех результатов вычисления гипотезы с входами x по сравнению с фактическим выходом y.

![Отклонения значений](/assets/images/ml_text/ml1-3.png "Отклонения значений"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

{% capture notice-2 %}
$$ 
J(b_0, b_1) 
= \frac{1}{2m} \sum_{i=1}^{m} (\hat{y_i} - y_i)^2 
= \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2 
$$
{% endcapture %}
<div class="presentation">{{ notice-2 | markdownify }}</div>

По сути своей, это половина среднего квадрата разницы между прогнозируемым и фактическим значением выходной переменной.

![Среднеквадратическая ошибка](/assets/images/ml_text/ml1-4.png "Среднеквадратическая ошибка"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Эту функцию называют «функцией квадрата ошибки» или «среднеквадратичной ошибкой» (mean squared error, MSE). Среднее значение уменьшено вдвое для удобства вычисления градиентного спуска, так как производная квадратичной функции будет отменять множитель 1/2.

![Ошибка](/assets/images/ml_text/ml1-5.png "Ошибка"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

![Ошибка](/assets/images/ml_text/ml1-6.png "Ошибка"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Теперь мы можем конкретно измерить точность нашей предсказывающей функции по сравнению с правильными результатами, которые мы имеем, чтобы мы могли предсказать новые результаты, которых у нас нет.

Если мы попытаемся представить это наглядно, наш набор данных обучения будет разбросан по плоскости x-y. Мы пытаемся подобрать прямую линию, которая проходит через этот разбросанный набор данных. Наша цель - получить наилучшую возможную линию. Лучшая линия будет такой, чтобы средние квадраты вертикальных расстояний рассеянных точек от линии были наименьшими. В лучшем случае линия должна проходить через все точки нашего набора данных обучения. В таком случае значение J будет равно 0.

{% capture notice %}
Выводы:
1. Функция ошибки нужна для того, чтобы отличать хорошие модели от плохих.
1. Функция ошибки показывает численно, насколько модель хорошо описывает данные.
1. Аргументами функции ошибки являются параметры модели, ошибка зависит от них.
1. Само значение функции ошибки не несет никакого смысла, оно используется только в сравнении.
1. Цель алгоритма машинного обучения - минимизировать функцию ошибки, то есть найти такой набор параметров модели, при которых ошибка минимальна.
1. Чаще всего используется так называемая L2-ошибка - средний квадрат отклонений теоретических значений от эмпирических.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div> 


#### Метод градиентного спуска

Таким образом, у нас есть наша функция гипотезы, и у нас есть способ оценить, насколько хорошо конкретная гипотеза вписывается в данные. Теперь нам нужно подобрать параметры в функции гипотезы. Вот где приходит на помощь метод градиентного спуска.

Представьте себе, что мы нарисуем нашу функцию гипотезы на основе ее параметров b<sub>0</sub> и b<sub>1</sub> (фактически мы представляем график функции стоимости как функцию оценок параметров). 

Отложим b<sub>0</sub> на оси x и b<sub>1</sub> на оси y, с функцией стоимости на вертикальной оси z. Точки на нашем графике будут результатом функции стоимости, используя нашу гипотезу с этими конкретными параметрами.

Мы будем знать, что нам удалось подобрать оптимальные параметры, когда наша функция стоимости находится в самом низу на нашем графике, то есть когда ее значение является минимальным.

То, как мы это делаем - это используя производную (касательную линию к функции) нашей функции стоимости. Наклон касательной является производной в этой точке, и это даст нам направление движения в сторону самого крутого уменьшения значения функции. Мы делаем шаги вниз по функции стоимости в направлении с самым крутым спусками, а размер каждого шага определяется параметром α, который называется скоростью обучения.

{% capture block %}
Алгоритм градиентного спуска:

повторяйте до сходимости: 

$$ b_j := b_j - \alpha \frac{\partial}{\partial b_j} J(b_0, b_1) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

где j=0,1 - представляет собой индекс номера признака.

{% capture block %}
Алгоритм градиентного спуска для парной линейной регрессии:

повторяйте до сходимости: 

$$ b_0 := b_0 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x)^{(i)} - y^{(i)}) $$

$$ b_1 := b_1 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x)^{(i)} - y^{(i)}) \cdot x^{(i)} $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

![Спуск](/assets/images/ml_text/ml1-7.png "Спуск"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

![Другой спуск](/assets/images/ml_text/ml1-8.png "Другой спуск"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. Метод градиентного спуска нужен, чтобы найти минимум функции, если мы не можем ее вычислить аналитически.
1. Это численный итеративный алгоритм локальной оптимизации.
1. Для запуска градиентного спуска нужно знать частную производную функции ошибки.
1. Для начала мы берем произвольные значения параметров, затем обновляем их по данной формуле.
1. Доказано, что этот метод сходится к локальному минимуму.
1. Если функция ошибки достаточно сложная, то разные начальные точки дадут разный результат.
1. Метод градиентного спуска имеет свой параметр - скорость обучения. Обычно его подстаивают автоматически.
1. Метод градиентного спуска повторяют много раз до тех пор, пока функция ошибки не перестанет значимо изменяться.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>


### Линейная регрессия с несколькими переменными

![Множественная регрессия](/assets/images/ml_text/ml1-9.png "Множественная регрессия"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Линейная регрессия с несколькими переменными также известна как «множественная линейная регрессия». Введем обозначения для уравнений, где мы можем иметь любое количество входных переменных:

$ x^{(i)} $- вектор-столбец всех значений признаков i-го обучающего примера;


$ x_j^{(i)} $ - значение j-го признака i-го обучающего примера;

_m_ - количество примеров в обучающей выборке;

_n_ - количество признаков;

_X_ - матрица признаков;

_b_ - вектор параметров регрессии.

Заметим, что в будущем для удобства примем, что $ x_0^{(i)} = 1 $ для всех i. Другими словами, мы для удобства введем некий суррогатный признак, для всех наблюдений равный единице. это сильно упростит математические выкладки, особенно в матричной форме. 

Теперь определим множественную форму функции гипотезы следующим образом, используя несколько признаков:


{% capture block %}
$$ h_b(x) = b_0 + b_1 x_1 + b_2 x_2 + ... + b_n x_n $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>


Используя определение матричного умножения, наша многопараметрическая функция гипотезы может быть кратко представлена в виде: _h(x) = B X_.

Для множественной регрессии функция ошибки от вектора параметров b выглядит следующим образом:

{% capture block %}
$$ J(b) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x^{(i)} - y^{(i)})^2 $$

Или в матричной форме:

$$ J(b) = \frac{1}{2m} (X b - \vec{y})^T (X b - \vec{y}) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture block %}
Метод градиентного спуска для множественной регрессии определяется следующими уравнениями:

повторять до сходимости:

$$ b_0 := b_0 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x_0^{(i)} $$

$$ b_1 := b_1 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x_1^{(i)} $$

$$ b_2 := b_2 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x_2^{(i)} $$

$$ ... $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Или в матричной форме:

{% capture block %}
$$ b := b - \frac{\alpha}{m} X^T (X b - \vec{y}) $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture notice %}
Выводы:
1. Множественная регрессия очень похожа на парную, но с большим количеством признаков.
1. Для удобства и однообразия, почти всега обозначают $x_0 = 1$.
1. Признаки уже образуют матрицу, поэтому уравнения множественной регрессии часто приводят в матричной форме, так короче.
1. Алгоритм градиентного спуска для множественной регресси точно такой же, как и для парной.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

<!-- #### Нормализация признаков

Мы можем ускорить сходимость метода градиентного спуска, получив каждое из наших входных значений примерно в том же диапазоне. Это связано с тем, что b будет быстро сходиться на малых диапазонах и медленно на больших диапазонах, и поэтому будет колебаться неэффективно до оптимального, если переменные очень неравномерны.

Способ предотвратить это - изменить диапазоны наших входных переменных, чтобы они были примерно одинаковыми. В идеале 

-1 ≤ x ≤ 1 или же -0,5 ≤ x ≤ 0,5.

Это не точные требования; мы только пытаемся ускорить процесс. Цель состоит в том, чтобы получить все входные переменные в примерно один из этих диапазонов, дать или взять несколько.

Два метода для этого - масштабирование признаков и нормализация по среднему. Масштабирование признаков заключается в делении входных значений на размах выборки (то есть максимальное значение минус минимальное значение) входной переменной, в результате чего новый диапазон составляет всего 1. Нормализация по среднему включает в себя вычитание среднего значения входной переменной из значений для этой входной переменной, в результате чего новое среднее значение для этой переменной равно нулю. Чтобы реализовать оба этих метода, отрегулируйте свои входные значения, как показано в этой формуле:


$$ x_i = \frac{x_i - \mu_i}{s_i} $$


Где 

$ \mu_i $- среднее значение признака i, а 

$ s_i $ - стандартное отклонение этого признака.


#### Советы по методу градиентного спуска

1. Отладка градиентного спуска. 
Сделайте график с количеством итераций по оси x. Теперь построим функцию стоимости J(b) по числу итераций градиентного спуска. Если J(b) когда-либо возрастает, то, вероятно, вам необходимо уменьшить α.

2. Автоматический тест сходимости. 
Объявите сходимость, если J(b) уменьшится меньше чем на E на одной итерации, где E - некоторое небольшое значение, такое как 10<sup>-3</sup>. Однако на практике трудно выбрать это пороговое значение.
Было доказано, что если скорость обучения α достаточно мала, то J(b) будет уменьшаться на каждой итерации. 

3. Суррогатные признаки
Мы можем улучшить наши функции и форму нашей функции гипотез несколькими способами. Мы можем объединить несколько признаков в один. Например, мы можем объединить x1 и x2 в новый признак x3, взяв x1⋅x2. -->

#### Полиномиальная регрессия

![Нелинейная регрессия](/assets/images/ml_text/ml1-10.png "Нелинейная регрессия"){: .align-center style="width: 800px;"}
{: style="text-align: center; font-size:0.7em;"}

Наша функция гипотезы не обязательно должна быть линейной (прямой), если это не соответствует данным.

Мы можем изменить поведение или кривую нашей функции гипотезы, сделав ее квадратичной, кубической или квадратной корневой функцией (или любой другой формой).

Например, если наша функция гипотезы 
$ \hat{y} = h_b (x) = b_0 + b_1 x $, 
то мы можем добавить еще один признак, основанный на x1, получив квадратичную функцию 

{% capture block %}
$$ \hat{y} = h_b (x) = b_0 + b_1 x + b_2 x^2 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

или кубическую функцию 

{% capture block %}
$$ \hat{y} = h_b (x) = b_0 + b_1 x + b_2 x^2 + b_3 x^3 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

В кубической функции мы по сути ввели два новых признака: 
$ x_2 = x^2, x_3 = x^3 $. 
Точно таким же образом, мы можем создать, например, такую функцию: 

{% capture block %}
$$ \hat{y} = h_b (x) = b_0 + b_1 x + b_2 \sqrt{x} $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

Одна важная вещь, о которой следует помнить, заключается в том, что если вы выбираете свои функции таким образом, масштабирование признаков становится очень важным. Например, если x имеет диапазон 1 - 1000, тогда диапазон x<sup>2</sup> становится 1 - 1000000, а диапазон x<sup>3</sup> становится 1 - 1000000000.

{% capture block %}
$$ \hat{y} = h_b (x) = b_0 + b_1 x_1 + b_2 x_2 + b_3 x_1^2 + b_4 x_2^2 + b_5 x_1 x_2  $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

{% capture block %}
$$ \hat{y} = h_b (x) = b_0 + b_1 x_1 + b_2 x_2 + b_3 x_1^2 + b_4 x_2^2 + b_5 x_1 x_2 + b_6 x_1^3 + b_7 x_2^3 + b_7 x_1^2 x_2 + b_8 x_1 x_2^2 $$
{% endcapture %}
<div class="presentation">{{ block | markdownify }}</div>

![Полиномиальная регрессия](https://upload.wikimedia.org/wikipedia/commons/9/90/Poly-reg-3.png "Полиномиальная регрессия"){: .align-center style="width: 800px;"}
Источник: [Wikimedia](https://www.google.com/url?sa=i&url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FFile%3APoly-reg-3.png&psig=AOvVaw0RpQeJZ6qEk5xxrxustROm&ust=1651936121936000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCMjYvuCTy_cCFQAAAAAdAAAAABAN).
{: style="text-align: center; font-size:0.7em;"}

{% capture notice %}
Выводы:
1. Данные в датасете не всегда располагаются так, что их хорошо может описывать линейная функция.
1. Для описания нелинейных зависимостей нужна более сложная, нелинейная модель.
1. Чтобы не изобретать алгоритм обучения заново, можно просто ввести в модель суррогатные признаки.
1. Суррогатный признак - это новый признак, который считается из существующих атрибутов.
1. Чаще всего используют полиномиальную регрессию - это когда в модель вводят полиномиальные признаки - степени существующих атрибутов.
1. Обычно берут все комбинации факторов до какой-то определенной степени полинома.
1. Полиномиальная регрессия может аппроксимировать любую функцию, нужно только подобрать степень полинома.
1. Чем больше степень полиномиальной регрессии, тем она сложнее и универсальнее, но вычислительно сложнее (экспоненциально).
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

<!-- #### Нормальное уравнение

«Нормальное уравнение» - это метод нахождения оптимальных параметров регрессии без итераций:

$$ b = (X^T X)^{-1} X^T y $$

Нет необходимости выполнять масштабирование признаков, если мы решаем регрессию с помощью нормального уравнения.

Метод решения через нормальное уравнение имеет ряд преимуществ по сравнению с методом градиентного спуска:

1. Нет необходимости в нормализации признаков;
2. Не нужно выбирать скорость обучения;
3. Не требует вычисления частных производных функции ошибки;

Однако, у него есть и недостатки:

1. Имеет асимптотику O(n<sup>3</sup>) по сравнению с O(n<sup>2</sup>) у градиентного спуска. Поэтому довольно медленно работает при больших n.
2. Требует вычисления обратной матрицы. В некоторых случаях матрица $X^T X$ может быть вырожденной, что затруднит использование нормального уравнения.


### Применение регрессионных моделей

#### Как должны быть представлены данные для машинного обучения?

#### Как работает метод машинного обучения "на пальцах"?

#### Как применять регрессию с использованием scikit-learn?

#### Как оценить качество регрессионной модели? -->