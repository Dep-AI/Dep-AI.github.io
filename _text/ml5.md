---
section: ml
title: "Предварительный анализ и обработка данных"
---

### Сбор данных для обучения

#### Реляционная форма - объекты, атрибуты и признаки

{% capture notice %}
Выводы:
1. Датасет - это набор данных, используемый для обучения моделей.
1. Объекты - это элементарные сущности, которые мы изучаем, объекты реального мира, измерения, наблюдения.
1. Каждый объект характеризуется набором атрибутов. В датасете у всех объектов одинаковый набор атрибутов, а значения - разные.
1. Атрибут или переменная - это свойство объектов в датасете, признак - это колонка данных, которая подается на вход модели машинного обучения.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Понятие чистых данных

{% capture notice %}
Выводы:
1. Данные представлены в виде единой таблицы.
1. строки таблицы представляют собой измерение, точку данных, объект предметной области.
1. Колонки таблицы представляют собой атрибуты объектов, признаки, переменные.
1. Каждая таблица, файл представляет собой данные об одном виде наблюдений или экспериментов.
1. Все данные должны быть выражены в численном виде.
1. В данных не должно быть отсутствующих значений. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Оценка источников и объемов данных

{% capture notice %}
Выводы:
1. После постановки задачи машинного обучения первый этап моделирования - определение источников и объема данных, необходимых для эффективного обучения.
1. Объем данных определяется порядком сложности задачи: чем больше данных, тем более сложные модели можно на них строить.
1. В целом, чем больше данных можно собрать, тем лучше.
1. Данные в датасете должны быть репрезентативной выборкой генеральной совокупности.
1. Источники данных могут быть открытые и закрытые, платные, по подписке, внутренние и внешние.
1. Данные могут быть пакетные и потоковые, с ними надо работать по разному.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Интеграция данных

{% capture notice %}
Выводы:
1. Интеграция данных - это процесс объединения данных из нескольких источников в единый датасет.
1. Объединение датасетов может происходить по горизонтали и по вертикали.
1. Вертикальное объединение датасетов - это по сути просто склеивание двух однотипных наборов данных в один.
1. Горизонтальное объединение датасетов происходит обязательно через аналог операции JOIN по ключу.
1. При объединении данных из разных источников необходимо особенно тщательно следить за обозначениями, соглашениями, датами. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Описательный анализ данных (EDA)

{% capture notice %}
Выводы:
1. Описательный анализ данных нужен для обнаружения проблем (артефактов) в данных и для выбора метода их устранения.
1. EDA также может дать информация о структуре данных, шкалах измерения переменных, которые потом повлияют на методы обработки данных.
1. Также EDA может помочь при выборе признаков, выявлении зависимостей в данных.
1. EDA - это обзорный анализ данных именно при их подготовке к процессу машинного обучения.
1. При необходимости, можно провести более глубокий статистический анализ данных.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Анализ репрезентативности датасета

{% capture notice %}
Выводы:
1. Для машинного обучения важно, чтобы датасет правильно отражал генеральную совокупность. Это дает модели обобщающую способность.
1. Анализ соотношения выборки и генеральной совокупность не всегда возможно провести, но когда можно - нужно это делать.
1. Самая простая метрика - процент ГС, который отражен в выборке.
1. Может быть проведена проверка адекватности распределения признаков экспертным знаниям в области.
1. На этом этапе принимается общее решение о целесообразности моделирования.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Описание шкалы измерения атрибутов

{% capture notice %}
Выводы:
1. Шкалы атрибутов показывают, какие значения может принимать этот атрибут и как его можно интерпретировать и сравнивать.
1. Все атрибуты подразделяются на численные (непрерывные) и категориальные (дискретные). 
1. Категориальные переменные потом придется преобразовать в численные.
1. Номинальная шкала - это признак, для которого имеет смысл только равенство. Пример - метка класса.
1. Ординальная шкала - это когда наряду с равенством мы можем выстроить значения по порядку, который имеет смысл. Пример - класс обслуживания.
1. Ординальные признаки можно преобразовывать методом LabelEncoder. Номинальные - только OneHotEncoder.
1. Интервалая шкала - это когда еще имеет смысл говорить о разнице между двумя значениями. Пример - даты.
1. Абсолютная шкала - это когда еще можно говорить о том, во сколько раз одно значение больше другого. Пример - сумма денег.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Визуализация распределения атрибутов

{% capture notice %}
Выводы:
1. Оценка эмпирического распределения атрибутов дает ценную информацию, которая определяет дальнейшую работу с этим атрибутом.
1. Можно использовать статистические методы, но обычно достаточно визуально оценить распределение по графику.
1. Категориальные переменные обычно изображают на графике, или списком в порядке убывания количества объектов.
1. Для численных переменных обычно строят график плотности распределения, хотя иногда - тоже гистограмму.
1. Для категориальных переменных оценивают долю каждого класса в датасете, сбалансированность распределения, моду.
1. Для численных переменных оценивают минимальное и максимальное значение, меры центрального элемента и разброса.
1. Для численных переменные еще оценивают вид распределения - равномерное, нормальное, логнормальное, экспоненциальное и т.д.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Проблема несбалансированных классов

{% capture notice %}
Выводы:
1. Сбалансированность классов - это равномерность распределения целевой переменной в задачах классификации.
1. Сильно несбалансированные классы плохо сказываются на эффективности обучения, так как модель подстраивается под мажоритарный класс.
1. Самый простой способ устранения - удаление рандомной части объектов мажоритарного класса, но это приводит к кратному уменьшения датасета.
1. Можно попробовать добавить объектов миноритарных классов, но это не всегда возможно.
1. С несбалансированными классами неплохо справляются иерархические классификаторы.
1.Можно попробовать модифицировать алгоритм обучения, придав классам веса.
1. Если ничего не помогает, возможно следует пресмотреть постановку задачи, разбить мажоритарный класс, переформулировать проблему.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Оценка влияния атрибутов на целевую переменную

{% capture notice %}
Выводы:
1. Очень полезно оценить влияние каждого атрибута на целевую переменную.
1. Для этого обычно строят совместное распределение атрибута и целевой переменной. Какой тип визуализации использовать - зависит от шкал.
1. Если обе переменные численные - строят диаграмму рассеяния.
1. Если обе переменные категориальные - можно строить гистограммы с несколькими столбцами или таблицы (часто раскрашивают).
1. Если шкалы разные, то обычно строят график с несколькими линиями.
1. При необходимости можно строить графики совместного распределения двух атрибутов и целевой переменной. Но они уже более сложные.
1. Этот этап может дать информацию о том, какие атрибуты важны, а какие можно и удалить из модели.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Построение корреляционной матрицы

{% capture notice %}
Выводы:
1. Коррелограмма - это популярный инструмент визуализации, он дает много информации, а построить его просто.
1. Корреляционная матрица дает представление о степени влияния каждого фактор на каждый и на целевую переменную.
1. Корреляционная матрица по своей природе симметрична относительно главной диагонали, в которой стоят единицы.
1. Коррелограмма может также дать информацию о мультиколлинеарности атрибутов.
1. Стоит обращать внимание как на положительные, так и на отрицательные корреляции.
1. Коррелограмма показывает только линейные зависимости.
1. По необходимости еще строится матрица совместных распределений.
1. Можно проводить и до и после преобразования данных, но если атрибутов слишком много, матрица получится перегруженной.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Обнаружение аномальных объектов в датасете

{% capture notice %}
Выводы:
1. Аномальные объекты - это те, которые по своим значениям сильно отличаются от большинства.
1. Часто аномалии означают ошибки в данных, опечатки, значения вне разумного диапазона для атрибута.
1. Выбросы (единичные значения атрибута, далеко отстоящие от всех соседей) - почти всегда свидетельствуют об ошибках в данных.1
1. Аномалии можно увидеть на графиках, но если атрибутов слишком много, не все аномалии могут быть выявлены.
1. Обнаружение аномалий - сама по себе задача машинного обучения, которая может выявить аномалии не только по одному измерению, а по всем.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

### Очистка и преобразование данных

#### Удаление лишних признаков (feature selection)

{% capture notice %}
Выводы:
1. Выбор признаков - важная часть преобразования данных, ведь чем точнее мы определим необходимую для моделирования информацию, тем эффективнее будет проходить обучение.
1. Не стоит оставлять в датасете ненужные признаки - это повышает вариативность моделей и может приводить к переобучению.
1. Для выбора признаком часто используют выводы из EDA, обучение простых моделей (DT, RF) или здравый смысл.
1. Выбор признаков можно автоматизировать - применять алгоритм очередного удаления или добавления признаков.
1. Выбор признаков менее актуален, если обучаются нейронные сети, они способны сами отбирать признаки.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Удаление непоказательных объектов

{% capture notice %}
Выводы:
1. Аномальные объекты часто удаляются из датасета, чтобы не искажать результаты обучения.
1. Если можно исправить выброс, можно попытаться это сделать.
1. Следует анализировать, показателен ли объект для предметной области. Если нет - можно смело удалять.
1. После удаления множества объектов может понадобиться повторить анализ сбалансированности классов.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Заполнение отсутствующих значений

{% capture notice %}
Выводы:
1. При выборе стратегии борьбы с пропусками в данных следует проанализировать, сколько пропусков и где они расположены.
1. Если по одному из признаков большинство значений пропущено, можно задуматься об удалении этого признака из датасета.
1. Если наоборот, по одному объекту много неизвестных атрибутов, можно удалить объект.
1. Следует сладить, чтобы от датасета что-то осталось после массового удаления.
1. Самый простой способ заполнить пропуски - заполнить их средним значением, но это сильно искажает форму распределения признака.
1. Зачастую можно считать групповое среднее, более "индивидуальную" оценку атрибута данного объекта, с учетом значений других атрибутов.
1. Иногда применяют заполнение случайным значением. Его лучше всего генерировать из распределения данного признака.
1. Самое грамотное решение - введение нового признака или заполнение специальным значением (по категориальным признакам).
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Создание суррогатных признаков (feature engineering)

{% capture notice %}
Выводы:
1. Инжиниринг признаков - сложная и творческа работа, но зачастую именно в ней кроется секрет существенного повышения эффективности моделей.
1. Суррогатные признаки - это как вычислимые поля в базах данных, они создаются на основе уже присутствующих в датасете атрибутов.
1. При создании новых признаков нужно руководствоваться здравым смыслом и знанием предметной области.
1. Зачастую новые признаки - это часть существующих, которые потом удаляются.
1. Например, из фамилии можно получить список родственников, из даты рождения - возраст и так далее.
1. После введения суррогатных признаков следует повторить EDA, хотя бы частично.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Преобразование численных атрибутов в категориальные

{% capture notice %}
Выводы:
1. Иногда бывает целесообразно сгруппировать объекты датасета по значению какого-то признака и заменить его названием группы.
1. В таком случае, мы удаляет часть информации из модели, но это может быть лишняя вариативность.
1. Показательный пример - группы населения по возрасту.
1. Такое нужно делать, только если есть уверенность, что объекты внутри группы одинаково относятся к целевой переменной.
1. Границы групп выбирают вручную, от этого многое зависит.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Преобразование категориальных атрибутов

{% capture notice %}
Выводы:
1. Категориальные признаки часто выражаются строковыми данными и не подходят для использования в машинном обучении, их преобразуют в численные.
1. Самый простой кодировщик - LabelEncoder - просто нумерует все значения категориального признака.
1. Он вводит порядок в значения категорий, которого раньше не было, поэтому можно исказить результаты обучения.
1. Исключение - бинарные признаки, их можно кодировать как 0 и 1.
1. Более продвинутый кодировщик - OneHotEncoder - преобразует один признак во множество.
1. Новые признаки соответствуют значениям исходного и кодируются бинарно. Этот способ более универсален и рекомендуется применять по умолчанию.
1. В принципе, один из получившихся признаков можно удалить, но обычно никто не заморачивается.
1. Да, из одного признака может получиться тысяча. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Нормализация и решкалирование признаков

{% capture notice %}
Выводы:
1. Нормализация признаков нужна для ускорения обучения и сходимости градиентного спуска.
1. Во многих реализациях моделей нормализация уже встроена и применяется по умолчанию.
1. Основная идея нормализации - это сделать так, чтобы все признаки измерялись по одной шкале, то есть лежали в одних пределах.
1. Обычно для этого выбирают шкалу от 0 до 1. Тогда каждое значение нужно разделить на максимальное.
1. Еще применяют стандартизацию - приведение к стандартному распределению.
1. Нормализация - это параметрическое преобразование, нужно запоминать, на что делили или что отнимали.
1. О отдельных случая применяются более крутые алгоритмы решкалирования с автоматическим устранением выбросов.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Воспроизводимость преобразования данных

{% capture notice %}
Выводы:
1. Алгоритм, по которому выполнялось преобразование обучающей выборки необходимо сохранить, так как именно такое же преобразование нужно будет проделать над тестовой.
1. Да, преобразование данных обычно проводят уже после разделения выборки на обучающую и тестовую.
1. При параметрических преобразованиях все значения параметров подбираются именно по обучающей выборке.
1. Это может означать, что в тестовой после нормализации признак может быть больше 1 (или меньше 0), это нормально, так и надо.
1. Если используется преобразование данных, то модель будет работать на преобразованных данных, а из реального мира будут приходить исходные. 
1. Обычно преобразование данных оформляется как функция или (в sklearn) как обучаемая модель.
1. Преобразование данных используется в составе конвейеров.
1. В процессе исследования бывает необходимо попробовать разные методы преобразования данных в комбинации с разными моделями обучения.
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

<!-- ### Работа с нестандартными типами данных

{% capture notice %}
Выводы:
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы работы с изображениями

{% capture notice %}
Выводы:
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы векторизации текстов

{% capture notice %}
Выводы:
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Работа с временными рядами

{% capture notice %}
Выводы:
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Векторизация аудиоданных

{% capture notice %}
Выводы:
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div>

#### Методы работы с видеоданными

{% capture notice %}
Выводы:
1. 
{% endcapture %}
<div class="notice--info">{{ notice | markdownify }}</div> -->